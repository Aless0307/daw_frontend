{
    "sourceFile": "src/pages/LoggedIn/Componentes-Iniciado/Micro-enter.jsx",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 12,
            "patches": [
                {
                    "date": 1746062237439,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1746064351179,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,172 +1,312 @@\n import React, { useState, useEffect, useRef } from 'react';\n+// Importa la librería cliente oficial de Google Generative AI para JS\n+import { GoogleGenerativeAI } from '@google/generative-ai';\n \n-// Asegúrate de que la Web Speech API esté disponible y maneja prefijos de navegador\n+// --- ¡¡¡ ADVERTENCIA DE SEGURIDAD !!! ---\n+// !!! NO PONGAS TU CLAVE DE API DIRECTAMENTE AQUÍ EN CÓDIGO PARA PRODUCCIÓN !!!\n+// Esto es solo para demostración. Para producción, la llamada a la API debe hacerse desde un BACKEND SEGURO.\n+const API_KEY = \"REEMPLAZA_ESTO_CON_TU_API_KEY_REAL\"; // <-- ¡PON TU CLAVE AQUÍ PARA PROBAR!\n+\n+\n+// --- Verifica si la Web Speech API está disponible ---\n const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n \n-const SpeechToTextPTT = () => {\n-  const [recognizedText, setRecognizedText] = useState(''); // Estado para almacenar el texto reconocido\n-  const [isListening, setIsListening] = useState(false); // Estado para indicar si está escuchando\n-  const [error, setError] = useState(''); // Estado para posibles errores\n \n-  // Usamos useRef para mantener una referencia a la instancia de SpeechRecognition\n-  // y a un flag para saber si la tecla Enter está siendo mantenida presionada\n-  const recognitionRef = useRef(null);\n-  const isHoldingEnter = useRef(false);\n+const VoiceChatWithGemini = () => {\n+  // --- Estados ---\n+  const [recognizedText, setRecognizedText] = useState(''); // Texto capturado por voz\n+  const [geminiResponse, setGeminiResponse] = useState(''); // Respuesta de Gemini\n+  const [isListening, setIsListening] = useState(false); // Estado del micrófono\n+  const [isLoadingGemini, setIsLoadingGemini] = useState(false); // Estado de la llamada a Gemini\n+  const [voiceError, setVoiceError] = useState(''); // Errores del reconocimiento de voz\n+  const [geminiError, setGeminiError] = useState(''); // Errores de la API de Gemini\n \n-  // Este useEffect se encarga de configurar el API de reconocimiento de voz y los listeners de eventos\n+  // --- Referencias (persisten entre renders sin causar re-render) ---\n+  const recognitionRef = useRef(null); // Instancia del objeto SpeechRecognition\n+  const isHoldingEnter = useRef(false); // Flag para saber si Enter está presionado\n+  const genAiRef = useRef(null); // Instancia de GoogleGenerativeAI client\n+  const modelRef = useRef(null); // Instancia del modelo Gemini\n+  const isGeminiCallingRef = useRef(false); // Flag para evitar múltiples llamadas a Gemini a la vez\n+\n+\n+  // --- Configuración de Gemini (similar a tu código Python) ---\n+   const MODEL_NAME = 'gemini-1.5-flash-latest'; // El modelo rápido\n+   const generationConfig = {\n+       // max_output_tokens se omite, confiamos en el prefijo del prompt para la brevedad\n+       \"temperature\": 0.5, // Temperatura baja para respuestas directas\n+   };\n+   // Prefijo para instruir al modelo a ser breve (similar a tu código Python)\n+   const PROMPT_PREFIX = \"Responde de forma muy breve a lo siguiente: \";\n+\n+\n+  // --- Función para enviar el texto reconocido a Gemini ---\n+  const sendToGemini = async (text) => {\n+    // Evitar enviar prompts vacíos o si ya hay una llamada en curso\n+    if (!text.trim() || isLoadingGemini || isGeminiCallingRef.current) {\n+      console.log(\"Saltando llamada a Gemini: texto vacío o ya hay una llamada en progreso.\");\n+      return;\n+    }\n+\n+    setIsLoadingGemini(true);\n+    isGeminiCallingRef.current = true; // Marcar que una llamada a Gemini está activa\n+    setGeminiResponse(''); // Limpiar la respuesta anterior\n+    setGeminiError(''); // Limpiar errores anteriores\n+\n+    // --- Iniciar la llamada a la API de Gemini ---\n+    try {\n+        // Inicializar el cliente y el modelo si no existen ya (usando refs)\n+        if (!genAiRef.current) {\n+            if (!API_KEY || API_KEY === \"REEMPLAZA_ESTO_CON_TU_API_KEY_REAL\") {\n+                 throw new Error(\"API Key de Gemini no configurada correctamente.\");\n+            }\n+            genAiRef.current = new GoogleGenerativeAI(API_KEY);\n+        }\n+        if (!modelRef.current) {\n+             modelRef.current = genAiRef.current.getGenerativeModel({\n+                 model: MODEL_NAME,\n+                 generationConfig: generationConfig,\n+             });\n+        }\n+\n+        // Construir el prompt completo con el prefijo para brevedad\n+        const fullPrompt = PROMPT_PREFIX + text;\n+        console.log(\"Enviando a Gemini:\", fullPrompt);\n+\n+        // Llamar a la API usando streaming para ver la respuesta a medida que llega\n+        const result = await modelRef.current.generateContentStream(fullPrompt);\n+\n+        // Procesar el stream de respuesta\n+        let responseText = '';\n+        for await (const chunk of result.stream) {\n+            // El chunk.text contiene la parte de la respuesta\n+             const chunkText = chunk.text || ''; // Manejar casos donde chunk.text podría ser undefined/null\n+             responseText += chunkText;\n+             setGeminiResponse(prev => prev + chunkText); // Añadir incrementalmente al estado\n+             // Opcional: Añadir un pequeño retardo para simular un stream más lento si quieres\n+             // await new Promise(resolve => setTimeout(resolve, 5));\n+        }\n+\n+         console.log(\"Respuesta de Gemini finalizada.\");\n+\n+    } catch (e) {\n+      console.error(\"Error llamando a la API de Gemini:\", e);\n+      setGeminiError(`Error de Gemini: ${e.message || 'Desconocido'}. Verifica tu API key y la consola.`);\n+      setGeminiResponse(''); // Limpiar cualquier respuesta parcial en caso de error\n+    } finally {\n+      setIsLoadingGemini(false);\n+      isGeminiCallingRef.current = false; // Resetear el flag al finalizar la llamada\n+    }\n+  };\n+\n+\n+  // --- useEffect para la Configuración del Reconocimiento de Voz y Eventos ---\n   useEffect(() => {\n-    // Si la API no está disponible, mostramos un error y salimos\n+    // Si la Web Speech API no está disponible, mostrar error y salir del efecto\n     if (!SpeechRecognition) {\n-      setError(\"La Web Speech API no es soportada por este navegador.\");\n-      console.error(\"La Web Speech API no es soportada por este navegador.\");\n+      setVoiceError(\"La Web Speech API no es soportada por este navegador.\");\n       return;\n     }\n \n-    // --- Configuración del Reconocimiento de Voz ---\n+    // --- Inicializar la instancia de SpeechRecognition ---\n     const recognition = new SpeechRecognition();\n-    recognition.continuous = false; // Queremos resultados al soltar la tecla, no reconocimiento continuo\n-    recognition.interimResults = false; // Solo queremos resultados finales, no intermedios\n-    recognition.lang = 'es-ES'; // Configura el idioma (cámbialo si necesitas otro)\n+    recognition.continuous = false; // Queremos una sola \"escucha\" por cada vez que se presiona Enter\n+    recognition.interimResults = false; // Solo capturar el resultado final\n+    recognition.lang = 'es-ES'; // Configura el idioma. ¡Cámbialo si es necesario!\n \n-    // --- Eventos del Reconocimiento de Voz ---\n+    // --- Handlers de Eventos de SpeechRecognition ---\n     recognition.onstart = () => {\n-      // Este evento se dispara cuando el micrófono comienza a escuchar\n-      setIsListening(true);\n-      setError(''); // Limpiar cualquier error previo al iniciar\n-      console.log('Reconocimiento de voz iniciado.');\n+       setIsListening(true); // Actualizar estado a \"escuchando\"\n+       setVoiceError(''); // Limpiar errores de voz anteriores al iniciar\n+       console.log('Reconocimiento de voz iniciado.');\n     };\n \n     recognition.onresult = (event) => {\n-      // Este evento se dispara cuando se reconoce una porción de voz\n+      // Este evento se dispara cuando se reconoce una porción de voz final (gracias a interimResults: false)\n       const transcript = event.results[event.results.length - 1][0].transcript;\n-      console.log('Resultado parcial o final:', transcript);\n-      // Aquí, como interimResults es false, este será el resultado final de la pausa de habla o al detenerse\n-      setRecognizedText(prevText => (prevText ? prevText + ' ' : '') + transcript); // Añadir el nuevo texto reconocido\n+      console.log('Resultado de voz final:', transcript);\n+      setRecognizedText(transcript); // Almacenar el texto reconocido\n+\n+      // --- ¡Paso Clave! Enviar el texto reconocido a Gemini ---\n+      // Disparamos la llamada a Gemini tan pronto como tengamos un resultado final\n+       if (!isGeminiCallingRef.current) { // Solo si no hay ya una llamada a Gemini en curso\n+           sendToGemini(transcript);\n+       } else {\n+           console.log(\"Resultado de voz listo, pero saltando llamada a Gemini porque ya hay una activa.\");\n+       }\n     };\n \n     recognition.onerror = (event) => {\n-      // Este evento se dispara si ocurre un error\n+      // Manejar errores de reconocimiento de voz\n       console.error('Error en reconocimiento de voz:', event.error);\n-      setIsListening(false); // Asegurar que el estado de escucha se desactive en caso de error\n-      // Dependiendo del error, podrías querer mostrar un mensaje diferente\n-      let errorMessage = `Error de reconocimiento: ${event.error}`;\n+      setIsListening(false); // Detener estado de escucha\n+      isHoldingEnter.current = false; // Asegurar que el flag de Enter se resetee\n\\ No newline at end of file\n+      isGeminiCallingRef.current = false; // También resetear el flag de Gemini\n+\n+      let errorMsg = `Error de voz: ${event.error}`;\n        if (event.error === 'not-allowed') {\n-            errorMessage = 'Se denegó el permiso del micrófono.';\n+            errorMsg = 'Permiso del micrófono denegado. Por favor, permite el acceso.';\n        } else if (event.error === 'no-speech') {\n-            errorMessage = 'No se detectó voz.';\n+            errorMsg = 'No se detectó voz. Intenta hablar más claro o ajusta el micrófono.';\n        } else if (event.error === 'network') {\n-            errorMessage = 'Error de red.';\n+            errorMsg = 'Error de red durante el reconocimiento de voz.';\n+       } else if (event.error === 'aborted') {\n+           errorMsg = 'Reconocimiento abortado.'; // Común si abortamos manualmente al presionar Enter de nuevo\n        }\n-       setError(errorMessage);\n-       isHoldingEnter.current = false; // Reset flag\n \n+       setVoiceError(errorMsg);\n+       setRecognizedText(''); // Limpiar texto reconocido en caso de error\n     };\n \n     recognition.onend = () => {\n-      // Este evento se dispara cuando el reconocimiento termina (se llama a stop() o hay un error/no-speech)\n+      // Este evento se dispara cuando la escucha termina (después de stop() o error/no-speech)\n       console.log('Reconocimiento de voz finalizado.');\n-      setIsListening(false); // Asegurar que el estado de escucha se desactive\n-      isHoldingEnter.current = false; // Asegurar que el flag se resetee\n-\n+      setIsListening(false); // Asegurar que el estado de escucha es falso\n+      isHoldingEnter.current = false; // Asegurar que el flag de Enter se resetee\n+      // El trigger a Gemini ya ocurrió en onresult si hubo voz, o no ocurrió si hubo error/no-speech.\n+      // No necesitamos llamar a sendToGemini aquí de nuevo a menos que 'onresult' no sea confiable antes de 'onend'.\n     };\n \n-    // Guardar la instancia en la referencia para poder acceder a ella en otros handlers\n+    // Guardar la instancia en la referencia para usarla en los handlers de teclado\n     recognitionRef.current = recognition;\n \n-    // --- Handlers de Eventos del Teclado ---\n+\n+    // --- Handlers de Eventos del Teclado (en la ventana global) ---\n     const handleKeyDown = (event) => {\n-      // Solo actuamos si es la tecla Enter y no la estamos manteniendo ya presionada\n+      // Iniciar reconocimiento solo si es la tecla Enter y no la estamos manteniendo ya\n       if (event.key === 'Enter' && !isHoldingEnter.current) {\n-        isHoldingEnter.current = true; // Marcar que Enter está presionada\n-        // No llamamos a start() aquí directamente, lo haremos de forma controlada\n-        // a veces es mejor dejar que onstart actualice el estado, pero aquí lo hacemos para feedback rápido\n-        setIsListening(true);\n-        setError(''); // Limpiar error al intentar hablar\n+        isHoldingEnter.current = true; // Marcar Enter como presionado\n+        // Limpiar estados anteriores al iniciar una nueva interacción\n+        setRecognizedText('');\n+        setGeminiResponse('');\n+        setVoiceError('');\n+        setGeminiError('');\n \n         try {\n-           // Abortar cualquier sesión previa que pudiera estar pendiente\n-           if(recognitionRef.current) {\n+           // Abortar cualquier sesión de reconocimiento previa que pudiera estar activa o pendiente\n+           if(recognitionRef.current && (recognitionRef.current.recognizing || isListening)) {\n                recognitionRef.current.abort(); // Abortar detiene inmediatamente y dispara 'onend'\n            }\n-           // Iniciar una nueva sesión de reconocimiento\n+           // Iniciar el reconocimiento de voz\n            recognitionRef.current.start();\n         } catch (e) {\n-            // Esto puede pasar si intentas start() mientras ya está iniciando o activa (raro con el abort() previo)\n-            console.error(\"Error al intentar iniciar el reconocimiento:\", e);\n-            setIsListening(false);\n-            isHoldingEnter.current = false;\n-            setError(\"No se pudo iniciar el micrófono.\");\n+           console.error(\"Error al intentar iniciar el reconocimiento de voz:\", e);\n+           setIsListening(false);\n+           isHoldingEnter.current = false;\n+           setVoiceError(\"Error al iniciar el micrófono. ¿Permiso denegado o no soportado?\");\n         }\n-\n+        // Opcional: event.preventDefault(); si quieres evitar el comportamiento por defecto de Enter (ej: enviar formularios)\n       }\n     };\n \n     const handleKeyUp = (event) => {\n-      // Solo actuamos si es la tecla Enter y la estábamos manteniendo presionada\n+      // Detener reconocimiento solo si es la tecla Enter y la estábamos manteniendo\n       if (event.key === 'Enter' && isHoldingEnter.current) {\n-        isHoldingEnter.current = false; // Marcar que Enter ha sido soltada\n-        // Llamar a stop() para detener el reconocimiento. Esto disparará 'onend'.\n-        if (recognitionRef.current && isListening) { // Solo detener si estaba escuchando\n+        isHoldingEnter.current = false; // Marcar Enter como soltado\n+        // Llamar a stop() para detener el reconocimiento. Esto dispara el evento 'onend'.\n+        // Solo llamar stop si estaba escuchando para evitar errores.\n+        if (recognitionRef.current && isListening) {\n              recognitionRef.current.stop();\n         } else {\n-            // Si soltó Enter pero no estaba escuchando (ej: error justo al presionar),\n-            // solo asegurarnos de que el flag y estado estén correctos.\n-             setIsListening(false); //redundante con onend, pero seguro\n+             // Si soltó Enter pero no estaba escuchando (quizás por un error),\n+             // solo asegurar que el estado y el flag estén correctos.\n+             setIsListening(false);\n         }\n       }\n     };\n \n     // Añadir los listeners de eventos al objeto global 'window'\n     window.addEventListener('keydown', handleKeyDown);\n     window.addEventListener('keyup', handleKeyUp);\n \n-    // --- Función de Limpieza (se ejecuta al desmontar el componente) ---\n+    // --- Función de Limpieza ---\n+    // Se ejecuta cuando el componente se desmonta\n     return () => {\n-      console.log('Limpiando componente SpeechToTextPTT.');\n-      // Remover los listeners de eventos para evitar fugas de memoria\n+      console.log('Limpiando componente VoiceChatWithGemini.');\n+      // Remover los listeners de eventos del teclado para evitar fugas de memoria\n       window.removeEventListener('keydown', handleKeyDown);\n       window.removeEventListener('keyup', handleKeyUp);\n \n-      // Abortar el reconocimiento si todavía está activo al desmontar el componente\n+      // Abortar el reconocimiento de voz si todavía está activo\n       if (recognitionRef.current && (recognitionRef.current.recognizing || isListening)) {\n         recognitionRef.current.abort(); // abort() es más seguro para limpieza rápida\n       }\n-      recognitionRef.current = null; // Limpiar la referencia\n+       // No es estrictamente necesario limpiar las refs genAiRef y modelRef,\n+       // ya que contienen objetos JS que serán recolectados por el recolector de basura.\n     };\n \n-  }, []); // El array vacío [] asegura que este efecto se ejecute solo una vez al montar el componente\n+  }, []); // El array vacío [] asegura que este efecto se ejecute solo una vez al montar y se limpie al desmontar.\n \n+\n   // --- Renderizado del Componente ---\n   return (\n-    <div style={{ margin: '20px', padding: '20px', border: '1px solid #ccc', borderRadius: '10px', fontFamily: 'sans-serif' }}>\n-      <h2>Control por Voz (Enter para Hablar)</h2>\n+    <div style={{ margin: '20px', padding: '25px', border: '3px solid #4a148c', borderRadius: '15px', fontFamily: 'sans-serif', backgroundColor: '#f3e5f5', boxShadow: '0 4px 8px rgba(0,0,0,0.1)' }}>\n+      <h2 style={{ color: '#4a148c', marginBottom: '20px', textAlign: 'center' }}>🎤 Chat de Voz con Gemini 🤖</h2>\n \n-      <p style={{ marginBottom: '15px', fontSize: '1.1em' }}>\n-        Estado: {isListening ?\n-                 <span style={{ color: 'green', fontWeight: 'bold' }}>🎙️ Escuchando...</span> :\n-                 <span style={{ color: 'gray' }}>🔘 Presiona y mantén la tecla Enter para hablar</span>\n+      {/* Indicador de estado del micrófono */}\n+      <p style={{ marginBottom: '15px', fontSize: '1.1em', color: '#333' }}>\n+        Estado del Micrófono: {isListening ?\n+                 <span style={{ color: '#388e3c', fontWeight: 'bold' }}>🎙️ Escuchando...</span> :\n+                 <span style={{ color: '#757575' }}>🔘 Presiona y mantén la tecla <kbd>Enter</kbd> para hablar.</span>\n                }\n       </p>\n \n-      {error && (\n-          <p style={{ color: 'red', fontWeight: 'bold' }}>Error: {error}</p>\n+      {/* Mostrar errores de voz */}\n+      {voiceError && (\n+          <p style={{ color: '#d32f2f', fontWeight: 'bold', marginBottom: '15px', padding: '10px', backgroundColor: '#ffebee', borderRadius: '5px' }}>Error de Voz: {voiceError}</p>\n       )}\n \n-      <div style={{ marginTop: '15px', padding: '15px', border: '1px dashed #bbb', minHeight: '80px', backgroundColor: '#f9f9f9', borderRadius: '5px', wordBreak: 'break-word' }}>\n-        <strong>Texto Reconocido:</strong>\n-        <p>{recognizedText || 'El texto de la voz aparecerá aquí...'}</p>\n+      {/* Área para mostrar el texto reconocido por voz */}\n+      <div style={{ marginTop: '15px', padding: '15px', border: '1px dashed #ab47bc', minHeight: '80px', backgroundColor: '#fce4ec', borderRadius: '8px', wordBreak: 'break-word' }}>\n+        <strong style={{ color: '#6a1b9a' }}>Tu Voz (Prompt para Gemini):</strong>\n+        <p style={{ color: '#4a148c', fontStyle: recognizedText ? 'normal' : 'italic' }}>\n+            {recognizedText || 'El texto que digas aparecerá aquí después de hablar...'}\n+        </p>\n       </div>\n \n-      {recognizedText && ( // Mostrar el botón de limpiar solo si hay texto\n-          <button\n-            onClick={() => { setRecognizedText(''); setError(''); }} // Limpiar texto y errores\n-            style={{ marginTop: '15px', padding: '8px 15px', cursor: 'pointer', border: '1px solid #ccc', borderRadius: '5px', backgroundColor: '#eee' }}\n-          >\n-            Limpiar Texto\n-          </button>\n-      )}\n+      {/* Indicador de carga de Gemini */}\n+       {isLoadingGemini && (\n+           <p style={{ marginTop: '15px', color: '#4a148c', fontWeight: 'bold', textAlign: 'center' }}>\n+               Enviando a Gemini, esperando respuesta... ⏳\n+           </p>\n+       )}\n+\n+      {/* Área para mostrar la respuesta de Gemini */}\n+      <div style={{ marginTop: '20px', padding: '15px', border: '2px solid #4a148c', minHeight: '120px', backgroundColor: '#ede7f6', borderRadius: '8px', wordBreak: 'break-word' }}>\n+        <strong style={{ color: '#4a148c' }}>Respuesta de Gemini:</strong>\n+        <p style={{ color: '#311b92', fontStyle: geminiResponse || geminiError ? 'normal' : 'italic' }}>\n+            {geminiResponse || geminiError || 'La respuesta de Gemini aparecerá aquí...'}\n+        </p>\n+      </div>\n+\n+       {/* Mostrar errores de Gemini */}\n+       {geminiError && (\n+           <p style={{ color: '#d32f2f', fontWeight: 'bold', marginTop: '15px', padding: '10px', backgroundColor: '#ffebee', borderRadius: '5px' }}>Error de Gemini: {geminiError}</p>\n+       )}\n+\n+      {/* Botón para limpiar el chat */}\n+       {(recognizedText || geminiResponse || voiceError || geminiError) && (\n+           <button\n+             onClick={() => {\n+                 setRecognizedText('');\n+                 setGeminiResponse('');\n+                 setVoiceError('');\n+                 setGeminiError('');\n+             }}\n+             style={{ marginTop: '25px', padding: '10px 20px', cursor: 'pointer', border: 'none', borderRadius: '5px', backgroundColor: '#ab47bc', color: 'white', fontSize: '1em', fontWeight: 'bold', display: 'block', margin: '0 auto' }}\n+           >\n+             Limpiar Chat\n+           </button>\n+       )}\n+\n+       {/* ADVERTENCIA DE SEGURIDAD EN EL FRONTEND */}\n+       <div style={{ color: '#e65100', backgroundColor: '#fff3e0', borderColor: '#ffcc80', padding: '15px', border: '1px solid', borderRadius: '8px', marginTop: '25px', fontSize: '0.9em' }}>\n+           <p style={{ fontWeight: 'bold' }}>⚠️ ADVERTENCIA DE SEGURIDAD (Solo Desarrollo):</p>\n+           <p>Tu clave de API de Gemini está en el código frontend. Esto NO es seguro para producción.</p>\n+           <p>Para producción, envía el texto reconocido a un **backend** seguro que realice la llamada a la API de Gemini con tu clave.</p>\n+       </div>\n+\n     </div>\n   );\n };\n \n-export default SpeechToTextPTT;\n+export default VoiceChatWithGemini;\n\\ No newline at end of file\n"
                },
                {
                    "date": 1746064434853,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -4,9 +4,9 @@\n \n // --- ¡¡¡ ADVERTENCIA DE SEGURIDAD !!! ---\n // !!! NO PONGAS TU CLAVE DE API DIRECTAMENTE AQUÍ EN CÓDIGO PARA PRODUCCIÓN !!!\n // Esto es solo para demostración. Para producción, la llamada a la API debe hacerse desde un BACKEND SEGURO.\n-const API_KEY = \"REEMPLAZA_ESTO_CON_TU_API_KEY_REAL\"; // <-- ¡PON TU CLAVE AQUÍ PARA PROBAR!\n+const API_KEY = \"AIzaSyClAldN4Lvq3HjK1MgogyFdMzitzAqAkXM\"\n \n \n // --- Verifica si la Web Speech API está disponible ---\n const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n"
                },
                {
                    "date": 1746064578315,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -29,9 +29,9 @@\n   const isGeminiCallingRef = useRef(false); // Flag para evitar múltiples llamadas a Gemini a la vez\n \n \n   // --- Configuración de Gemini (similar a tu código Python) ---\n-   const MODEL_NAME = 'gemini-1.5-flash-latest'; // El modelo rápido\n+   const MODEL_NAME = 'gemini-2.0-flash'; // El modelo rápido\n    const generationConfig = {\n        // max_output_tokens se omite, confiamos en el prefijo del prompt para la brevedad\n        \"temperature\": 0.5, // Temperatura baja para respuestas directas\n    };\n"
                },
                {
                    "date": 1746064763572,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -78,9 +78,10 @@\n         // Procesar el stream de respuesta\n         let responseText = '';\n         for await (const chunk of result.stream) {\n             // El chunk.text contiene la parte de la respuesta\n-             const chunkText = chunk.text || ''; // Manejar casos donde chunk.text podría ser undefined/null\n+             const chunkText = chunk.text() || ''; // Manejar casos donde chunk.text podría ser undefined/null\n+             \n              responseText += chunkText;\n              setGeminiResponse(prev => prev + chunkText); // Añadir incrementalmente al estado\n              // Opcional: Añadir un pequeño retardo para simular un stream más lento si quieres\n              // await new Promise(resolve => setTimeout(resolve, 5));\n"
                },
                {
                    "date": 1746064965502,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -171,50 +171,72 @@\n     recognitionRef.current = recognition;\n \n \n     // --- Handlers de Eventos del Teclado (en la ventana global) ---\n-    const handleKeyDown = (event) => {\n-      // Iniciar reconocimiento solo si es la tecla Enter y no la estamos manteniendo ya\n-      if (event.key === 'Enter' && !isHoldingEnter.current) {\n-        isHoldingEnter.current = true; // Marcar Enter como presionado\n-        // Limpiar estados anteriores al iniciar una nueva interacción\n-        setRecognizedText('');\n-        setGeminiResponse('');\n-        setVoiceError('');\n-        setGeminiError('');\n+    // --- Handlers de Eventos del Teclado (en la ventana global) ---\n+  const handleKeyDown = (event) => {\n+    // Solo procesar si es la tecla Enter Y no la estamos manteniendo ya presionada (evita procesar las repeticiones de tecla)\n+    if (event.key === 'Enter' && !isHoldingEnter.current) {\n+      console.log('Tecla Enter presionada (primera pulsación detectada).');\n+      isHoldingEnter.current = true; // Marcamos inmediatamente que Enter está presionado\n \n-        try {\n-           // Abortar cualquier sesión de reconocimiento previa que pudiera estar activa o pendiente\n-           if(recognitionRef.current && (recognitionRef.current.recognizing || isListening)) {\n-               recognitionRef.current.abort(); // Abortar detiene inmediatamente y dispara 'onend'\n-           }\n-           // Iniciar el reconocimiento de voz\n-           recognitionRef.current.start();\n-        } catch (e) {\n-           console.error(\"Error al intentar iniciar el reconocimiento de voz:\", e);\n-           setIsListening(false);\n-           isHoldingEnter.current = false;\n-           setVoiceError(\"Error al iniciar el micrófono. ¿Permiso denegado o no soportado?\");\n-        }\n-        // Opcional: event.preventDefault(); si quieres evitar el comportamiento por defecto de Enter (ej: enviar formularios)\n+      // *** VERIFICACIÓN CLAVE: Solo intentar iniciar si la API está en estado 'idle' ***\n+      if (recognitionRef.current && recognitionRef.current.state === 'idle') {\n+          console.log('La API de reconocimiento de voz está inactiva. Intentando iniciar...');\n+          // Limpiar estados anteriores al iniciar una nueva interacción\n+          setRecognizedText('');\n+          setGeminiResponse('');\n+          setError('');\n+          setVoiceError('');\n+          setGeminiError('');\n+          setIsLoadingGemini(false); // Asegurarse de que no muestra \"Pensando...\" del intento anterior\n+\n+          try {\n+             // No necesitamos abort() aquí si ya verificamos state === 'idle',\n+             // ya que 'idle' significa que ya está detenido y listo para empezar.\n+             recognitionRef.current.start();\n+          } catch (e) {\n+             console.error(\"Error al intentar iniciar el reconocimiento de voz:\", e);\n+             setIsListening(false);\n+             isHoldingEnter.current = false; // Resetear flag si falla el inicio\n+             setVoiceError(\"Error al iniciar el micrófono.\");\n+             isGeminiCallingRef.current = false; // También resetear Gemini flag si falla\n+          }\n+      } else if (recognitionRef.current) {\n+           // Si no está idle, significa que está en otro estado (listening, stopping, error).\n+           // En este caso, no hacemos nada en esta pulsación, ya que el flag isHoldingEnter\n+           // evitará que este bloque se ejecute en las repeticiones rápidas.\n+            console.log(`Tecla Enter presionada (primera pulsación), pero API no está inactiva (estado: ${recognitionRef.current.state}). Saltando inicio.`);\n+      } else {\n+           // recognitionRef.current no existe (API no soportada)\n+            console.log(\"API de reconocimiento de voz no disponible.\");\n+            isHoldingEnter.current = false; // Resetear flag ya que no podemos hacer nada\n       }\n+      // Las pulsaciones subsiguientes de Enter MIENTRAS SE MANTIENE PRESIONADO son ignoradas\n+      // por la condición `!isHoldingEnter.current` al principio de esta función.\n     };\n+  };\n \n-    const handleKeyUp = (event) => {\n-      // Detener reconocimiento solo si es la tecla Enter y la estábamos manteniendo\n-      if (event.key === 'Enter' && isHoldingEnter.current) {\n+  // La función handleKeyUp se mantiene igual\n+  const handleKeyUp = (event) => {\n+    // Solo procesar si es la tecla Enter Y la estábamos manteniendo presionada\n+    if (event.key === 'Enter' && isHoldingEnter.current) {\n+        console.log('Tecla Enter soltada.');\n         isHoldingEnter.current = false; // Marcar Enter como soltado\n-        // Llamar a stop() para detener el reconocimiento. Esto dispara el evento 'onend'.\n-        // Solo llamar stop si estaba escuchando para evitar errores.\n-        if (recognitionRef.current && isListening) {\n+\n+        // Si el reconocimiento estaba en el estado 'listening', lo detenemos.\n+        // El evento 'onend' se encargará de actualizar el estado isListening.\n+        if (recognitionRef.current && recognitionRef.current.state === 'listening') {\n+             console.log('Deteniendo reconocimiento de voz...');\n              recognitionRef.current.stop();\n         } else {\n-             // Si soltó Enter pero no estaba escuchando (quizás por un error),\n-             // solo asegurar que el estado y el flag estén correctos.\n-             setIsListening(false);\n+             // Si soltó Enter pero la API no estaba escuchando (quizás por un error o ya se detuvo),\n+             // solo asegurarnos de que el estado isListening es falso.\n+             console.log(`Tecla Enter soltada, pero API no estaba escuchando (estado: ${recognitionRef.current ? recognitionRef.current.state : 'N/A'}).`);\n+             setIsListening(false); // Asegurarse de que el estado local está sincronizado\n         }\n-      }\n-    };\n+    }\n+  };\n \n     // Añadir los listeners de eventos al objeto global 'window'\n     window.addEventListener('keydown', handleKeyDown);\n     window.addEventListener('keyup', handleKeyUp);\n"
                },
                {
                    "date": 1746065007427,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -171,72 +171,50 @@\n     recognitionRef.current = recognition;\n \n \n     // --- Handlers de Eventos del Teclado (en la ventana global) ---\n-    // --- Handlers de Eventos del Teclado (en la ventana global) ---\n-  const handleKeyDown = (event) => {\n-    // Solo procesar si es la tecla Enter Y no la estamos manteniendo ya presionada (evita procesar las repeticiones de tecla)\n-    if (event.key === 'Enter' && !isHoldingEnter.current) {\n-      console.log('Tecla Enter presionada (primera pulsación detectada).');\n-      isHoldingEnter.current = true; // Marcamos inmediatamente que Enter está presionado\n+    const handleKeyDown = (event) => {\n+      // Iniciar reconocimiento solo si es la tecla Enter y no la estamos manteniendo ya\n+      if (event.key === 'Enter' && !isHoldingEnter.current) {\n+        isHoldingEnter.current = true; // Marcar Enter como presionado\n+        // Limpiar estados anteriores al iniciar una nueva interacción\n+        setRecognizedText('');\n+        setGeminiResponse('');\n+        setVoiceError('');\n+        setGeminiError('');\n \n-      // *** VERIFICACIÓN CLAVE: Solo intentar iniciar si la API está en estado 'idle' ***\n-      if (recognitionRef.current && recognitionRef.current.state === 'idle') {\n-          console.log('La API de reconocimiento de voz está inactiva. Intentando iniciar...');\n-          // Limpiar estados anteriores al iniciar una nueva interacción\n-          setRecognizedText('');\n-          setGeminiResponse('');\n-          setError('');\n-          setVoiceError('');\n-          setGeminiError('');\n-          setIsLoadingGemini(false); // Asegurarse de que no muestra \"Pensando...\" del intento anterior\n-\n-          try {\n-             // No necesitamos abort() aquí si ya verificamos state === 'idle',\n-             // ya que 'idle' significa que ya está detenido y listo para empezar.\n-             recognitionRef.current.start();\n-          } catch (e) {\n-             console.error(\"Error al intentar iniciar el reconocimiento de voz:\", e);\n-             setIsListening(false);\n-             isHoldingEnter.current = false; // Resetear flag si falla el inicio\n-             setVoiceError(\"Error al iniciar el micrófono.\");\n-             isGeminiCallingRef.current = false; // También resetear Gemini flag si falla\n-          }\n-      } else if (recognitionRef.current) {\n-           // Si no está idle, significa que está en otro estado (listening, stopping, error).\n-           // En este caso, no hacemos nada en esta pulsación, ya que el flag isHoldingEnter\n-           // evitará que este bloque se ejecute en las repeticiones rápidas.\n-            console.log(`Tecla Enter presionada (primera pulsación), pero API no está inactiva (estado: ${recognitionRef.current.state}). Saltando inicio.`);\n-      } else {\n-           // recognitionRef.current no existe (API no soportada)\n-            console.log(\"API de reconocimiento de voz no disponible.\");\n-            isHoldingEnter.current = false; // Resetear flag ya que no podemos hacer nada\n+        try {\n+           // Abortar cualquier sesión de reconocimiento previa que pudiera estar activa o pendiente\n+           if(recognitionRef.current && (recognitionRef.current.recognizing || isListening)) {\n+               recognitionRef.current.abort(); // Abortar detiene inmediatamente y dispara 'onend'\n+           }\n+           // Iniciar el reconocimiento de voz\n+           recognitionRef.current.start();\n+        } catch (e) {\n+           console.error(\"Error al intentar iniciar el reconocimiento de voz:\", e);\n+           setIsListening(false);\n+           isHoldingEnter.current = false;\n+           setVoiceError(\"Error al iniciar el micrófono. ¿Permiso denegado o no soportado?\");\n+        }\n+        // Opcional: event.preventDefault(); si quieres evitar el comportamiento por defecto de Enter (ej: enviar formularios)\n       }\n-      // Las pulsaciones subsiguientes de Enter MIENTRAS SE MANTIENE PRESIONADO son ignoradas\n-      // por la condición `!isHoldingEnter.current` al principio de esta función.\n     };\n-  };\n \n-  // La función handleKeyUp se mantiene igual\n-  const handleKeyUp = (event) => {\n-    // Solo procesar si es la tecla Enter Y la estábamos manteniendo presionada\n-    if (event.key === 'Enter' && isHoldingEnter.current) {\n-        console.log('Tecla Enter soltada.');\n+    const handleKeyUp = (event) => {\n+      // Detener reconocimiento solo si es la tecla Enter y la estábamos manteniendo\n+      if (event.key === 'Enter' && isHoldingEnter.current) {\n         isHoldingEnter.current = false; // Marcar Enter como soltado\n-\n-        // Si el reconocimiento estaba en el estado 'listening', lo detenemos.\n-        // El evento 'onend' se encargará de actualizar el estado isListening.\n-        if (recognitionRef.current && recognitionRef.current.state === 'listening') {\n-             console.log('Deteniendo reconocimiento de voz...');\n+        // Llamar a stop() para detener el reconocimiento. Esto dispara el evento 'onend'.\n+        // Solo llamar stop si estaba escuchando para evitar errores.\n+        if (recognitionRef.current && isListening) {\n              recognitionRef.current.stop();\n         } else {\n-             // Si soltó Enter pero la API no estaba escuchando (quizás por un error o ya se detuvo),\n-             // solo asegurarnos de que el estado isListening es falso.\n-             console.log(`Tecla Enter soltada, pero API no estaba escuchando (estado: ${recognitionRef.current ? recognitionRef.current.state : 'N/A'}).`);\n-             setIsListening(false); // Asegurarse de que el estado local está sincronizado\n+             // Si soltó Enter pero no estaba escuchando (quizás por un error),\n+             // solo asegurar que el estado y el flag estén correctos.\n+             setIsListening(false);\n         }\n-    }\n-  };\n+      }\n+    };\n \n     // Añadir los listeners de eventos al objeto global 'window'\n     window.addEventListener('keydown', handleKeyDown);\n     window.addEventListener('keyup', handleKeyUp);\n"
                },
                {
                    "date": 1746065049144,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -171,50 +171,86 @@\n     recognitionRef.current = recognition;\n \n \n     // --- Handlers de Eventos del Teclado (en la ventana global) ---\n-    const handleKeyDown = (event) => {\n-      // Iniciar reconocimiento solo si es la tecla Enter y no la estamos manteniendo ya\n-      if (event.key === 'Enter' && !isHoldingEnter.current) {\n-        isHoldingEnter.current = true; // Marcar Enter como presionado\n-        // Limpiar estados anteriores al iniciar una nueva interacción\n-        setRecognizedText('');\n-        setGeminiResponse('');\n-        setVoiceError('');\n-        setGeminiError('');\n+    // --- Handlers de Eventos del Teclado (en la ventana global) ---\n+  const handleKeyDown = (event) => {\n+    // Solo procesar si es la tecla Enter Y no la estamos manteniendo ya presionada\n+    if (event.key === 'Enter' && !isHoldingEnter.current) {\n+      console.log('Tecla Enter presionada (primera pulsación detectada).');\n+      isHoldingEnter.current = true; // Marcamos inmediatamente que Enter está presionado\n \n-        try {\n-           // Abortar cualquier sesión de reconocimiento previa que pudiera estar activa o pendiente\n-           if(recognitionRef.current && (recognitionRef.current.recognizing || isListening)) {\n-               recognitionRef.current.abort(); // Abortar detiene inmediatamente y dispara 'onend'\n-           }\n-           // Iniciar el reconocimiento de voz\n-           recognitionRef.current.start();\n-        } catch (e) {\n-           console.error(\"Error al intentar iniciar el reconocimiento de voz:\", e);\n-           setIsListening(false);\n-           isHoldingEnter.current = false;\n-           setVoiceError(\"Error al iniciar el micrófono. ¿Permiso denegado o no soportado?\");\n-        }\n-        // Opcional: event.preventDefault(); si quieres evitar el comportamiento por defecto de Enter (ej: enviar formularios)\n+      // Verificar si la instancia de la API existe Y NO está ya escuchando o iniciando\n+      // Usamos optional chaining (?.) para seguridad si recognitionRef.current aún no está listo\n+      if (recognitionRef.current && recognitionRef.current.state !== 'listening' && recognitionRef.current.state !== 'starting') {\n+          // Aquí 'recognitionRef.current.state' podría ser 'idle', undefined, 'stopped', 'aborting'...\n+          // Siempre y cuando no esté 'listening' o 'starting', podemos intentar iniciar.\n+          console.log(`La API de reconocimiento de voz está en estado '${recognitionRef.current.state}'. Intentando iniciar...`);\n+\n+          // Limpiar estados anteriores para una nueva interacción\n+          setRecognizedText('');\n+          setGeminiResponse('');\n+          setError('');\n+          setVoiceError('');\n+          setGeminiError('');\n+          setIsLoadingGemini(false); // Asegurarse de que el indicador de carga de Gemini no se quede pegado\n+\n+          try {\n+             // Aunque verificamos el estado, llamar a abort() justo antes de start()\n+             // es una estrategia defensiva común para asegurar que cualquier proceso anterior\n+             // que pudiera estar finalizando se detenga completamente.\n+             if (recognitionRef.current.state !== 'idle') { // Solo abortar si no está ya idle\n+                 recognitionRef.current.abort();\n+                 console.log('Abortando sesión previa...');\n+             }\n+\n+             // Iniciar el reconocimiento de voz\n+             recognitionRef.current.start();\n+\n+          } catch (e) {\n+             console.error(\"Error al intentar iniciar el reconocimiento de voz:\", e);\n+             setIsListening(false);\n+             isHoldingEnter.current = false; // Resetear flag si falla el inicio\n+             setVoiceError(`Error al iniciar el micrófono: ${e.message}.`);\n+             isGeminiCallingRef.current = false; // Resetear Gemini flag si falla\n+          }\n+      } else if (recognitionRef.current) {\n+           // Si está escuchando o iniciando, saltamos el inicio para evitar errores.\n+           console.log(`Tecla Enter presionada (primera pulsación), pero API está ocupada (estado: ${recognitionRef.current.state}). Saltando inicio.`);\n+           // El flag isHoldingEnter ya está en true, lo que previene las repeticiones rápidas.\n+           // El usuario tendrá que soltar y presionar de nuevo.\n+      } else {\n+           // recognitionRef.current aún no existe (API no soportada o componente no listo).\n+            console.log(\"API de reconocimiento de voz no disponible o no inicializada.\");\n+            isHoldingEnter.current = false; // Resetear flag\n+            setVoiceError(\"API de reconocimiento de voz no soportada o no lista.\");\n       }\n+      // Las pulsaciones subsiguientes de Enter MIENTRAS SE MANTIENE PRESIONADO son ignoradas\n+      // por la condición `!isHoldingEnter.current` al principio de esta función.\n     };\n+  };\n \n-    const handleKeyUp = (event) => {\n-      // Detener reconocimiento solo si es la tecla Enter y la estábamos manteniendo\n-      if (event.key === 'Enter' && isHoldingEnter.current) {\n+  // --- Handlers de Eventos del Teclado (en la ventana global) ---\n+  const handleKeyUp = (event) => {\n+    // Solo procesar si es la tecla Enter Y la estábamos manteniendo presionada\n+    if (event.key === 'Enter' && isHoldingEnter.current) {\n+        console.log('Tecla Enter soltada.');\n         isHoldingEnter.current = false; // Marcar Enter como soltado\n-        // Llamar a stop() para detener el reconocimiento. Esto dispara el evento 'onend'.\n-        // Solo llamar stop si estaba escuchando para evitar errores.\n-        if (recognitionRef.current && isListening) {\n+\n+        // Si el reconocimiento estaba en el estado 'listening' o 'starting', lo detenemos.\n+        // El evento 'onend' se encargará de actualizar el estado isListening.\n+        if (recognitionRef.current && (recognitionRef.current.state === 'listening' || recognitionRef.current.state === 'starting')) {\n+             console.log(`API en estado ${recognitionRef.current.state}. Deteniendo reconocimiento de voz...`);\n              recognitionRef.current.stop();\n         } else {\n-             // Si soltó Enter pero no estaba escuchando (quizás por un error),\n-             // solo asegurar que el estado y el flag estén correctos.\n-             setIsListening(false);\n+             // Si soltó Enter pero la API no estaba escuchando/iniciando (quizás por un error, ya se detuvo, o estaba idle),\n+             // solo asegurarnos de que el estado isListening es falso.\n+             console.log(`Tecla Enter soltada, pero API no estaba escuchando ni iniciando (estado: ${recognitionRef.current ? recognitionRef.current.state : 'N/A'}).`);\n+             setIsListening(false); // Asegurar que el estado local está sincronizado\n+             isGeminiCallingRef.current = false; // Asegurar que el flag de Gemini también se resetea si algo salió mal\n         }\n-      }\n-    };\n+    }\n+  };\n \n     // Añadir los listeners de eventos al objeto global 'window'\n     window.addEventListener('keydown', handleKeyDown);\n     window.addEventListener('keyup', handleKeyUp);\n"
                },
                {
                    "date": 1746065078017,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -171,86 +171,50 @@\n     recognitionRef.current = recognition;\n \n \n     // --- Handlers de Eventos del Teclado (en la ventana global) ---\n-    // --- Handlers de Eventos del Teclado (en la ventana global) ---\n-  const handleKeyDown = (event) => {\n-    // Solo procesar si es la tecla Enter Y no la estamos manteniendo ya presionada\n-    if (event.key === 'Enter' && !isHoldingEnter.current) {\n-      console.log('Tecla Enter presionada (primera pulsación detectada).');\n-      isHoldingEnter.current = true; // Marcamos inmediatamente que Enter está presionado\n+    const handleKeyDown = (event) => {\n+      // Iniciar reconocimiento solo si es la tecla Enter y no la estamos manteniendo ya\n+      if (event.key === 'Enter' && !isHoldingEnter.current) {\n+        isHoldingEnter.current = true; // Marcar Enter como presionado\n+        // Limpiar estados anteriores al iniciar una nueva interacción\n+        setRecognizedText('');\n+        setGeminiResponse('');\n+        setVoiceError('');\n+        setGeminiError('');\n \n-      // Verificar si la instancia de la API existe Y NO está ya escuchando o iniciando\n-      // Usamos optional chaining (?.) para seguridad si recognitionRef.current aún no está listo\n-      if (recognitionRef.current && recognitionRef.current.state !== 'listening' && recognitionRef.current.state !== 'starting') {\n-          // Aquí 'recognitionRef.current.state' podría ser 'idle', undefined, 'stopped', 'aborting'...\n-          // Siempre y cuando no esté 'listening' o 'starting', podemos intentar iniciar.\n-          console.log(`La API de reconocimiento de voz está en estado '${recognitionRef.current.state}'. Intentando iniciar...`);\n-\n-          // Limpiar estados anteriores para una nueva interacción\n-          setRecognizedText('');\n-          setGeminiResponse('');\n-          setError('');\n-          setVoiceError('');\n-          setGeminiError('');\n-          setIsLoadingGemini(false); // Asegurarse de que el indicador de carga de Gemini no se quede pegado\n-\n-          try {\n-             // Aunque verificamos el estado, llamar a abort() justo antes de start()\n-             // es una estrategia defensiva común para asegurar que cualquier proceso anterior\n-             // que pudiera estar finalizando se detenga completamente.\n-             if (recognitionRef.current.state !== 'idle') { // Solo abortar si no está ya idle\n-                 recognitionRef.current.abort();\n-                 console.log('Abortando sesión previa...');\n-             }\n-\n-             // Iniciar el reconocimiento de voz\n-             recognitionRef.current.start();\n-\n-          } catch (e) {\n-             console.error(\"Error al intentar iniciar el reconocimiento de voz:\", e);\n-             setIsListening(false);\n-             isHoldingEnter.current = false; // Resetear flag si falla el inicio\n-             setVoiceError(`Error al iniciar el micrófono: ${e.message}.`);\n-             isGeminiCallingRef.current = false; // Resetear Gemini flag si falla\n-          }\n-      } else if (recognitionRef.current) {\n-           // Si está escuchando o iniciando, saltamos el inicio para evitar errores.\n-           console.log(`Tecla Enter presionada (primera pulsación), pero API está ocupada (estado: ${recognitionRef.current.state}). Saltando inicio.`);\n-           // El flag isHoldingEnter ya está en true, lo que previene las repeticiones rápidas.\n-           // El usuario tendrá que soltar y presionar de nuevo.\n-      } else {\n-           // recognitionRef.current aún no existe (API no soportada o componente no listo).\n-            console.log(\"API de reconocimiento de voz no disponible o no inicializada.\");\n-            isHoldingEnter.current = false; // Resetear flag\n-            setVoiceError(\"API de reconocimiento de voz no soportada o no lista.\");\n+        try {\n+           // Abortar cualquier sesión de reconocimiento previa que pudiera estar activa o pendiente\n+           if(recognitionRef.current && (recognitionRef.current.recognizing || isListening)) {\n+               recognitionRef.current.abort(); // Abortar detiene inmediatamente y dispara 'onend'\n+           }\n+           // Iniciar el reconocimiento de voz\n+           recognitionRef.current.start();\n+        } catch (e) {\n+           console.error(\"Error al intentar iniciar el reconocimiento de voz:\", e);\n+           setIsListening(false);\n+           isHoldingEnter.current = false;\n+           setVoiceError(\"Error al iniciar el micrófono. ¿Permiso denegado o no soportado?\");\n+        }\n+        // Opcional: event.preventDefault(); si quieres evitar el comportamiento por defecto de Enter (ej: enviar formularios)\n       }\n-      // Las pulsaciones subsiguientes de Enter MIENTRAS SE MANTIENE PRESIONADO son ignoradas\n-      // por la condición `!isHoldingEnter.current` al principio de esta función.\n     };\n-  };\n \n-  // --- Handlers de Eventos del Teclado (en la ventana global) ---\n-  const handleKeyUp = (event) => {\n-    // Solo procesar si es la tecla Enter Y la estábamos manteniendo presionada\n-    if (event.key === 'Enter' && isHoldingEnter.current) {\n-        console.log('Tecla Enter soltada.');\n+    const handleKeyUp = (event) => {\n+      // Detener reconocimiento solo si es la tecla Enter y la estábamos manteniendo\n+      if (event.key === 'Enter' && isHoldingEnter.current) {\n         isHoldingEnter.current = false; // Marcar Enter como soltado\n-\n-        // Si el reconocimiento estaba en el estado 'listening' o 'starting', lo detenemos.\n-        // El evento 'onend' se encargará de actualizar el estado isListening.\n-        if (recognitionRef.current && (recognitionRef.current.state === 'listening' || recognitionRef.current.state === 'starting')) {\n-             console.log(`API en estado ${recognitionRef.current.state}. Deteniendo reconocimiento de voz...`);\n+        // Llamar a stop() para detener el reconocimiento. Esto dispara el evento 'onend'.\n+        // Solo llamar stop si estaba escuchando para evitar errores.\n+        if (recognitionRef.current && isListening) {\n              recognitionRef.current.stop();\n         } else {\n-             // Si soltó Enter pero la API no estaba escuchando/iniciando (quizás por un error, ya se detuvo, o estaba idle),\n-             // solo asegurarnos de que el estado isListening es falso.\n-             console.log(`Tecla Enter soltada, pero API no estaba escuchando ni iniciando (estado: ${recognitionRef.current ? recognitionRef.current.state : 'N/A'}).`);\n-             setIsListening(false); // Asegurar que el estado local está sincronizado\n-             isGeminiCallingRef.current = false; // Asegurar que el flag de Gemini también se resetea si algo salió mal\n+             // Si soltó Enter pero no estaba escuchando (quizás por un error),\n+             // solo asegurar que el estado y el flag estén correctos.\n+             setIsListening(false);\n         }\n-    }\n-  };\n+      }\n+    };\n \n     // Añadir los listeners de eventos al objeto global 'window'\n     window.addEventListener('keydown', handleKeyDown);\n     window.addEventListener('keyup', handleKeyUp);\n"
                },
                {
                    "date": 1746114294020,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,106 +1,19 @@\n import React, { useState, useEffect, useRef } from 'react';\n-// Importa la librería cliente oficial de Google Generative AI para JS\n-import { GoogleGenerativeAI } from '@google/generative-ai';\n \n-// --- ¡¡¡ ADVERTENCIA DE SEGURIDAD !!! ---\n-// !!! NO PONGAS TU CLAVE DE API DIRECTAMENTE AQUÍ EN CÓDIGO PARA PRODUCCIÓN !!!\n-// Esto es solo para demostración. Para producción, la llamada a la API debe hacerse desde un BACKEND SEGURO.\n-const API_KEY = \"AIzaSyClAldN4Lvq3HjK1MgogyFdMzitzAqAkXM\"\n-\n-\n // --- Verifica si la Web Speech API está disponible ---\n const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n \n-\n-const VoiceChatWithGemini = () => {\n+const VoiceRecognition = ({ onTextRecognized, responseData, isLoadingResponse, responseError }) => {\n   // --- Estados ---\n   const [recognizedText, setRecognizedText] = useState(''); // Texto capturado por voz\n-  const [geminiResponse, setGeminiResponse] = useState(''); // Respuesta de Gemini\n   const [isListening, setIsListening] = useState(false); // Estado del micrófono\n-  const [isLoadingGemini, setIsLoadingGemini] = useState(false); // Estado de la llamada a Gemini\n   const [voiceError, setVoiceError] = useState(''); // Errores del reconocimiento de voz\n-  const [geminiError, setGeminiError] = useState(''); // Errores de la API de Gemini\n \n   // --- Referencias (persisten entre renders sin causar re-render) ---\n   const recognitionRef = useRef(null); // Instancia del objeto SpeechRecognition\n   const isHoldingEnter = useRef(false); // Flag para saber si Enter está presionado\n-  const genAiRef = useRef(null); // Instancia de GoogleGenerativeAI client\n-  const modelRef = useRef(null); // Instancia del modelo Gemini\n-  const isGeminiCallingRef = useRef(false); // Flag para evitar múltiples llamadas a Gemini a la vez\n \n-\n-  // --- Configuración de Gemini (similar a tu código Python) ---\n-   const MODEL_NAME = 'gemini-2.0-flash'; // El modelo rápido\n-   const generationConfig = {\n-       // max_output_tokens se omite, confiamos en el prefijo del prompt para la brevedad\n-       \"temperature\": 0.5, // Temperatura baja para respuestas directas\n-   };\n-   // Prefijo para instruir al modelo a ser breve (similar a tu código Python)\n-   const PROMPT_PREFIX = \"Responde de forma muy breve a lo siguiente: \";\n-\n-\n-  // --- Función para enviar el texto reconocido a Gemini ---\n-  const sendToGemini = async (text) => {\n-    // Evitar enviar prompts vacíos o si ya hay una llamada en curso\n-    if (!text.trim() || isLoadingGemini || isGeminiCallingRef.current) {\n-      console.log(\"Saltando llamada a Gemini: texto vacío o ya hay una llamada en progreso.\");\n-      return;\n-    }\n-\n-    setIsLoadingGemini(true);\n-    isGeminiCallingRef.current = true; // Marcar que una llamada a Gemini está activa\n-    setGeminiResponse(''); // Limpiar la respuesta anterior\n-    setGeminiError(''); // Limpiar errores anteriores\n-\n-    // --- Iniciar la llamada a la API de Gemini ---\n-    try {\n-        // Inicializar el cliente y el modelo si no existen ya (usando refs)\n-        if (!genAiRef.current) {\n-            if (!API_KEY || API_KEY === \"REEMPLAZA_ESTO_CON_TU_API_KEY_REAL\") {\n-                 throw new Error(\"API Key de Gemini no configurada correctamente.\");\n-            }\n-            genAiRef.current = new GoogleGenerativeAI(API_KEY);\n-        }\n-        if (!modelRef.current) {\n-             modelRef.current = genAiRef.current.getGenerativeModel({\n-                 model: MODEL_NAME,\n-                 generationConfig: generationConfig,\n-             });\n-        }\n-\n-        // Construir el prompt completo con el prefijo para brevedad\n-        const fullPrompt = PROMPT_PREFIX + text;\n-        console.log(\"Enviando a Gemini:\", fullPrompt);\n-\n-        // Llamar a la API usando streaming para ver la respuesta a medida que llega\n-        const result = await modelRef.current.generateContentStream(fullPrompt);\n-\n-        // Procesar el stream de respuesta\n-        let responseText = '';\n-        for await (const chunk of result.stream) {\n-            // El chunk.text contiene la parte de la respuesta\n-             const chunkText = chunk.text() || ''; // Manejar casos donde chunk.text podría ser undefined/null\n-             \n-             responseText += chunkText;\n-             setGeminiResponse(prev => prev + chunkText); // Añadir incrementalmente al estado\n-             // Opcional: Añadir un pequeño retardo para simular un stream más lento si quieres\n-             // await new Promise(resolve => setTimeout(resolve, 5));\n-        }\n-\n-         console.log(\"Respuesta de Gemini finalizada.\");\n-\n-    } catch (e) {\n-      console.error(\"Error llamando a la API de Gemini:\", e);\n-      setGeminiError(`Error de Gemini: ${e.message || 'Desconocido'}. Verifica tu API key y la consola.`);\n-      setGeminiResponse(''); // Limpiar cualquier respuesta parcial en caso de error\n-    } finally {\n-      setIsLoadingGemini(false);\n-      isGeminiCallingRef.current = false; // Resetear el flag al finalizar la llamada\n-    }\n-  };\n-\n-\n   // --- useEffect para la Configuración del Reconocimiento de Voz y Eventos ---\n   useEffect(() => {\n     // Si la Web Speech API no está disponible, mostrar error y salir del efecto\n     if (!SpeechRecognition) {\n@@ -121,28 +34,24 @@\n        console.log('Reconocimiento de voz iniciado.');\n     };\n \n     recognition.onresult = (event) => {\n-      // Este evento se dispara cuando se reconoce una porción de voz final (gracias a interimResults: false)\n+      // Este evento se dispara cuando se reconoce una porción de voz final\n       const transcript = event.results[event.results.length - 1][0].transcript;\n       console.log('Resultado de voz final:', transcript);\n       setRecognizedText(transcript); // Almacenar el texto reconocido\n \n-      // --- ¡Paso Clave! Enviar el texto reconocido a Gemini ---\n-      // Disparamos la llamada a Gemini tan pronto como tengamos un resultado final\n-       if (!isGeminiCallingRef.current) { // Solo si no hay ya una llamada a Gemini en curso\n-           sendToGemini(transcript);\n-       } else {\n-           console.log(\"Resultado de voz listo, pero saltando llamada a Gemini porque ya hay una activa.\");\n-       }\n+      // Enviar el texto al componente padre para procesarlo\n+      if (onTextRecognized) {\n+        onTextRecognized(transcript);\n+      }\n     };\n \n     recognition.onerror = (event) => {\n       // Manejar errores de reconocimiento de voz\n       console.error('Error en reconocimiento de voz:', event.error);\n       setIsListening(false); // Detener estado de escucha\n       isHoldingEnter.current = false; // Asegurar que el flag de Enter se resetee\n-      isGeminiCallingRef.current = false; // También resetear el flag de Gemini\n \n       let errorMsg = `Error de voz: ${event.error}`;\n        if (event.error === 'not-allowed') {\n             errorMsg = 'Permiso del micrófono denegado. Por favor, permite el acceso.';\n@@ -158,30 +67,25 @@\n        setRecognizedText(''); // Limpiar texto reconocido en caso de error\n     };\n \n     recognition.onend = () => {\n-      // Este evento se dispara cuando la escucha termina (después de stop() o error/no-speech)\n+      // Este evento se dispara cuando la escucha termina\n       console.log('Reconocimiento de voz finalizado.');\n       setIsListening(false); // Asegurar que el estado de escucha es falso\n       isHoldingEnter.current = false; // Asegurar que el flag de Enter se resetee\n-      // El trigger a Gemini ya ocurrió en onresult si hubo voz, o no ocurrió si hubo error/no-speech.\n-      // No necesitamos llamar a sendToGemini aquí de nuevo a menos que 'onresult' no sea confiable antes de 'onend'.\n     };\n \n     // Guardar la instancia en la referencia para usarla en los handlers de teclado\n     recognitionRef.current = recognition;\n \n-\n     // --- Handlers de Eventos del Teclado (en la ventana global) ---\n     const handleKeyDown = (event) => {\n       // Iniciar reconocimiento solo si es la tecla Enter y no la estamos manteniendo ya\n       if (event.key === 'Enter' && !isHoldingEnter.current) {\n         isHoldingEnter.current = true; // Marcar Enter como presionado\n         // Limpiar estados anteriores al iniciar una nueva interacción\n         setRecognizedText('');\n-        setGeminiResponse('');\n         setVoiceError('');\n-        setGeminiError('');\n \n         try {\n            // Abortar cualquier sesión de reconocimiento previa que pudiera estar activa o pendiente\n            if(recognitionRef.current && (recognitionRef.current.recognizing || isListening)) {\n@@ -194,9 +98,8 @@\n            setIsListening(false);\n            isHoldingEnter.current = false;\n            setVoiceError(\"Error al iniciar el micrófono. ¿Permiso denegado o no soportado?\");\n         }\n-        // Opcional: event.preventDefault(); si quieres evitar el comportamiento por defecto de Enter (ej: enviar formularios)\n       }\n     };\n \n     const handleKeyUp = (event) => {\n@@ -221,28 +124,24 @@\n \n     // --- Función de Limpieza ---\n     // Se ejecuta cuando el componente se desmonta\n     return () => {\n-      console.log('Limpiando componente VoiceChatWithGemini.');\n+      console.log('Limpiando componente VoiceRecognition.');\n       // Remover los listeners de eventos del teclado para evitar fugas de memoria\n       window.removeEventListener('keydown', handleKeyDown);\n       window.removeEventListener('keyup', handleKeyUp);\n \n       // Abortar el reconocimiento de voz si todavía está activo\n       if (recognitionRef.current && (recognitionRef.current.recognizing || isListening)) {\n         recognitionRef.current.abort(); // abort() es más seguro para limpieza rápida\n       }\n-       // No es estrictamente necesario limpiar las refs genAiRef y modelRef,\n-       // ya que contienen objetos JS que serán recolectados por el recolector de basura.\n     };\n+  }, [onTextRecognized]); // Dependencia añadida para ejecutar el efecto cuando cambie la función\n \n-  }, []); // El array vacío [] asegura que este efecto se ejecute solo una vez al montar y se limpie al desmontar.\n-\n-\n   // --- Renderizado del Componente ---\n   return (\n     <div style={{ margin: '20px', padding: '25px', border: '3px solid #4a148c', borderRadius: '15px', fontFamily: 'sans-serif', backgroundColor: '#f3e5f5', boxShadow: '0 4px 8px rgba(0,0,0,0.1)' }}>\n-      <h2 style={{ color: '#4a148c', marginBottom: '20px', textAlign: 'center' }}>🎤 Chat de Voz con Gemini 🤖</h2>\n+      <h2 style={{ color: '#4a148c', marginBottom: '20px', textAlign: 'center' }}>🎤 Reconocimiento de Voz 🤖</h2>\n \n       {/* Indicador de estado del micrófono */}\n       <p style={{ marginBottom: '15px', fontSize: '1.1em', color: '#333' }}>\n         Estado del Micrófono: {isListening ?\n@@ -257,57 +156,50 @@\n       )}\n \n       {/* Área para mostrar el texto reconocido por voz */}\n       <div style={{ marginTop: '15px', padding: '15px', border: '1px dashed #ab47bc', minHeight: '80px', backgroundColor: '#fce4ec', borderRadius: '8px', wordBreak: 'break-word' }}>\n-        <strong style={{ color: '#6a1b9a' }}>Tu Voz (Prompt para Gemini):</strong>\n+        <strong style={{ color: '#6a1b9a' }}>Tu Voz (Prompt para el Asistente):</strong>\n         <p style={{ color: '#4a148c', fontStyle: recognizedText ? 'normal' : 'italic' }}>\n             {recognizedText || 'El texto que digas aparecerá aquí después de hablar...'}\n         </p>\n       </div>\n \n-      {/* Indicador de carga de Gemini */}\n-       {isLoadingGemini && (\n+      {/* Indicador de carga de la respuesta */}\n+       {isLoadingResponse && (\n            <p style={{ marginTop: '15px', color: '#4a148c', fontWeight: 'bold', textAlign: 'center' }}>\n-               Enviando a Gemini, esperando respuesta... ⏳\n+               Enviando consulta, esperando respuesta... ⏳\n            </p>\n        )}\n \n-      {/* Área para mostrar la respuesta de Gemini */}\n+      {/* Área para mostrar la respuesta */}\n       <div style={{ marginTop: '20px', padding: '15px', border: '2px solid #4a148c', minHeight: '120px', backgroundColor: '#ede7f6', borderRadius: '8px', wordBreak: 'break-word' }}>\n-        <strong style={{ color: '#4a148c' }}>Respuesta de Gemini:</strong>\n-        <p style={{ color: '#311b92', fontStyle: geminiResponse || geminiError ? 'normal' : 'italic' }}>\n-            {geminiResponse || geminiError || 'La respuesta de Gemini aparecerá aquí...'}\n+        <strong style={{ color: '#4a148c' }}>Respuesta del Asistente:</strong>\n+        <p style={{ color: '#311b92', fontStyle: responseData || responseError ? 'normal' : 'italic' }}>\n+            {responseData || responseError || 'La respuesta aparecerá aquí...'}\n         </p>\n       </div>\n \n-       {/* Mostrar errores de Gemini */}\n-       {geminiError && (\n-           <p style={{ color: '#d32f2f', fontWeight: 'bold', marginTop: '15px', padding: '10px', backgroundColor: '#ffebee', borderRadius: '5px' }}>Error de Gemini: {geminiError}</p>\n+       {/* Mostrar errores de respuesta */}\n+       {responseError && (\n+           <p style={{ color: '#d32f2f', fontWeight: 'bold', marginTop: '15px', padding: '10px', backgroundColor: '#ffebee', borderRadius: '5px' }}>Error: {responseError}</p>\n        )}\n \n       {/* Botón para limpiar el chat */}\n-       {(recognizedText || geminiResponse || voiceError || geminiError) && (\n+       {(recognizedText || responseData || voiceError || responseError) && (\n            <button\n              onClick={() => {\n                  setRecognizedText('');\n-                 setGeminiResponse('');\n                  setVoiceError('');\n-                 setGeminiError('');\n+                 if (onTextRecognized) {\n+                     onTextRecognized('', true); // Segundo parámetro indica limpieza\n+                 }\n              }}\n              style={{ marginTop: '25px', padding: '10px 20px', cursor: 'pointer', border: 'none', borderRadius: '5px', backgroundColor: '#ab47bc', color: 'white', fontSize: '1em', fontWeight: 'bold', display: 'block', margin: '0 auto' }}\n            >\n              Limpiar Chat\n\\ No newline at end of file\n            </button>\n        )}\n-\n-       {/* ADVERTENCIA DE SEGURIDAD EN EL FRONTEND */}\n-       <div style={{ color: '#e65100', backgroundColor: '#fff3e0', borderColor: '#ffcc80', padding: '15px', border: '1px solid', borderRadius: '8px', marginTop: '25px', fontSize: '0.9em' }}>\n-           <p style={{ fontWeight: 'bold' }}>⚠️ ADVERTENCIA DE SEGURIDAD (Solo Desarrollo):</p>\n-           <p>Tu clave de API de Gemini está en el código frontend. Esto NO es seguro para producción.</p>\n-           <p>Para producción, envía el texto reconocido a un **backend** seguro que realice la llamada a la API de Gemini con tu clave.</p>\n-       </div>\n-\n     </div>\n   );\n };\n \n-export default VoiceChatWithGemini;\n+export default VoiceRecognition;\n\\ No newline at end of file\n"
                },
                {
                    "date": 1746989634816,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,202 +1,193 @@\n+// src/pages/LoggedIn/Componentes-Iniciado/Micro-enter.jsx\n import React, { useState, useEffect, useRef } from 'react';\n \n-// --- Verifica si la Web Speech API está disponible ---\n const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n \n-const VoiceRecognition = ({ onTextRecognized, responseData, isLoadingResponse, responseError }) => {\n-  // --- Estados ---\n-  const [recognizedText, setRecognizedText] = useState(''); // Texto capturado por voz\n-  const [isListening, setIsListening] = useState(false); // Estado del micrófono\n-  const [voiceError, setVoiceError] = useState(''); // Errores del reconocimiento de voz\n+const VoiceRecognition = ({\n+    onTextRecognized,\n+    onListeningChange,\n+    isLoadingResponse,\n+    // responseError, // Asumimos que el padre muestra errores de API\n+    // responseData   // Asumimos que el padre muestra feedback\n+}) => {\n+  const [interimTranscript, setInterimTranscript] = useState(''); // Para feedback visual mientras habla\n+  const [isListening, setIsListening] = useState(false);\n+  const [voiceError, setVoiceError] = useState('');\n+  const recognitionRef = useRef(null);\n+  const finalTranscriptRef = useRef(''); // Usaremos una ref para acumular el texto final\n \n-  // --- Referencias (persisten entre renders sin causar re-render) ---\n-  const recognitionRef = useRef(null); // Instancia del objeto SpeechRecognition\n-  const isHoldingEnter = useRef(false); // Flag para saber si Enter está presionado\n-\n-  // --- useEffect para la Configuración del Reconocimiento de Voz y Eventos ---\n+  // --- Configuración Inicial y Limpieza ---\n   useEffect(() => {\n-    // Si la Web Speech API no está disponible, mostrar error y salir del efecto\n     if (!SpeechRecognition) {\n-      setVoiceError(\"La Web Speech API no es soportada por este navegador.\");\n+      setVoiceError(\"Web Speech API no soportada.\");\n       return;\n     }\n \n-    // --- Inicializar la instancia de SpeechRecognition ---\n     const recognition = new SpeechRecognition();\n-    recognition.continuous = false; // Queremos una sola \"escucha\" por cada vez que se presiona Enter\n-    recognition.interimResults = false; // Solo capturar el resultado final\n-    recognition.lang = 'es-ES'; // Configura el idioma. ¡Cámbialo si es necesario!\n+    // --- CAMBIOS IMPORTANTES ---\n+    recognition.continuous = true;    // <-- Seguir escuchando a través de silencios\n+    recognition.interimResults = true; // <-- Mostrar resultados mientras habla (opcional pero útil)\n+    // --- FIN CAMBIOS IMPORTANTES ---\n+    recognition.lang = 'es-ES';\n \n-    // --- Handlers de Eventos de SpeechRecognition ---\n+    recognitionRef.current = recognition;\n+\n+    // --- Handlers de Eventos del Reconocimiento ---\n     recognition.onstart = () => {\n-       setIsListening(true); // Actualizar estado a \"escuchando\"\n-       setVoiceError(''); // Limpiar errores de voz anteriores al iniciar\n-       console.log('Reconocimiento de voz iniciado.');\n+      console.log(\">>> VR [Continuous]: onstart - Micrófono activado.\");\n+      setIsListening(true);\n+      if (onListeningChange) onListeningChange(true);\n+      setVoiceError('');\n+      setInterimTranscript(''); // Limpiar transcripción visual\n+      finalTranscriptRef.current = ''; // Limpiar acumulador final\n     };\n \n     recognition.onresult = (event) => {\n-      // Este evento se dispara cuando se reconoce una porción de voz final\n-      const transcript = event.results[event.results.length - 1][0].transcript;\n-      console.log('Resultado de voz final:', transcript);\n-      setRecognizedText(transcript); // Almacenar el texto reconocido\n+      console.log(\">>> VR [Continuous]: onresult - Recibiendo datos...\");\n+      let interim = '';\n+      let finalChunk = '';\n \n-      // Enviar el texto al componente padre para procesarlo\n-      if (onTextRecognized) {\n-        onTextRecognized(transcript);\n+      // Iterar sobre todos los resultados recibidos hasta ahora\n+      for (let i = event.resultIndex; i < event.results.length; ++i) {\n+        const transcriptPart = event.results[i][0].transcript;\n+        if (event.results[i].isFinal) {\n+          // Si es un resultado final, añadirlo al acumulador\n+          finalChunk += transcriptPart + ' '; // Añadir espacio entre frases finales\n+          console.log(\">>> VR [Continuous]: Chunk final detectado:\", transcriptPart);\n+        } else {\n+          // Si es intermedio, guardarlo para mostrarlo visualmente\n+          interim += transcriptPart;\n+        }\n       }\n+      setInterimTranscript(interim); // Actualizar vista con lo último intermedio\n+      if (finalChunk) {\n+        finalTranscriptRef.current += finalChunk; // Acumular partes finales en la ref\n+        console.log(\">>> VR [Continuous]: Acumulador final ahora:\", finalTranscriptRef.current);\n+      }\n     };\n \n     recognition.onerror = (event) => {\n-      // Manejar errores de reconocimiento de voz\n-      console.error('Error en reconocimiento de voz:', event.error);\n-      setIsListening(false); // Detener estado de escucha\n-      isHoldingEnter.current = false; // Asegurar que el flag de Enter se resetee\n-\n+      console.error('>>> VR [Continuous]: onerror - Error:', event.error);\n       let errorMsg = `Error de voz: ${event.error}`;\n-       if (event.error === 'not-allowed') {\n-            errorMsg = 'Permiso del micrófono denegado. Por favor, permite el acceso.';\n-       } else if (event.error === 'no-speech') {\n-            errorMsg = 'No se detectó voz. Intenta hablar más claro o ajusta el micrófono.';\n-       } else if (event.error === 'network') {\n-            errorMsg = 'Error de red durante el reconocimiento de voz.';\n-       } else if (event.error === 'aborted') {\n-           errorMsg = 'Reconocimiento abortado.'; // Común si abortamos manualmente al presionar Enter de nuevo\n-       }\n+      // Con continuous=true, 'no-speech' es menos común, pero 'audio-capture' o 'network' pueden ocurrir.\n+      if (event.error === 'not-allowed') { errorMsg = 'Permiso del micrófono denegado.'; }\n+      else if (event.error === 'no-speech') { errorMsg = 'No se detectó voz inicial.'; } // Podría pasar al inicio\n+      else if (event.error === 'network') { errorMsg = 'Error de red.'; }\n+      else if (event.error === 'aborted') { errorMsg = 'Grabación cancelada.'; } // Si llamamos a abort()\n \n-       setVoiceError(errorMsg);\n-       setRecognizedText(''); // Limpiar texto reconocido en caso de error\n+      setVoiceError(errorMsg);\n+      setIsListening(false);\n+      if (onListeningChange) onListeningChange(false);\n+      finalTranscriptRef.current = ''; // Limpiar acumulador en error\n+      setInterimTranscript('');\n     };\n \n     recognition.onend = () => {\n-      // Este evento se dispara cuando la escucha termina\n-      console.log('Reconocimiento de voz finalizado.');\n-      setIsListening(false); // Asegurar que el estado de escucha es falso\n-      isHoldingEnter.current = false; // Asegurar que el flag de Enter se resetee\n+      console.log(\">>> VR [Continuous]: onend - Reconocimiento finalizado.\");\n+      setIsListening(false);\n+      if (onListeningChange) onListeningChange(false);\n+      setInterimTranscript(''); // Limpiar transcripción interina visual\n+\n+      // Enviar el texto final acumulado al padre, si existe\n+      const finalText = finalTranscriptRef.current.trim();\n+      if (onTextRecognized) {\n+           console.log(\">>> VR [Continuous]: Enviando texto final acumulado desde onend:\", finalText);\n+           onTextRecognized(finalText); // Enviar aunque esté vacío para indicar que terminó\n+      }\n+      // NO limpiamos la ref aquí, onstart lo hará la próxima vez\n     };\n \n-    // Guardar la instancia en la referencia para usarla en los handlers de teclado\n-    recognitionRef.current = recognition;\n-\n-    // --- Handlers de Eventos del Teclado (en la ventana global) ---\n-    const handleKeyDown = (event) => {\n-      // Iniciar reconocimiento solo si es la tecla Enter y no la estamos manteniendo ya\n-      if (event.key === 'Enter' && !isHoldingEnter.current) {\n-        isHoldingEnter.current = true; // Marcar Enter como presionado\n-        // Limpiar estados anteriores al iniciar una nueva interacción\n-        setRecognizedText('');\n-        setVoiceError('');\n-\n-        try {\n-           // Abortar cualquier sesión de reconocimiento previa que pudiera estar activa o pendiente\n-           if(recognitionRef.current && (recognitionRef.current.recognizing || isListening)) {\n-               recognitionRef.current.abort(); // Abortar detiene inmediatamente y dispara 'onend'\n-           }\n-           // Iniciar el reconocimiento de voz\n-           recognitionRef.current.start();\n-        } catch (e) {\n-           console.error(\"Error al intentar iniciar el reconocimiento de voz:\", e);\n-           setIsListening(false);\n-           isHoldingEnter.current = false;\n-           setVoiceError(\"Error al iniciar el micrófono. ¿Permiso denegado o no soportado?\");\n-        }\n+    // --- useEffect de Limpieza ---\n+    return () => {\n+      console.log('>>> VR [Continuous]: Limpiando componente.');\n+      if (recognitionRef.current) {\n+        recognitionRef.current.abort(); // Usar abort para detener inmediatamente al desmontar\n       }\n     };\n+  }, [onTextRecognized, onListeningChange]); // Dependencias\n \n+  // --- useEffect para Manejar la Tecla Enter (Modo Alternar) ---\n+  useEffect(() => {\n     const handleKeyUp = (event) => {\n-      // Detener reconocimiento solo si es la tecla Enter y la estábamos manteniendo\n-      if (event.key === 'Enter' && isHoldingEnter.current) {\n-        isHoldingEnter.current = false; // Marcar Enter como soltado\n-        // Llamar a stop() para detener el reconocimiento. Esto dispara el evento 'onend'.\n-        // Solo llamar stop si estaba escuchando para evitar errores.\n-        if (recognitionRef.current && isListening) {\n-             recognitionRef.current.stop();\n+      if (event.key === 'Enter' && recognitionRef.current) {\n+        console.log(\">>> VR [Continuous]: handleKeyUp ENTER detectado. Estado isListening:\", isListening);\n+\n+        if (!isListening) {\n+          // --- Empezar a Grabar ---\n+          try {\n+            setVoiceError('');\n+            setInterimTranscript('');\n+            finalTranscriptRef.current = ''; // Asegurar que el acumulador esté limpio\n+            console.log(\">>> VR [Continuous]: Llamando a recognition.start()\");\n+            recognitionRef.current.start();\n+          } catch (e) {\n+            console.error(\">>> VR [Continuous]: Error al intentar iniciar:\", e);\n+            setVoiceError(\"No se pudo iniciar el micrófono.\");\n+            setIsListening(false);\n+            if (onListeningChange) onListeningChange(false);\n+          }\n         } else {\n-             // Si soltó Enter pero no estaba escuchando (quizás por un error),\n-             // solo asegurar que el estado y el flag estén correctos.\n-             setIsListening(false);\n+          // --- Detener la Grabación ---\n+          try {\n+            console.log(\">>> VR [Continuous]: Llamando a recognition.stop()\");\n+            recognitionRef.current.stop(); // Esto disparará onresult (final?) y luego onend\n+          } catch (e) {\n+            console.error(\">>> VR [Continuous]: Error al intentar detener:\", e);\n+            setVoiceError(\"Error al detener la grabación.\");\n+            setIsListening(false);\n+            if (onListeningChange) onListeningChange(false);\n+          }\n         }\n       }\n     };\n \n-    // Añadir los listeners de eventos al objeto global 'window'\n-    window.addEventListener('keydown', handleKeyDown);\n     window.addEventListener('keyup', handleKeyUp);\n-\n-    // --- Función de Limpieza ---\n-    // Se ejecuta cuando el componente se desmonta\n     return () => {\n-      console.log('Limpiando componente VoiceRecognition.');\n-      // Remover los listeners de eventos del teclado para evitar fugas de memoria\n-      window.removeEventListener('keydown', handleKeyDown);\n+      console.log(\">>> VR [Continuous]: Removiendo listener de keyup.\");\n       window.removeEventListener('keyup', handleKeyUp);\n-\n-      // Abortar el reconocimiento de voz si todavía está activo\n-      if (recognitionRef.current && (recognitionRef.current.recognizing || isListening)) {\n-        recognitionRef.current.abort(); // abort() es más seguro para limpieza rápida\n-      }\n     };\n-  }, [onTextRecognized]); // Dependencia añadida para ejecutar el efecto cuando cambie la función\n+  }, [isListening, onListeningChange]); // Depende de isListening\n \n   // --- Renderizado del Componente ---\n   return (\n-    <div style={{ margin: '20px', padding: '25px', border: '3px solid #4a148c', borderRadius: '15px', fontFamily: 'sans-serif', backgroundColor: '#f3e5f5', boxShadow: '0 4px 8px rgba(0,0,0,0.1)' }}>\n-      <h2 style={{ color: '#4a148c', marginBottom: '20px', textAlign: 'center' }}>🎤 Reconocimiento de Voz 🤖</h2>\n+    <div style={{ margin: '20px', padding: '25px', border: '3px solid #1e88e5', borderRadius: '15px', fontFamily: 'sans-serif', backgroundColor: '#e3f2fd', boxShadow: '0 4px 8px rgba(0,0,0,0.1)' }}>\n+      <h2 style={{ color: '#0d47a1', marginBottom: '20px', textAlign: 'center' }}>🎤 Control de Voz (Modo Alternar Continuo) 🗣️</h2>\n \n-      {/* Indicador de estado del micrófono */}\n-      <p style={{ marginBottom: '15px', fontSize: '1.1em', color: '#333' }}>\n-        Estado del Micrófono: {isListening ?\n-                 <span style={{ color: '#388e3c', fontWeight: 'bold' }}>🎙️ Escuchando...</span> :\n-                 <span style={{ color: '#757575' }}>🔘 Presiona y mantén la tecla <kbd>Enter</kbd> para hablar.</span>\n-               }\n+      <p style={{ marginBottom: '15px', fontSize: '1.1em', color: '#333', textAlign: 'center', fontWeight: 'bold' }}>\n+        {isListening ? (\n+                 <span style={{ color: '#d32f2f' }}>🔴 GRABANDO... (Habla ahora, presiona <kbd>Enter</kbd> para detener)</span>\n+               ) : (\n+                 <span style={{ color: '#1565c0' }}>🔵 Presiona <kbd>Enter</kbd> para empezar a hablar.</span>\n+               )}\n       </p>\n \n-      {/* Mostrar errores de voz */}\n-      {voiceError && (\n-          <p style={{ color: '#d32f2f', fontWeight: 'bold', marginBottom: '15px', padding: '10px', backgroundColor: '#ffebee', borderRadius: '5px' }}>Error de Voz: {voiceError}</p>\n-      )}\n+      {voiceError && ( <p style={{ color: '#c62828', /* ... */ }}>⚠️ {voiceError}</p> )}\n+      {isLoadingResponse && ( <p style={{ marginTop: '15px', /* ... */ }}> Procesando tu solicitud... ⏳ </p> )}\n \n-      {/* Área para mostrar el texto reconocido por voz */}\n-      <div style={{ marginTop: '15px', padding: '15px', border: '1px dashed #ab47bc', minHeight: '80px', backgroundColor: '#fce4ec', borderRadius: '8px', wordBreak: 'break-word' }}>\n-        <strong style={{ color: '#6a1b9a' }}>Tu Voz (Prompt para el Asistente):</strong>\n-        <p style={{ color: '#4a148c', fontStyle: recognizedText ? 'normal' : 'italic' }}>\n-            {recognizedText || 'El texto que digas aparecerá aquí después de hablar...'}\n+      {/* Mostrar transcripción (interina o final) */}\n+      <div style={{ marginTop: '15px', padding: '15px', border: '1px dashed #1976d2', minHeight: '50px', backgroundColor: '#bbdefb', borderRadius: '8px', wordBreak: 'break-word' }}>\n+        <strong style={{ color: '#0d47a1' }}>Detectado:</strong>\n+        {/* Usamos interimTranscript para feedback visual rápido */}\n+        <p style={{ color: '#1a237e', fontStyle: interimTranscript || finalTranscriptRef.current ? 'normal' : 'italic' }}>\n+            {interimTranscript || finalTranscriptRef.current || '(El texto aparecerá aquí mientras hablas...)'}\n         </p>\n       </div>\n \n-      {/* Indicador de carga de la respuesta */}\n-       {isLoadingResponse && (\n-           <p style={{ marginTop: '15px', color: '#4a148c', fontWeight: 'bold', textAlign: 'center' }}>\n-               Enviando consulta, esperando respuesta... ⏳\n-           </p>\n-       )}\n-\n-      {/* Área para mostrar la respuesta */}\n-      <div style={{ marginTop: '20px', padding: '15px', border: '2px solid #4a148c', minHeight: '120px', backgroundColor: '#ede7f6', borderRadius: '8px', wordBreak: 'break-word' }}>\n-        <strong style={{ color: '#4a148c' }}>Respuesta del Asistente:</strong>\n-        <p style={{ color: '#311b92', fontStyle: responseData || responseError ? 'normal' : 'italic' }}>\n-            {responseData || responseError || 'La respuesta aparecerá aquí...'}\n-        </p>\n-      </div>\n-\n-       {/* Mostrar errores de respuesta */}\n-       {responseError && (\n-           <p style={{ color: '#d32f2f', fontWeight: 'bold', marginTop: '15px', padding: '10px', backgroundColor: '#ffebee', borderRadius: '5px' }}>Error: {responseError}</p>\n-       )}\n-\n-      {/* Botón para limpiar el chat */}\n-       {(recognizedText || responseData || voiceError || responseError) && (\n+      {/* Botón Limpiar (solo si no está grabando) */}\n+       {(!isListening && (interimTranscript || finalTranscriptRef.current || voiceError)) && (\n            <button\n              onClick={() => {\n-                 setRecognizedText('');\n+                 console.log(\">>> VR [Continuous]: Botón Limpiar presionado.\")\n+                 setInterimTranscript('');\n                  setVoiceError('');\n-                 if (onTextRecognized) {\n-                     onTextRecognized('', true); // Segundo parámetro indica limpieza\n-                 }\n+                 finalTranscriptRef.current = '';\n+                 // Opcional: Notificar al padre para limpiar su estado también si es necesario\n+                 if (onTextRecognized) { onTextRecognized('', true); }\n              }}\n-             style={{ marginTop: '25px', padding: '10px 20px', cursor: 'pointer', border: 'none', borderRadius: '5px', backgroundColor: '#ab47bc', color: 'white', fontSize: '1em', fontWeight: 'bold', display: 'block', margin: '0 auto' }}\n+             style={{ marginTop: '25px', /* ... */ }}\n            >\n-             Limpiar Chat\n+             Limpiar Texto Detectado\n            </button>\n        )}\n     </div>\n   );\n"
                },
                {
                    "date": 1747002582002,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,196 +1,192 @@\n // src/pages/LoggedIn/Componentes-Iniciado/Micro-enter.jsx\n import React, { useState, useEffect, useRef } from 'react';\n+// import './Micro-enter.css'; // Asegúrate que exista o crea uno si es necesario\n \n const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n \n const VoiceRecognition = ({\n     onTextRecognized,\n     onListeningChange,\n     isLoadingResponse,\n-    // responseError, // Asumimos que el padre muestra errores de API\n-    // responseData   // Asumimos que el padre muestra feedback\n }) => {\n-  const [interimTranscript, setInterimTranscript] = useState(''); // Para feedback visual mientras habla\n+  const [interimTranscript, setInterimTranscript] = useState('');\n   const [isListening, setIsListening] = useState(false);\n   const [voiceError, setVoiceError] = useState('');\n+\n   const recognitionRef = useRef(null);\n-  const finalTranscriptRef = useRef(''); // Usaremos una ref para acumular el texto final\n+  const finalTranscriptRef = useRef('');\n \n-  // --- Configuración Inicial y Limpieza ---\n+  // --- Refs para las props de callback ---\n+  // Esto permite que el useEffect principal tenga dependencias vacías []\n+  // pero siga usando las últimas versiones de las funciones pasadas como props.\n+  const onTextRecognizedRef = useRef(onTextRecognized);\n+  const onListeningChangeRef = useRef(onListeningChange);\n+\n   useEffect(() => {\n+    onTextRecognizedRef.current = onTextRecognized;\n+  }, [onTextRecognized]);\n+\n+  useEffect(() => {\n+    onListeningChangeRef.current = onListeningChange;\n+  }, [onListeningChange]);\n+\n+\n+  // --- Configuración Inicial y Limpieza del Reconocimiento ---\n+  useEffect(() => {\n     if (!SpeechRecognition) {\n       setVoiceError(\"Web Speech API no soportada.\");\n       return;\n     }\n \n+    console.log(\">>> VR [Continuous]: INICIALIZANDO instancia de SpeechRecognition (solo una vez por montaje)\");\n     const recognition = new SpeechRecognition();\n-    // --- CAMBIOS IMPORTANTES ---\n-    recognition.continuous = true;    // <-- Seguir escuchando a través de silencios\n-    recognition.interimResults = true; // <-- Mostrar resultados mientras habla (opcional pero útil)\n-    // --- FIN CAMBIOS IMPORTANTES ---\n+    recognition.continuous = true;\n+    recognition.interimResults = true;\n     recognition.lang = 'es-ES';\n-\n     recognitionRef.current = recognition;\n \n-    // --- Handlers de Eventos del Reconocimiento ---\n     recognition.onstart = () => {\n       console.log(\">>> VR [Continuous]: onstart - Micrófono activado.\");\n       setIsListening(true);\n-      if (onListeningChange) onListeningChange(true);\n+      if (onListeningChangeRef.current) onListeningChangeRef.current(true);\n       setVoiceError('');\n-      setInterimTranscript(''); // Limpiar transcripción visual\n-      finalTranscriptRef.current = ''; // Limpiar acumulador final\n+      setInterimTranscript('');\n+      finalTranscriptRef.current = '';\n     };\n \n     recognition.onresult = (event) => {\n-      console.log(\">>> VR [Continuous]: onresult - Recibiendo datos...\");\n       let interim = '';\n       let finalChunk = '';\n-\n-      // Iterar sobre todos los resultados recibidos hasta ahora\n       for (let i = event.resultIndex; i < event.results.length; ++i) {\n         const transcriptPart = event.results[i][0].transcript;\n         if (event.results[i].isFinal) {\n-          // Si es un resultado final, añadirlo al acumulador\n-          finalChunk += transcriptPart + ' '; // Añadir espacio entre frases finales\n-          console.log(\">>> VR [Continuous]: Chunk final detectado:\", transcriptPart);\n+          finalChunk += transcriptPart + ' ';\n         } else {\n-          // Si es intermedio, guardarlo para mostrarlo visualmente\n           interim += transcriptPart;\n         }\n       }\n-      setInterimTranscript(interim); // Actualizar vista con lo último intermedio\n+      setInterimTranscript(prev => prev + interim); // Mostrar intermedios acumulados\n       if (finalChunk) {\n-        finalTranscriptRef.current += finalChunk; // Acumular partes finales en la ref\n+        finalTranscriptRef.current += finalChunk;\n+        setInterimTranscript(finalTranscriptRef.current); // Mostrar final acumulado como si fuera intermedio\n         console.log(\">>> VR [Continuous]: Acumulador final ahora:\", finalTranscriptRef.current);\n       }\n     };\n \n     recognition.onerror = (event) => {\n       console.error('>>> VR [Continuous]: onerror - Error:', event.error);\n       let errorMsg = `Error de voz: ${event.error}`;\n-      // Con continuous=true, 'no-speech' es menos común, pero 'audio-capture' o 'network' pueden ocurrir.\n       if (event.error === 'not-allowed') { errorMsg = 'Permiso del micrófono denegado.'; }\n-      else if (event.error === 'no-speech') { errorMsg = 'No se detectó voz inicial.'; } // Podría pasar al inicio\n+      else if (event.error === 'no-speech') { errorMsg = 'No se detectó voz.'; } // Puede ocurrir con continuous=true si hay silencio muy largo al inicio.\n       else if (event.error === 'network') { errorMsg = 'Error de red.'; }\n-      else if (event.error === 'aborted') { errorMsg = 'Grabación cancelada.'; } // Si llamamos a abort()\n-\n+      else if (event.error === 'aborted') { errorMsg = 'Grabación cancelada.'; }\n       setVoiceError(errorMsg);\n       setIsListening(false);\n-      if (onListeningChange) onListeningChange(false);\n-      finalTranscriptRef.current = ''; // Limpiar acumulador en error\n+      if (onListeningChangeRef.current) onListeningChangeRef.current(false);\n+      finalTranscriptRef.current = '';\n       setInterimTranscript('');\n     };\n \n     recognition.onend = () => {\n       console.log(\">>> VR [Continuous]: onend - Reconocimiento finalizado.\");\n       setIsListening(false);\n-      if (onListeningChange) onListeningChange(false);\n-      setInterimTranscript(''); // Limpiar transcripción interina visual\n+      if (onListeningChangeRef.current) onListeningChangeRef.current(false);\n+      setInterimTranscript('');\n \n-      // Enviar el texto final acumulado al padre, si existe\n       const finalText = finalTranscriptRef.current.trim();\n-      if (onTextRecognized) {\n+      if (onTextRecognizedRef.current) {\n            console.log(\">>> VR [Continuous]: Enviando texto final acumulado desde onend:\", finalText);\n-           onTextRecognized(finalText); // Enviar aunque esté vacío para indicar que terminó\n+           onTextRecognizedRef.current(finalText);\n       }\n-      // NO limpiamos la ref aquí, onstart lo hará la próxima vez\n     };\n \n-    // --- useEffect de Limpieza ---\n     return () => {\n-      console.log('>>> VR [Continuous]: Limpiando componente.');\n+      console.log('>>> VR [Continuous]: Limpiando instancia de SpeechRecognition (al desmontar).');\n       if (recognitionRef.current) {\n-        recognitionRef.current.abort(); // Usar abort para detener inmediatamente al desmontar\n+        // Remover listeners explícitamente si es necesario, aunque abort() debería bastar\n+        recognitionRef.current.onstart = null;\n+        recognitionRef.current.onresult = null;\n+        recognitionRef.current.onerror = null;\n+        recognitionRef.current.onend = null;\n+        recognitionRef.current.abort();\n       }\n     };\n-  }, [onTextRecognized, onListeningChange]); // Dependencias\n+  }, []); // <-- ARRAY DE DEPENDENCIAS VACÍO para que se ejecute solo una vez\n \n   // --- useEffect para Manejar la Tecla Enter (Modo Alternar) ---\n   useEffect(() => {\n     const handleKeyUp = (event) => {\n+      const targetTagName = event.target.tagName;\n+      if (targetTagName === 'INPUT' || targetTagName === 'TEXTAREA' || targetTagName === 'SELECT' || event.target.isContentEditable) return;\n+\n       if (event.key === 'Enter' && recognitionRef.current) {\n-        console.log(\">>> VR [Continuous]: handleKeyUp ENTER detectado. Estado isListening:\", isListening);\n-\n-        if (!isListening) {\n-          // --- Empezar a Grabar ---\n+        event.preventDefault();\n+        // Usamos el estado 'isListening' directamente, ya no necesitamos 'isListeningLocal' si el contexto se quita\n+        if (!isListening) { // Si NO está escuchando, iniciar\n           try {\n             setVoiceError('');\n             setInterimTranscript('');\n-            finalTranscriptRef.current = ''; // Asegurar que el acumulador esté limpio\n-            console.log(\">>> VR [Continuous]: Llamando a recognition.start()\");\n+            finalTranscriptRef.current = '';\n+            console.log(\">>> VR [Continuous]: KeyUp Enter - Llamando a recognition.start()\");\n             recognitionRef.current.start();\n           } catch (e) {\n-            console.error(\">>> VR [Continuous]: Error al intentar iniciar:\", e);\n+            console.error(\">>> VR [Continuous]: Error al intentar iniciar por Enter:\", e);\n             setVoiceError(\"No se pudo iniciar el micrófono.\");\n             setIsListening(false);\n-            if (onListeningChange) onListeningChange(false);\n+            if (onListeningChangeRef.current) onListeningChangeRef.current(false);\n           }\n-        } else {\n-          // --- Detener la Grabación ---\n+        } else { // Si YA está escuchando, detener\n           try {\n-            console.log(\">>> VR [Continuous]: Llamando a recognition.stop()\");\n-            recognitionRef.current.stop(); // Esto disparará onresult (final?) y luego onend\n+            console.log(\">>> VR [Continuous]: KeyUp Enter - Llamando a recognition.stop()\");\n+            recognitionRef.current.stop();\n           } catch (e) {\n-            console.error(\">>> VR [Continuous]: Error al intentar detener:\", e);\n+            console.error(\">>> VR [Continuous]: Error al intentar detener por Enter:\", e);\n             setVoiceError(\"Error al detener la grabación.\");\n             setIsListening(false);\n-            if (onListeningChange) onListeningChange(false);\n+            if (onListeningChangeRef.current) onListeningChangeRef.current(false);\n           }\n         }\n       }\n     };\n \n     window.addEventListener('keyup', handleKeyUp);\n     return () => {\n-      console.log(\">>> VR [Continuous]: Removiendo listener de keyup.\");\n+      console.log(\">>> VR [Continuous]: Removiendo listener de keyup global.\");\n       window.removeEventListener('keyup', handleKeyUp);\n     };\n-  }, [isListening, onListeningChange]); // Depende de isListening\n+    // isListening aquí es el estado local. onListeningChangeRef es una ref.\n+  }, [isListening]); // Depende de isListening para alternar start/stop\n \n-  // --- Renderizado del Componente ---\n+  // --- Renderizado ---\n+  if (!SpeechRecognition && !error) {\n+    return <div className=\"voice-recognition-error\" title=\"Voz no soportada\">🚫 Mic. No Soportado</div>;\n+  }\n   return (\n-    <div style={{ margin: '20px', padding: '25px', border: '3px solid #1e88e5', borderRadius: '15px', fontFamily: 'sans-serif', backgroundColor: '#e3f2fd', boxShadow: '0 4px 8px rgba(0,0,0,0.1)' }}>\n-      <h2 style={{ color: '#0d47a1', marginBottom: '20px', textAlign: 'center' }}>🎤 Control de Voz (Modo Alternar Continuo) 🗣️</h2>\n-\n-      <p style={{ marginBottom: '15px', fontSize: '1.1em', color: '#333', textAlign: 'center', fontWeight: 'bold' }}>\n-        {isListening ? (\n-                 <span style={{ color: '#d32f2f' }}>🔴 GRABANDO... (Habla ahora, presiona <kbd>Enter</kbd> para detener)</span>\n-               ) : (\n-                 <span style={{ color: '#1565c0' }}>🔵 Presiona <kbd>Enter</kbd> para empezar a hablar.</span>\n-               )}\n+    <div className={`voice-recognition-ui ${isListening ? 'listening' : ''}`} style={{ padding: '15px', border: '2px solid #ccc', borderRadius: '8px', textAlign: 'center' }}>\n+      <p style={{ fontWeight: 'bold', marginBottom: '10px' }}>\n+        {isListening ?\n+          <span style={{ color: 'red' }}>🔴 GRABANDO... (Presiona <kbd>Enter</kbd> para detener)</span> :\n+          <span style={{ color: 'green' }}>🔵 Presiona <kbd>Enter</kbd> para hablar.</span>\n+        }\n       </p>\n-\n-      {voiceError && ( <p style={{ color: '#c62828', /* ... */ }}>⚠️ {voiceError}</p> )}\n-      {isLoadingResponse && ( <p style={{ marginTop: '15px', /* ... */ }}> Procesando tu solicitud... ⏳ </p> )}\n-\n-      {/* Mostrar transcripción (interina o final) */}\n-      <div style={{ marginTop: '15px', padding: '15px', border: '1px dashed #1976d2', minHeight: '50px', backgroundColor: '#bbdefb', borderRadius: '8px', wordBreak: 'break-word' }}>\n-        <strong style={{ color: '#0d47a1' }}>Detectado:</strong>\n-        {/* Usamos interimTranscript para feedback visual rápido */}\n-        <p style={{ color: '#1a237e', fontStyle: interimTranscript || finalTranscriptRef.current ? 'normal' : 'italic' }}>\n-            {interimTranscript || finalTranscriptRef.current || '(El texto aparecerá aquí mientras hablas...)'}\n-        </p>\n+      {voiceError && <p style={{ color: 'red', fontStyle: 'italic' }}>Error: {voiceError}</p>}\n+      {isLoadingResponse && <p style={{ color: 'blue' }}>Procesando solicitud del padre...</p>}\n+      <div style={{ minHeight: '30px', background: '#f0f0f0', padding: '5px', marginTop: '5px', borderRadius: '4px' }}>\n+        <span style={{ fontWeight: '500' }}>Detectado: </span>\n+        <span>{interimTranscript || finalTranscriptRef.current || \"...\"}</span>\n       </div>\n-\n-      {/* Botón Limpiar (solo si no está grabando) */}\n        {(!isListening && (interimTranscript || finalTranscriptRef.current || voiceError)) && (\n            <button\n              onClick={() => {\n-                 console.log(\">>> VR [Continuous]: Botón Limpiar presionado.\")\n-                 setInterimTranscript('');\n-                 setVoiceError('');\n-                 finalTranscriptRef.current = '';\n-                 // Opcional: Notificar al padre para limpiar su estado también si es necesario\n-                 if (onTextRecognized) { onTextRecognized('', true); }\n+                 setInterimTranscript(''); setVoiceError(''); finalTranscriptRef.current = '';\n+                 if (onTextRecognizedRef.current) { onTextRecognizedRef.current('', true); }\n              }}\n-             style={{ marginTop: '25px', /* ... */ }}\n+             style={{ marginTop: '10px', padding: '5px 10px', fontSize: '0.8em' }}\n            >\n-             Limpiar Texto Detectado\n+             Limpiar Texto\n            </button>\n        )}\n     </div>\n   );\n };\n-\n export default VoiceRecognition;\n\\ No newline at end of file\n"
                },
                {
                    "date": 1747003173817,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,25 +1,23 @@\n // src/pages/LoggedIn/Componentes-Iniciado/Micro-enter.jsx\n import React, { useState, useEffect, useRef } from 'react';\n-// import './Micro-enter.css'; // Asegúrate que exista o crea uno si es necesario\n+// import './Micro-enter.css'; // O el nombre de tu CSS\n \n const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n \n const VoiceRecognition = ({\n     onTextRecognized,\n     onListeningChange,\n     isLoadingResponse,\n }) => {\n-  const [interimTranscript, setInterimTranscript] = useState('');\n+  const [displayTranscript, setDisplayTranscript] = useState(''); // Único estado para mostrar transcripción\n   const [isListening, setIsListening] = useState(false);\n   const [voiceError, setVoiceError] = useState('');\n \n   const recognitionRef = useRef(null);\n-  const finalTranscriptRef = useRef('');\n+  const finalAccumulatedTranscriptRef = useRef(''); // Para acumular todas las partes finales\n \n-  // --- Refs para las props de callback ---\n-  // Esto permite que el useEffect principal tenga dependencias vacías []\n-  // pero siga usando las últimas versiones de las funciones pasadas como props.\n+  // --- Refs para las props de callback (para estabilizar useEffect principal) ---\n   const onTextRecognizedRef = useRef(onTextRecognized);\n   const onListeningChangeRef = useRef(onListeningChange);\n \n   useEffect(() => {\n@@ -29,9 +27,8 @@\n   useEffect(() => {\n     onListeningChangeRef.current = onListeningChange;\n   }, [onListeningChange]);\n \n-\n   // --- Configuración Inicial y Limpieza del Reconocimiento ---\n   useEffect(() => {\n     if (!SpeechRecognition) {\n       setVoiceError(\"Web Speech API no soportada.\");\n@@ -49,70 +46,75 @@\n       console.log(\">>> VR [Continuous]: onstart - Micrófono activado.\");\n       setIsListening(true);\n       if (onListeningChangeRef.current) onListeningChangeRef.current(true);\n       setVoiceError('');\n-      setInterimTranscript('');\n-      finalTranscriptRef.current = '';\n+      // --- CORRECCIÓN: Limpiar estados de transcripción al iniciar ---\n+      setDisplayTranscript('');\n+      finalAccumulatedTranscriptRef.current = '';\n+      // --- FIN CORRECCIÓN ---\n     };\n \n     recognition.onresult = (event) => {\n-      let interim = '';\n-      let finalChunk = '';\n+      // console.log(\">>> VR [Continuous]: onresult - Recibiendo datos...\"); // Puede ser muy verboso\n+      let interim_transcript_for_event = ''; // Lo que es intermedio en ESTE evento\n+      let final_transcript_for_event = '';   // Lo que es final en ESTE evento\n+\n       for (let i = event.resultIndex; i < event.results.length; ++i) {\n-        const transcriptPart = event.results[i][0].transcript;\n+        const transcript_part = event.results[i][0].transcript;\n         if (event.results[i].isFinal) {\n-          finalChunk += transcriptPart + ' ';\n+          final_transcript_for_event += transcript_part + ' ';\n         } else {\n-          interim += transcriptPart;\n+          interim_transcript_for_event += transcript_part;\n         }\n       }\n-      setInterimTranscript(prev => prev + interim); // Mostrar intermedios acumulados\n-      if (finalChunk) {\n-        finalTranscriptRef.current += finalChunk;\n-        setInterimTranscript(finalTranscriptRef.current); // Mostrar final acumulado como si fuera intermedio\n-        console.log(\">>> VR [Continuous]: Acumulador final ahora:\", finalTranscriptRef.current);\n+\n+      // --- CORRECCIÓN: Acumular solo partes finales y construir display ---\n+      if (final_transcript_for_event) {\n+        finalAccumulatedTranscriptRef.current += final_transcript_for_event;\n+        console.log(\">>> VR [Continuous]: Nuevo chunk final añadido. Acumulado final:\", finalAccumulatedTranscriptRef.current);\n       }\n+      // La vista siempre muestra todo lo final acumulado + lo intermedio actual de este evento\n+      setDisplayTranscript(finalAccumulatedTranscriptRef.current + interim_transcript_for_event);\n+      // --- FIN CORRECCIÓN ---\n     };\n \n     recognition.onerror = (event) => {\n       console.error('>>> VR [Continuous]: onerror - Error:', event.error);\n       let errorMsg = `Error de voz: ${event.error}`;\n-      if (event.error === 'not-allowed') { errorMsg = 'Permiso del micrófono denegado.'; }\n-      else if (event.error === 'no-speech') { errorMsg = 'No se detectó voz.'; } // Puede ocurrir con continuous=true si hay silencio muy largo al inicio.\n+      if (event.error === 'not-allowed') { errorMsg = 'Permiso denegado.'; }\n+      else if (event.error === 'no-speech') { errorMsg = 'No se detectó voz.'; }\n       else if (event.error === 'network') { errorMsg = 'Error de red.'; }\n       else if (event.error === 'aborted') { errorMsg = 'Grabación cancelada.'; }\n       setVoiceError(errorMsg);\n       setIsListening(false);\n       if (onListeningChangeRef.current) onListeningChangeRef.current(false);\n-      finalTranscriptRef.current = '';\n-      setInterimTranscript('');\n+      finalAccumulatedTranscriptRef.current = '';\n+      setDisplayTranscript('');\n     };\n \n     recognition.onend = () => {\n       console.log(\">>> VR [Continuous]: onend - Reconocimiento finalizado.\");\n       setIsListening(false);\n       if (onListeningChangeRef.current) onListeningChangeRef.current(false);\n-      setInterimTranscript('');\n+      setDisplayTranscript(finalAccumulatedTranscriptRef.current.trim()); // Mostrar solo el final acumulado\n \n-      const finalText = finalTranscriptRef.current.trim();\n+      const finalText = finalAccumulatedTranscriptRef.current.trim();\n       if (onTextRecognizedRef.current) {\n            console.log(\">>> VR [Continuous]: Enviando texto final acumulado desde onend:\", finalText);\n            onTextRecognizedRef.current(finalText);\n       }\n+      // Considerar si limpiar finalAccumulatedTranscriptRef aquí o en onstart. Onstart es mejor.\n     };\n \n     return () => {\n-      console.log('>>> VR [Continuous]: Limpiando instancia de SpeechRecognition (al desmontar).');\n+      console.log('>>> VR [Continuous]: Limpiando instancia SpeechRecognition (al desmontar).');\n       if (recognitionRef.current) {\n-        // Remover listeners explícitamente si es necesario, aunque abort() debería bastar\n-        recognitionRef.current.onstart = null;\n-        recognitionRef.current.onresult = null;\n-        recognitionRef.current.onerror = null;\n-        recognitionRef.current.onend = null;\n+        recognitionRef.current.onstart = null; recognitionRef.current.onresult = null;\n+        recognitionRef.current.onerror = null; recognitionRef.current.onend = null;\n         recognitionRef.current.abort();\n       }\n     };\n-  }, []); // <-- ARRAY DE DEPENDENCIAS VACÍO para que se ejecute solo una vez\n+  }, []); // Array de dependencias vacío\n \n   // --- useEffect para Manejar la Tecla Enter (Modo Alternar) ---\n   useEffect(() => {\n     const handleKeyUp = (event) => {\n@@ -120,46 +122,36 @@\n       if (targetTagName === 'INPUT' || targetTagName === 'TEXTAREA' || targetTagName === 'SELECT' || event.target.isContentEditable) return;\n \n       if (event.key === 'Enter' && recognitionRef.current) {\n         event.preventDefault();\n-        // Usamos el estado 'isListening' directamente, ya no necesitamos 'isListeningLocal' si el contexto se quita\n-        if (!isListening) { // Si NO está escuchando, iniciar\n+        if (!isListening) {\n           try {\n-            setVoiceError('');\n-            setInterimTranscript('');\n-            finalTranscriptRef.current = '';\n-            console.log(\">>> VR [Continuous]: KeyUp Enter - Llamando a recognition.start()\");\n+            setVoiceError(''); setDisplayTranscript(''); finalAccumulatedTranscriptRef.current = '';\n+            console.log(\">>> VR [Continuous]: KeyUp Enter - Llamando recognition.start()\");\n             recognitionRef.current.start();\n           } catch (e) {\n-            console.error(\">>> VR [Continuous]: Error al intentar iniciar por Enter:\", e);\n-            setVoiceError(\"No se pudo iniciar el micrófono.\");\n-            setIsListening(false);\n+            console.error(\">>> VR [Continuous]: Error al iniciar por Enter:\", e);\n+            setVoiceError(\"No se pudo iniciar Mic.\"); setIsListening(false);\n             if (onListeningChangeRef.current) onListeningChangeRef.current(false);\n           }\n-        } else { // Si YA está escuchando, detener\n+        } else {\n           try {\n-            console.log(\">>> VR [Continuous]: KeyUp Enter - Llamando a recognition.stop()\");\n+            console.log(\">>> VR [Continuous]: KeyUp Enter - Llamando recognition.stop()\");\n             recognitionRef.current.stop();\n           } catch (e) {\n-            console.error(\">>> VR [Continuous]: Error al intentar detener por Enter:\", e);\n-            setVoiceError(\"Error al detener la grabación.\");\n-            setIsListening(false);\n+            console.error(\">>> VR [Continuous]: Error al detener por Enter:\", e);\n+            setVoiceError(\"Error al detener grabación.\"); setIsListening(false);\n             if (onListeningChangeRef.current) onListeningChangeRef.current(false);\n           }\n         }\n       }\n     };\n-\n     window.addEventListener('keyup', handleKeyUp);\n-    return () => {\n-      console.log(\">>> VR [Continuous]: Removiendo listener de keyup global.\");\n-      window.removeEventListener('keyup', handleKeyUp);\n-    };\n-    // isListening aquí es el estado local. onListeningChangeRef es una ref.\n-  }, [isListening]); // Depende de isListening para alternar start/stop\n+    return () => { window.removeEventListener('keyup', handleKeyUp); };\n+  }, [isListening]); // Depende de isListening\n \n   // --- Renderizado ---\n-  if (!SpeechRecognition && !error) {\n+  if (!SpeechRecognition && !voiceError) { // Mostrar error solo si no hay soporte y no hay otro error\n     return <div className=\"voice-recognition-error\" title=\"Voz no soportada\">🚫 Mic. No Soportado</div>;\n   }\n   return (\n     <div className={`voice-recognition-ui ${isListening ? 'listening' : ''}`} style={{ padding: '15px', border: '2px solid #ccc', borderRadius: '8px', textAlign: 'center' }}>\n@@ -172,14 +164,14 @@\n       {voiceError && <p style={{ color: 'red', fontStyle: 'italic' }}>Error: {voiceError}</p>}\n       {isLoadingResponse && <p style={{ color: 'blue' }}>Procesando solicitud del padre...</p>}\n       <div style={{ minHeight: '30px', background: '#f0f0f0', padding: '5px', marginTop: '5px', borderRadius: '4px' }}>\n         <span style={{ fontWeight: '500' }}>Detectado: </span>\n-        <span>{interimTranscript || finalTranscriptRef.current || \"...\"}</span>\n+        <span>{displayTranscript || \"...\"}</span>\n       </div>\n-       {(!isListening && (interimTranscript || finalTranscriptRef.current || voiceError)) && (\n+       {(!isListening && (displayTranscript || voiceError)) && (\n            <button\n              onClick={() => {\n-                 setInterimTranscript(''); setVoiceError(''); finalTranscriptRef.current = '';\n+                 setDisplayTranscript(''); setVoiceError(''); finalAccumulatedTranscriptRef.current = '';\n                  if (onTextRecognizedRef.current) { onTextRecognizedRef.current('', true); }\n              }}\n              style={{ marginTop: '10px', padding: '5px 10px', fontSize: '0.8em' }}\n            >\n"
                }
            ],
            "date": 1746062237439,
            "name": "Commit-0",
            "content": "import React, { useState, useEffect, useRef } from 'react';\n\n// Asegúrate de que la Web Speech API esté disponible y maneja prefijos de navegador\nconst SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n\nconst SpeechToTextPTT = () => {\n  const [recognizedText, setRecognizedText] = useState(''); // Estado para almacenar el texto reconocido\n  const [isListening, setIsListening] = useState(false); // Estado para indicar si está escuchando\n  const [error, setError] = useState(''); // Estado para posibles errores\n\n  // Usamos useRef para mantener una referencia a la instancia de SpeechRecognition\n  // y a un flag para saber si la tecla Enter está siendo mantenida presionada\n  const recognitionRef = useRef(null);\n  const isHoldingEnter = useRef(false);\n\n  // Este useEffect se encarga de configurar el API de reconocimiento de voz y los listeners de eventos\n  useEffect(() => {\n    // Si la API no está disponible, mostramos un error y salimos\n    if (!SpeechRecognition) {\n      setError(\"La Web Speech API no es soportada por este navegador.\");\n      console.error(\"La Web Speech API no es soportada por este navegador.\");\n      return;\n    }\n\n    // --- Configuración del Reconocimiento de Voz ---\n    const recognition = new SpeechRecognition();\n    recognition.continuous = false; // Queremos resultados al soltar la tecla, no reconocimiento continuo\n    recognition.interimResults = false; // Solo queremos resultados finales, no intermedios\n    recognition.lang = 'es-ES'; // Configura el idioma (cámbialo si necesitas otro)\n\n    // --- Eventos del Reconocimiento de Voz ---\n    recognition.onstart = () => {\n      // Este evento se dispara cuando el micrófono comienza a escuchar\n      setIsListening(true);\n      setError(''); // Limpiar cualquier error previo al iniciar\n      console.log('Reconocimiento de voz iniciado.');\n    };\n\n    recognition.onresult = (event) => {\n      // Este evento se dispara cuando se reconoce una porción de voz\n      const transcript = event.results[event.results.length - 1][0].transcript;\n      console.log('Resultado parcial o final:', transcript);\n      // Aquí, como interimResults es false, este será el resultado final de la pausa de habla o al detenerse\n      setRecognizedText(prevText => (prevText ? prevText + ' ' : '') + transcript); // Añadir el nuevo texto reconocido\n    };\n\n    recognition.onerror = (event) => {\n      // Este evento se dispara si ocurre un error\n      console.error('Error en reconocimiento de voz:', event.error);\n      setIsListening(false); // Asegurar que el estado de escucha se desactive en caso de error\n      // Dependiendo del error, podrías querer mostrar un mensaje diferente\n      let errorMessage = `Error de reconocimiento: ${event.error}`;\n       if (event.error === 'not-allowed') {\n            errorMessage = 'Se denegó el permiso del micrófono.';\n       } else if (event.error === 'no-speech') {\n            errorMessage = 'No se detectó voz.';\n       } else if (event.error === 'network') {\n            errorMessage = 'Error de red.';\n       }\n       setError(errorMessage);\n       isHoldingEnter.current = false; // Reset flag\n\n    };\n\n    recognition.onend = () => {\n      // Este evento se dispara cuando el reconocimiento termina (se llama a stop() o hay un error/no-speech)\n      console.log('Reconocimiento de voz finalizado.');\n      setIsListening(false); // Asegurar que el estado de escucha se desactive\n      isHoldingEnter.current = false; // Asegurar que el flag se resetee\n\n    };\n\n    // Guardar la instancia en la referencia para poder acceder a ella en otros handlers\n    recognitionRef.current = recognition;\n\n    // --- Handlers de Eventos del Teclado ---\n    const handleKeyDown = (event) => {\n      // Solo actuamos si es la tecla Enter y no la estamos manteniendo ya presionada\n      if (event.key === 'Enter' && !isHoldingEnter.current) {\n        isHoldingEnter.current = true; // Marcar que Enter está presionada\n        // No llamamos a start() aquí directamente, lo haremos de forma controlada\n        // a veces es mejor dejar que onstart actualice el estado, pero aquí lo hacemos para feedback rápido\n        setIsListening(true);\n        setError(''); // Limpiar error al intentar hablar\n\n        try {\n           // Abortar cualquier sesión previa que pudiera estar pendiente\n           if(recognitionRef.current) {\n               recognitionRef.current.abort(); // Abortar detiene inmediatamente y dispara 'onend'\n           }\n           // Iniciar una nueva sesión de reconocimiento\n           recognitionRef.current.start();\n        } catch (e) {\n            // Esto puede pasar si intentas start() mientras ya está iniciando o activa (raro con el abort() previo)\n            console.error(\"Error al intentar iniciar el reconocimiento:\", e);\n            setIsListening(false);\n            isHoldingEnter.current = false;\n            setError(\"No se pudo iniciar el micrófono.\");\n        }\n\n      }\n    };\n\n    const handleKeyUp = (event) => {\n      // Solo actuamos si es la tecla Enter y la estábamos manteniendo presionada\n      if (event.key === 'Enter' && isHoldingEnter.current) {\n        isHoldingEnter.current = false; // Marcar que Enter ha sido soltada\n        // Llamar a stop() para detener el reconocimiento. Esto disparará 'onend'.\n        if (recognitionRef.current && isListening) { // Solo detener si estaba escuchando\n             recognitionRef.current.stop();\n        } else {\n            // Si soltó Enter pero no estaba escuchando (ej: error justo al presionar),\n            // solo asegurarnos de que el flag y estado estén correctos.\n             setIsListening(false); //redundante con onend, pero seguro\n        }\n      }\n    };\n\n    // Añadir los listeners de eventos al objeto global 'window'\n    window.addEventListener('keydown', handleKeyDown);\n    window.addEventListener('keyup', handleKeyUp);\n\n    // --- Función de Limpieza (se ejecuta al desmontar el componente) ---\n    return () => {\n      console.log('Limpiando componente SpeechToTextPTT.');\n      // Remover los listeners de eventos para evitar fugas de memoria\n      window.removeEventListener('keydown', handleKeyDown);\n      window.removeEventListener('keyup', handleKeyUp);\n\n      // Abortar el reconocimiento si todavía está activo al desmontar el componente\n      if (recognitionRef.current && (recognitionRef.current.recognizing || isListening)) {\n        recognitionRef.current.abort(); // abort() es más seguro para limpieza rápida\n      }\n      recognitionRef.current = null; // Limpiar la referencia\n    };\n\n  }, []); // El array vacío [] asegura que este efecto se ejecute solo una vez al montar el componente\n\n  // --- Renderizado del Componente ---\n  return (\n    <div style={{ margin: '20px', padding: '20px', border: '1px solid #ccc', borderRadius: '10px', fontFamily: 'sans-serif' }}>\n      <h2>Control por Voz (Enter para Hablar)</h2>\n\n      <p style={{ marginBottom: '15px', fontSize: '1.1em' }}>\n        Estado: {isListening ?\n                 <span style={{ color: 'green', fontWeight: 'bold' }}>🎙️ Escuchando...</span> :\n                 <span style={{ color: 'gray' }}>🔘 Presiona y mantén la tecla Enter para hablar</span>\n               }\n      </p>\n\n      {error && (\n          <p style={{ color: 'red', fontWeight: 'bold' }}>Error: {error}</p>\n      )}\n\n      <div style={{ marginTop: '15px', padding: '15px', border: '1px dashed #bbb', minHeight: '80px', backgroundColor: '#f9f9f9', borderRadius: '5px', wordBreak: 'break-word' }}>\n        <strong>Texto Reconocido:</strong>\n        <p>{recognizedText || 'El texto de la voz aparecerá aquí...'}</p>\n      </div>\n\n      {recognizedText && ( // Mostrar el botón de limpiar solo si hay texto\n          <button\n            onClick={() => { setRecognizedText(''); setError(''); }} // Limpiar texto y errores\n            style={{ marginTop: '15px', padding: '8px 15px', cursor: 'pointer', border: '1px solid #ccc', borderRadius: '5px', backgroundColor: '#eee' }}\n          >\n            Limpiar Texto\n          </button>\n      )}\n    </div>\n  );\n};\n\nexport default SpeechToTextPTT;"
        }
    ]
}