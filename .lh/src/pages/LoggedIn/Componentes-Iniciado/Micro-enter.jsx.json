{
    "sourceFile": "src/pages/LoggedIn/Componentes-Iniciado/Micro-enter.jsx",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 9,
            "patches": [
                {
                    "date": 1746062237439,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1746064351179,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,172 +1,312 @@\n import React, { useState, useEffect, useRef } from 'react';\n+// Importa la librería cliente oficial de Google Generative AI para JS\n+import { GoogleGenerativeAI } from '@google/generative-ai';\n \n-// Asegúrate de que la Web Speech API esté disponible y maneja prefijos de navegador\n+// --- ¡¡¡ ADVERTENCIA DE SEGURIDAD !!! ---\n+// !!! NO PONGAS TU CLAVE DE API DIRECTAMENTE AQUÍ EN CÓDIGO PARA PRODUCCIÓN !!!\n+// Esto es solo para demostración. Para producción, la llamada a la API debe hacerse desde un BACKEND SEGURO.\n+const API_KEY = \"REEMPLAZA_ESTO_CON_TU_API_KEY_REAL\"; // <-- ¡PON TU CLAVE AQUÍ PARA PROBAR!\n+\n+\n+// --- Verifica si la Web Speech API está disponible ---\n const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n \n-const SpeechToTextPTT = () => {\n-  const [recognizedText, setRecognizedText] = useState(''); // Estado para almacenar el texto reconocido\n-  const [isListening, setIsListening] = useState(false); // Estado para indicar si está escuchando\n-  const [error, setError] = useState(''); // Estado para posibles errores\n \n-  // Usamos useRef para mantener una referencia a la instancia de SpeechRecognition\n-  // y a un flag para saber si la tecla Enter está siendo mantenida presionada\n-  const recognitionRef = useRef(null);\n-  const isHoldingEnter = useRef(false);\n+const VoiceChatWithGemini = () => {\n+  // --- Estados ---\n+  const [recognizedText, setRecognizedText] = useState(''); // Texto capturado por voz\n+  const [geminiResponse, setGeminiResponse] = useState(''); // Respuesta de Gemini\n+  const [isListening, setIsListening] = useState(false); // Estado del micrófono\n+  const [isLoadingGemini, setIsLoadingGemini] = useState(false); // Estado de la llamada a Gemini\n+  const [voiceError, setVoiceError] = useState(''); // Errores del reconocimiento de voz\n+  const [geminiError, setGeminiError] = useState(''); // Errores de la API de Gemini\n \n-  // Este useEffect se encarga de configurar el API de reconocimiento de voz y los listeners de eventos\n+  // --- Referencias (persisten entre renders sin causar re-render) ---\n+  const recognitionRef = useRef(null); // Instancia del objeto SpeechRecognition\n+  const isHoldingEnter = useRef(false); // Flag para saber si Enter está presionado\n+  const genAiRef = useRef(null); // Instancia de GoogleGenerativeAI client\n+  const modelRef = useRef(null); // Instancia del modelo Gemini\n+  const isGeminiCallingRef = useRef(false); // Flag para evitar múltiples llamadas a Gemini a la vez\n+\n+\n+  // --- Configuración de Gemini (similar a tu código Python) ---\n+   const MODEL_NAME = 'gemini-1.5-flash-latest'; // El modelo rápido\n+   const generationConfig = {\n+       // max_output_tokens se omite, confiamos en el prefijo del prompt para la brevedad\n+       \"temperature\": 0.5, // Temperatura baja para respuestas directas\n+   };\n+   // Prefijo para instruir al modelo a ser breve (similar a tu código Python)\n+   const PROMPT_PREFIX = \"Responde de forma muy breve a lo siguiente: \";\n+\n+\n+  // --- Función para enviar el texto reconocido a Gemini ---\n+  const sendToGemini = async (text) => {\n+    // Evitar enviar prompts vacíos o si ya hay una llamada en curso\n+    if (!text.trim() || isLoadingGemini || isGeminiCallingRef.current) {\n+      console.log(\"Saltando llamada a Gemini: texto vacío o ya hay una llamada en progreso.\");\n+      return;\n+    }\n+\n+    setIsLoadingGemini(true);\n+    isGeminiCallingRef.current = true; // Marcar que una llamada a Gemini está activa\n+    setGeminiResponse(''); // Limpiar la respuesta anterior\n+    setGeminiError(''); // Limpiar errores anteriores\n+\n+    // --- Iniciar la llamada a la API de Gemini ---\n+    try {\n+        // Inicializar el cliente y el modelo si no existen ya (usando refs)\n+        if (!genAiRef.current) {\n+            if (!API_KEY || API_KEY === \"REEMPLAZA_ESTO_CON_TU_API_KEY_REAL\") {\n+                 throw new Error(\"API Key de Gemini no configurada correctamente.\");\n+            }\n+            genAiRef.current = new GoogleGenerativeAI(API_KEY);\n+        }\n+        if (!modelRef.current) {\n+             modelRef.current = genAiRef.current.getGenerativeModel({\n+                 model: MODEL_NAME,\n+                 generationConfig: generationConfig,\n+             });\n+        }\n+\n+        // Construir el prompt completo con el prefijo para brevedad\n+        const fullPrompt = PROMPT_PREFIX + text;\n+        console.log(\"Enviando a Gemini:\", fullPrompt);\n+\n+        // Llamar a la API usando streaming para ver la respuesta a medida que llega\n+        const result = await modelRef.current.generateContentStream(fullPrompt);\n+\n+        // Procesar el stream de respuesta\n+        let responseText = '';\n+        for await (const chunk of result.stream) {\n+            // El chunk.text contiene la parte de la respuesta\n+             const chunkText = chunk.text || ''; // Manejar casos donde chunk.text podría ser undefined/null\n+             responseText += chunkText;\n+             setGeminiResponse(prev => prev + chunkText); // Añadir incrementalmente al estado\n+             // Opcional: Añadir un pequeño retardo para simular un stream más lento si quieres\n+             // await new Promise(resolve => setTimeout(resolve, 5));\n+        }\n+\n+         console.log(\"Respuesta de Gemini finalizada.\");\n+\n+    } catch (e) {\n+      console.error(\"Error llamando a la API de Gemini:\", e);\n+      setGeminiError(`Error de Gemini: ${e.message || 'Desconocido'}. Verifica tu API key y la consola.`);\n+      setGeminiResponse(''); // Limpiar cualquier respuesta parcial en caso de error\n+    } finally {\n+      setIsLoadingGemini(false);\n+      isGeminiCallingRef.current = false; // Resetear el flag al finalizar la llamada\n+    }\n+  };\n+\n+\n+  // --- useEffect para la Configuración del Reconocimiento de Voz y Eventos ---\n   useEffect(() => {\n-    // Si la API no está disponible, mostramos un error y salimos\n+    // Si la Web Speech API no está disponible, mostrar error y salir del efecto\n     if (!SpeechRecognition) {\n-      setError(\"La Web Speech API no es soportada por este navegador.\");\n-      console.error(\"La Web Speech API no es soportada por este navegador.\");\n+      setVoiceError(\"La Web Speech API no es soportada por este navegador.\");\n       return;\n     }\n \n-    // --- Configuración del Reconocimiento de Voz ---\n+    // --- Inicializar la instancia de SpeechRecognition ---\n     const recognition = new SpeechRecognition();\n-    recognition.continuous = false; // Queremos resultados al soltar la tecla, no reconocimiento continuo\n-    recognition.interimResults = false; // Solo queremos resultados finales, no intermedios\n-    recognition.lang = 'es-ES'; // Configura el idioma (cámbialo si necesitas otro)\n+    recognition.continuous = false; // Queremos una sola \"escucha\" por cada vez que se presiona Enter\n+    recognition.interimResults = false; // Solo capturar el resultado final\n+    recognition.lang = 'es-ES'; // Configura el idioma. ¡Cámbialo si es necesario!\n \n-    // --- Eventos del Reconocimiento de Voz ---\n+    // --- Handlers de Eventos de SpeechRecognition ---\n     recognition.onstart = () => {\n-      // Este evento se dispara cuando el micrófono comienza a escuchar\n-      setIsListening(true);\n-      setError(''); // Limpiar cualquier error previo al iniciar\n-      console.log('Reconocimiento de voz iniciado.');\n+       setIsListening(true); // Actualizar estado a \"escuchando\"\n+       setVoiceError(''); // Limpiar errores de voz anteriores al iniciar\n+       console.log('Reconocimiento de voz iniciado.');\n     };\n \n     recognition.onresult = (event) => {\n-      // Este evento se dispara cuando se reconoce una porción de voz\n+      // Este evento se dispara cuando se reconoce una porción de voz final (gracias a interimResults: false)\n       const transcript = event.results[event.results.length - 1][0].transcript;\n-      console.log('Resultado parcial o final:', transcript);\n-      // Aquí, como interimResults es false, este será el resultado final de la pausa de habla o al detenerse\n-      setRecognizedText(prevText => (prevText ? prevText + ' ' : '') + transcript); // Añadir el nuevo texto reconocido\n+      console.log('Resultado de voz final:', transcript);\n+      setRecognizedText(transcript); // Almacenar el texto reconocido\n+\n+      // --- ¡Paso Clave! Enviar el texto reconocido a Gemini ---\n+      // Disparamos la llamada a Gemini tan pronto como tengamos un resultado final\n+       if (!isGeminiCallingRef.current) { // Solo si no hay ya una llamada a Gemini en curso\n+           sendToGemini(transcript);\n+       } else {\n+           console.log(\"Resultado de voz listo, pero saltando llamada a Gemini porque ya hay una activa.\");\n+       }\n     };\n \n     recognition.onerror = (event) => {\n-      // Este evento se dispara si ocurre un error\n+      // Manejar errores de reconocimiento de voz\n       console.error('Error en reconocimiento de voz:', event.error);\n-      setIsListening(false); // Asegurar que el estado de escucha se desactive en caso de error\n-      // Dependiendo del error, podrías querer mostrar un mensaje diferente\n-      let errorMessage = `Error de reconocimiento: ${event.error}`;\n+      setIsListening(false); // Detener estado de escucha\n+      isHoldingEnter.current = false; // Asegurar que el flag de Enter se resetee\n\\ No newline at end of file\n+      isGeminiCallingRef.current = false; // También resetear el flag de Gemini\n+\n+      let errorMsg = `Error de voz: ${event.error}`;\n        if (event.error === 'not-allowed') {\n-            errorMessage = 'Se denegó el permiso del micrófono.';\n+            errorMsg = 'Permiso del micrófono denegado. Por favor, permite el acceso.';\n        } else if (event.error === 'no-speech') {\n-            errorMessage = 'No se detectó voz.';\n+            errorMsg = 'No se detectó voz. Intenta hablar más claro o ajusta el micrófono.';\n        } else if (event.error === 'network') {\n-            errorMessage = 'Error de red.';\n+            errorMsg = 'Error de red durante el reconocimiento de voz.';\n+       } else if (event.error === 'aborted') {\n+           errorMsg = 'Reconocimiento abortado.'; // Común si abortamos manualmente al presionar Enter de nuevo\n        }\n-       setError(errorMessage);\n-       isHoldingEnter.current = false; // Reset flag\n \n+       setVoiceError(errorMsg);\n+       setRecognizedText(''); // Limpiar texto reconocido en caso de error\n     };\n \n     recognition.onend = () => {\n-      // Este evento se dispara cuando el reconocimiento termina (se llama a stop() o hay un error/no-speech)\n+      // Este evento se dispara cuando la escucha termina (después de stop() o error/no-speech)\n       console.log('Reconocimiento de voz finalizado.');\n-      setIsListening(false); // Asegurar que el estado de escucha se desactive\n-      isHoldingEnter.current = false; // Asegurar que el flag se resetee\n-\n+      setIsListening(false); // Asegurar que el estado de escucha es falso\n+      isHoldingEnter.current = false; // Asegurar que el flag de Enter se resetee\n+      // El trigger a Gemini ya ocurrió en onresult si hubo voz, o no ocurrió si hubo error/no-speech.\n+      // No necesitamos llamar a sendToGemini aquí de nuevo a menos que 'onresult' no sea confiable antes de 'onend'.\n     };\n \n-    // Guardar la instancia en la referencia para poder acceder a ella en otros handlers\n+    // Guardar la instancia en la referencia para usarla en los handlers de teclado\n     recognitionRef.current = recognition;\n \n-    // --- Handlers de Eventos del Teclado ---\n+\n+    // --- Handlers de Eventos del Teclado (en la ventana global) ---\n     const handleKeyDown = (event) => {\n-      // Solo actuamos si es la tecla Enter y no la estamos manteniendo ya presionada\n+      // Iniciar reconocimiento solo si es la tecla Enter y no la estamos manteniendo ya\n       if (event.key === 'Enter' && !isHoldingEnter.current) {\n-        isHoldingEnter.current = true; // Marcar que Enter está presionada\n-        // No llamamos a start() aquí directamente, lo haremos de forma controlada\n-        // a veces es mejor dejar que onstart actualice el estado, pero aquí lo hacemos para feedback rápido\n-        setIsListening(true);\n-        setError(''); // Limpiar error al intentar hablar\n+        isHoldingEnter.current = true; // Marcar Enter como presionado\n+        // Limpiar estados anteriores al iniciar una nueva interacción\n+        setRecognizedText('');\n+        setGeminiResponse('');\n+        setVoiceError('');\n+        setGeminiError('');\n \n         try {\n-           // Abortar cualquier sesión previa que pudiera estar pendiente\n-           if(recognitionRef.current) {\n+           // Abortar cualquier sesión de reconocimiento previa que pudiera estar activa o pendiente\n+           if(recognitionRef.current && (recognitionRef.current.recognizing || isListening)) {\n                recognitionRef.current.abort(); // Abortar detiene inmediatamente y dispara 'onend'\n            }\n-           // Iniciar una nueva sesión de reconocimiento\n+           // Iniciar el reconocimiento de voz\n            recognitionRef.current.start();\n         } catch (e) {\n-            // Esto puede pasar si intentas start() mientras ya está iniciando o activa (raro con el abort() previo)\n-            console.error(\"Error al intentar iniciar el reconocimiento:\", e);\n-            setIsListening(false);\n-            isHoldingEnter.current = false;\n-            setError(\"No se pudo iniciar el micrófono.\");\n+           console.error(\"Error al intentar iniciar el reconocimiento de voz:\", e);\n+           setIsListening(false);\n+           isHoldingEnter.current = false;\n+           setVoiceError(\"Error al iniciar el micrófono. ¿Permiso denegado o no soportado?\");\n         }\n-\n+        // Opcional: event.preventDefault(); si quieres evitar el comportamiento por defecto de Enter (ej: enviar formularios)\n       }\n     };\n \n     const handleKeyUp = (event) => {\n-      // Solo actuamos si es la tecla Enter y la estábamos manteniendo presionada\n+      // Detener reconocimiento solo si es la tecla Enter y la estábamos manteniendo\n       if (event.key === 'Enter' && isHoldingEnter.current) {\n-        isHoldingEnter.current = false; // Marcar que Enter ha sido soltada\n-        // Llamar a stop() para detener el reconocimiento. Esto disparará 'onend'.\n-        if (recognitionRef.current && isListening) { // Solo detener si estaba escuchando\n+        isHoldingEnter.current = false; // Marcar Enter como soltado\n+        // Llamar a stop() para detener el reconocimiento. Esto dispara el evento 'onend'.\n+        // Solo llamar stop si estaba escuchando para evitar errores.\n+        if (recognitionRef.current && isListening) {\n              recognitionRef.current.stop();\n         } else {\n-            // Si soltó Enter pero no estaba escuchando (ej: error justo al presionar),\n-            // solo asegurarnos de que el flag y estado estén correctos.\n-             setIsListening(false); //redundante con onend, pero seguro\n+             // Si soltó Enter pero no estaba escuchando (quizás por un error),\n+             // solo asegurar que el estado y el flag estén correctos.\n+             setIsListening(false);\n         }\n       }\n     };\n \n     // Añadir los listeners de eventos al objeto global 'window'\n     window.addEventListener('keydown', handleKeyDown);\n     window.addEventListener('keyup', handleKeyUp);\n \n-    // --- Función de Limpieza (se ejecuta al desmontar el componente) ---\n+    // --- Función de Limpieza ---\n+    // Se ejecuta cuando el componente se desmonta\n     return () => {\n-      console.log('Limpiando componente SpeechToTextPTT.');\n-      // Remover los listeners de eventos para evitar fugas de memoria\n+      console.log('Limpiando componente VoiceChatWithGemini.');\n+      // Remover los listeners de eventos del teclado para evitar fugas de memoria\n       window.removeEventListener('keydown', handleKeyDown);\n       window.removeEventListener('keyup', handleKeyUp);\n \n-      // Abortar el reconocimiento si todavía está activo al desmontar el componente\n+      // Abortar el reconocimiento de voz si todavía está activo\n       if (recognitionRef.current && (recognitionRef.current.recognizing || isListening)) {\n         recognitionRef.current.abort(); // abort() es más seguro para limpieza rápida\n       }\n-      recognitionRef.current = null; // Limpiar la referencia\n+       // No es estrictamente necesario limpiar las refs genAiRef y modelRef,\n+       // ya que contienen objetos JS que serán recolectados por el recolector de basura.\n     };\n \n-  }, []); // El array vacío [] asegura que este efecto se ejecute solo una vez al montar el componente\n+  }, []); // El array vacío [] asegura que este efecto se ejecute solo una vez al montar y se limpie al desmontar.\n \n+\n   // --- Renderizado del Componente ---\n   return (\n-    <div style={{ margin: '20px', padding: '20px', border: '1px solid #ccc', borderRadius: '10px', fontFamily: 'sans-serif' }}>\n-      <h2>Control por Voz (Enter para Hablar)</h2>\n+    <div style={{ margin: '20px', padding: '25px', border: '3px solid #4a148c', borderRadius: '15px', fontFamily: 'sans-serif', backgroundColor: '#f3e5f5', boxShadow: '0 4px 8px rgba(0,0,0,0.1)' }}>\n+      <h2 style={{ color: '#4a148c', marginBottom: '20px', textAlign: 'center' }}>🎤 Chat de Voz con Gemini 🤖</h2>\n \n-      <p style={{ marginBottom: '15px', fontSize: '1.1em' }}>\n-        Estado: {isListening ?\n-                 <span style={{ color: 'green', fontWeight: 'bold' }}>🎙️ Escuchando...</span> :\n-                 <span style={{ color: 'gray' }}>🔘 Presiona y mantén la tecla Enter para hablar</span>\n+      {/* Indicador de estado del micrófono */}\n+      <p style={{ marginBottom: '15px', fontSize: '1.1em', color: '#333' }}>\n+        Estado del Micrófono: {isListening ?\n+                 <span style={{ color: '#388e3c', fontWeight: 'bold' }}>🎙️ Escuchando...</span> :\n+                 <span style={{ color: '#757575' }}>🔘 Presiona y mantén la tecla <kbd>Enter</kbd> para hablar.</span>\n                }\n       </p>\n \n-      {error && (\n-          <p style={{ color: 'red', fontWeight: 'bold' }}>Error: {error}</p>\n+      {/* Mostrar errores de voz */}\n+      {voiceError && (\n+          <p style={{ color: '#d32f2f', fontWeight: 'bold', marginBottom: '15px', padding: '10px', backgroundColor: '#ffebee', borderRadius: '5px' }}>Error de Voz: {voiceError}</p>\n       )}\n \n-      <div style={{ marginTop: '15px', padding: '15px', border: '1px dashed #bbb', minHeight: '80px', backgroundColor: '#f9f9f9', borderRadius: '5px', wordBreak: 'break-word' }}>\n-        <strong>Texto Reconocido:</strong>\n-        <p>{recognizedText || 'El texto de la voz aparecerá aquí...'}</p>\n+      {/* Área para mostrar el texto reconocido por voz */}\n+      <div style={{ marginTop: '15px', padding: '15px', border: '1px dashed #ab47bc', minHeight: '80px', backgroundColor: '#fce4ec', borderRadius: '8px', wordBreak: 'break-word' }}>\n+        <strong style={{ color: '#6a1b9a' }}>Tu Voz (Prompt para Gemini):</strong>\n+        <p style={{ color: '#4a148c', fontStyle: recognizedText ? 'normal' : 'italic' }}>\n+            {recognizedText || 'El texto que digas aparecerá aquí después de hablar...'}\n+        </p>\n       </div>\n \n-      {recognizedText && ( // Mostrar el botón de limpiar solo si hay texto\n-          <button\n-            onClick={() => { setRecognizedText(''); setError(''); }} // Limpiar texto y errores\n-            style={{ marginTop: '15px', padding: '8px 15px', cursor: 'pointer', border: '1px solid #ccc', borderRadius: '5px', backgroundColor: '#eee' }}\n-          >\n-            Limpiar Texto\n-          </button>\n-      )}\n+      {/* Indicador de carga de Gemini */}\n+       {isLoadingGemini && (\n+           <p style={{ marginTop: '15px', color: '#4a148c', fontWeight: 'bold', textAlign: 'center' }}>\n+               Enviando a Gemini, esperando respuesta... ⏳\n+           </p>\n+       )}\n+\n+      {/* Área para mostrar la respuesta de Gemini */}\n+      <div style={{ marginTop: '20px', padding: '15px', border: '2px solid #4a148c', minHeight: '120px', backgroundColor: '#ede7f6', borderRadius: '8px', wordBreak: 'break-word' }}>\n+        <strong style={{ color: '#4a148c' }}>Respuesta de Gemini:</strong>\n+        <p style={{ color: '#311b92', fontStyle: geminiResponse || geminiError ? 'normal' : 'italic' }}>\n+            {geminiResponse || geminiError || 'La respuesta de Gemini aparecerá aquí...'}\n+        </p>\n+      </div>\n+\n+       {/* Mostrar errores de Gemini */}\n+       {geminiError && (\n+           <p style={{ color: '#d32f2f', fontWeight: 'bold', marginTop: '15px', padding: '10px', backgroundColor: '#ffebee', borderRadius: '5px' }}>Error de Gemini: {geminiError}</p>\n+       )}\n+\n+      {/* Botón para limpiar el chat */}\n+       {(recognizedText || geminiResponse || voiceError || geminiError) && (\n+           <button\n+             onClick={() => {\n+                 setRecognizedText('');\n+                 setGeminiResponse('');\n+                 setVoiceError('');\n+                 setGeminiError('');\n+             }}\n+             style={{ marginTop: '25px', padding: '10px 20px', cursor: 'pointer', border: 'none', borderRadius: '5px', backgroundColor: '#ab47bc', color: 'white', fontSize: '1em', fontWeight: 'bold', display: 'block', margin: '0 auto' }}\n+           >\n+             Limpiar Chat\n+           </button>\n+       )}\n+\n+       {/* ADVERTENCIA DE SEGURIDAD EN EL FRONTEND */}\n+       <div style={{ color: '#e65100', backgroundColor: '#fff3e0', borderColor: '#ffcc80', padding: '15px', border: '1px solid', borderRadius: '8px', marginTop: '25px', fontSize: '0.9em' }}>\n+           <p style={{ fontWeight: 'bold' }}>⚠️ ADVERTENCIA DE SEGURIDAD (Solo Desarrollo):</p>\n+           <p>Tu clave de API de Gemini está en el código frontend. Esto NO es seguro para producción.</p>\n+           <p>Para producción, envía el texto reconocido a un **backend** seguro que realice la llamada a la API de Gemini con tu clave.</p>\n+       </div>\n+\n     </div>\n   );\n };\n \n-export default SpeechToTextPTT;\n+export default VoiceChatWithGemini;\n\\ No newline at end of file\n"
                },
                {
                    "date": 1746064434853,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -4,9 +4,9 @@\n \n // --- ¡¡¡ ADVERTENCIA DE SEGURIDAD !!! ---\n // !!! NO PONGAS TU CLAVE DE API DIRECTAMENTE AQUÍ EN CÓDIGO PARA PRODUCCIÓN !!!\n // Esto es solo para demostración. Para producción, la llamada a la API debe hacerse desde un BACKEND SEGURO.\n-const API_KEY = \"REEMPLAZA_ESTO_CON_TU_API_KEY_REAL\"; // <-- ¡PON TU CLAVE AQUÍ PARA PROBAR!\n+const API_KEY = \"AIzaSyClAldN4Lvq3HjK1MgogyFdMzitzAqAkXM\"\n \n \n // --- Verifica si la Web Speech API está disponible ---\n const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n"
                },
                {
                    "date": 1746064578315,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -29,9 +29,9 @@\n   const isGeminiCallingRef = useRef(false); // Flag para evitar múltiples llamadas a Gemini a la vez\n \n \n   // --- Configuración de Gemini (similar a tu código Python) ---\n-   const MODEL_NAME = 'gemini-1.5-flash-latest'; // El modelo rápido\n+   const MODEL_NAME = 'gemini-2.0-flash'; // El modelo rápido\n    const generationConfig = {\n        // max_output_tokens se omite, confiamos en el prefijo del prompt para la brevedad\n        \"temperature\": 0.5, // Temperatura baja para respuestas directas\n    };\n"
                },
                {
                    "date": 1746064763572,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -78,9 +78,10 @@\n         // Procesar el stream de respuesta\n         let responseText = '';\n         for await (const chunk of result.stream) {\n             // El chunk.text contiene la parte de la respuesta\n-             const chunkText = chunk.text || ''; // Manejar casos donde chunk.text podría ser undefined/null\n+             const chunkText = chunk.text() || ''; // Manejar casos donde chunk.text podría ser undefined/null\n+             \n              responseText += chunkText;\n              setGeminiResponse(prev => prev + chunkText); // Añadir incrementalmente al estado\n              // Opcional: Añadir un pequeño retardo para simular un stream más lento si quieres\n              // await new Promise(resolve => setTimeout(resolve, 5));\n"
                },
                {
                    "date": 1746064965502,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -171,50 +171,72 @@\n     recognitionRef.current = recognition;\n \n \n     // --- Handlers de Eventos del Teclado (en la ventana global) ---\n-    const handleKeyDown = (event) => {\n-      // Iniciar reconocimiento solo si es la tecla Enter y no la estamos manteniendo ya\n-      if (event.key === 'Enter' && !isHoldingEnter.current) {\n-        isHoldingEnter.current = true; // Marcar Enter como presionado\n-        // Limpiar estados anteriores al iniciar una nueva interacción\n-        setRecognizedText('');\n-        setGeminiResponse('');\n-        setVoiceError('');\n-        setGeminiError('');\n+    // --- Handlers de Eventos del Teclado (en la ventana global) ---\n+  const handleKeyDown = (event) => {\n+    // Solo procesar si es la tecla Enter Y no la estamos manteniendo ya presionada (evita procesar las repeticiones de tecla)\n+    if (event.key === 'Enter' && !isHoldingEnter.current) {\n+      console.log('Tecla Enter presionada (primera pulsación detectada).');\n+      isHoldingEnter.current = true; // Marcamos inmediatamente que Enter está presionado\n \n-        try {\n-           // Abortar cualquier sesión de reconocimiento previa que pudiera estar activa o pendiente\n-           if(recognitionRef.current && (recognitionRef.current.recognizing || isListening)) {\n-               recognitionRef.current.abort(); // Abortar detiene inmediatamente y dispara 'onend'\n-           }\n-           // Iniciar el reconocimiento de voz\n-           recognitionRef.current.start();\n-        } catch (e) {\n-           console.error(\"Error al intentar iniciar el reconocimiento de voz:\", e);\n-           setIsListening(false);\n-           isHoldingEnter.current = false;\n-           setVoiceError(\"Error al iniciar el micrófono. ¿Permiso denegado o no soportado?\");\n-        }\n-        // Opcional: event.preventDefault(); si quieres evitar el comportamiento por defecto de Enter (ej: enviar formularios)\n+      // *** VERIFICACIÓN CLAVE: Solo intentar iniciar si la API está en estado 'idle' ***\n+      if (recognitionRef.current && recognitionRef.current.state === 'idle') {\n+          console.log('La API de reconocimiento de voz está inactiva. Intentando iniciar...');\n+          // Limpiar estados anteriores al iniciar una nueva interacción\n+          setRecognizedText('');\n+          setGeminiResponse('');\n+          setError('');\n+          setVoiceError('');\n+          setGeminiError('');\n+          setIsLoadingGemini(false); // Asegurarse de que no muestra \"Pensando...\" del intento anterior\n+\n+          try {\n+             // No necesitamos abort() aquí si ya verificamos state === 'idle',\n+             // ya que 'idle' significa que ya está detenido y listo para empezar.\n+             recognitionRef.current.start();\n+          } catch (e) {\n+             console.error(\"Error al intentar iniciar el reconocimiento de voz:\", e);\n+             setIsListening(false);\n+             isHoldingEnter.current = false; // Resetear flag si falla el inicio\n+             setVoiceError(\"Error al iniciar el micrófono.\");\n+             isGeminiCallingRef.current = false; // También resetear Gemini flag si falla\n+          }\n+      } else if (recognitionRef.current) {\n+           // Si no está idle, significa que está en otro estado (listening, stopping, error).\n+           // En este caso, no hacemos nada en esta pulsación, ya que el flag isHoldingEnter\n+           // evitará que este bloque se ejecute en las repeticiones rápidas.\n+            console.log(`Tecla Enter presionada (primera pulsación), pero API no está inactiva (estado: ${recognitionRef.current.state}). Saltando inicio.`);\n+      } else {\n+           // recognitionRef.current no existe (API no soportada)\n+            console.log(\"API de reconocimiento de voz no disponible.\");\n+            isHoldingEnter.current = false; // Resetear flag ya que no podemos hacer nada\n       }\n+      // Las pulsaciones subsiguientes de Enter MIENTRAS SE MANTIENE PRESIONADO son ignoradas\n+      // por la condición `!isHoldingEnter.current` al principio de esta función.\n     };\n+  };\n \n-    const handleKeyUp = (event) => {\n-      // Detener reconocimiento solo si es la tecla Enter y la estábamos manteniendo\n-      if (event.key === 'Enter' && isHoldingEnter.current) {\n+  // La función handleKeyUp se mantiene igual\n+  const handleKeyUp = (event) => {\n+    // Solo procesar si es la tecla Enter Y la estábamos manteniendo presionada\n+    if (event.key === 'Enter' && isHoldingEnter.current) {\n+        console.log('Tecla Enter soltada.');\n         isHoldingEnter.current = false; // Marcar Enter como soltado\n-        // Llamar a stop() para detener el reconocimiento. Esto dispara el evento 'onend'.\n-        // Solo llamar stop si estaba escuchando para evitar errores.\n-        if (recognitionRef.current && isListening) {\n+\n+        // Si el reconocimiento estaba en el estado 'listening', lo detenemos.\n+        // El evento 'onend' se encargará de actualizar el estado isListening.\n+        if (recognitionRef.current && recognitionRef.current.state === 'listening') {\n+             console.log('Deteniendo reconocimiento de voz...');\n              recognitionRef.current.stop();\n         } else {\n-             // Si soltó Enter pero no estaba escuchando (quizás por un error),\n-             // solo asegurar que el estado y el flag estén correctos.\n-             setIsListening(false);\n+             // Si soltó Enter pero la API no estaba escuchando (quizás por un error o ya se detuvo),\n+             // solo asegurarnos de que el estado isListening es falso.\n+             console.log(`Tecla Enter soltada, pero API no estaba escuchando (estado: ${recognitionRef.current ? recognitionRef.current.state : 'N/A'}).`);\n+             setIsListening(false); // Asegurarse de que el estado local está sincronizado\n         }\n-      }\n-    };\n+    }\n+  };\n \n     // Añadir los listeners de eventos al objeto global 'window'\n     window.addEventListener('keydown', handleKeyDown);\n     window.addEventListener('keyup', handleKeyUp);\n"
                },
                {
                    "date": 1746065007427,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -171,72 +171,50 @@\n     recognitionRef.current = recognition;\n \n \n     // --- Handlers de Eventos del Teclado (en la ventana global) ---\n-    // --- Handlers de Eventos del Teclado (en la ventana global) ---\n-  const handleKeyDown = (event) => {\n-    // Solo procesar si es la tecla Enter Y no la estamos manteniendo ya presionada (evita procesar las repeticiones de tecla)\n-    if (event.key === 'Enter' && !isHoldingEnter.current) {\n-      console.log('Tecla Enter presionada (primera pulsación detectada).');\n-      isHoldingEnter.current = true; // Marcamos inmediatamente que Enter está presionado\n+    const handleKeyDown = (event) => {\n+      // Iniciar reconocimiento solo si es la tecla Enter y no la estamos manteniendo ya\n+      if (event.key === 'Enter' && !isHoldingEnter.current) {\n+        isHoldingEnter.current = true; // Marcar Enter como presionado\n+        // Limpiar estados anteriores al iniciar una nueva interacción\n+        setRecognizedText('');\n+        setGeminiResponse('');\n+        setVoiceError('');\n+        setGeminiError('');\n \n-      // *** VERIFICACIÓN CLAVE: Solo intentar iniciar si la API está en estado 'idle' ***\n-      if (recognitionRef.current && recognitionRef.current.state === 'idle') {\n-          console.log('La API de reconocimiento de voz está inactiva. Intentando iniciar...');\n-          // Limpiar estados anteriores al iniciar una nueva interacción\n-          setRecognizedText('');\n-          setGeminiResponse('');\n-          setError('');\n-          setVoiceError('');\n-          setGeminiError('');\n-          setIsLoadingGemini(false); // Asegurarse de que no muestra \"Pensando...\" del intento anterior\n-\n-          try {\n-             // No necesitamos abort() aquí si ya verificamos state === 'idle',\n-             // ya que 'idle' significa que ya está detenido y listo para empezar.\n-             recognitionRef.current.start();\n-          } catch (e) {\n-             console.error(\"Error al intentar iniciar el reconocimiento de voz:\", e);\n-             setIsListening(false);\n-             isHoldingEnter.current = false; // Resetear flag si falla el inicio\n-             setVoiceError(\"Error al iniciar el micrófono.\");\n-             isGeminiCallingRef.current = false; // También resetear Gemini flag si falla\n-          }\n-      } else if (recognitionRef.current) {\n-           // Si no está idle, significa que está en otro estado (listening, stopping, error).\n-           // En este caso, no hacemos nada en esta pulsación, ya que el flag isHoldingEnter\n-           // evitará que este bloque se ejecute en las repeticiones rápidas.\n-            console.log(`Tecla Enter presionada (primera pulsación), pero API no está inactiva (estado: ${recognitionRef.current.state}). Saltando inicio.`);\n-      } else {\n-           // recognitionRef.current no existe (API no soportada)\n-            console.log(\"API de reconocimiento de voz no disponible.\");\n-            isHoldingEnter.current = false; // Resetear flag ya que no podemos hacer nada\n+        try {\n+           // Abortar cualquier sesión de reconocimiento previa que pudiera estar activa o pendiente\n+           if(recognitionRef.current && (recognitionRef.current.recognizing || isListening)) {\n+               recognitionRef.current.abort(); // Abortar detiene inmediatamente y dispara 'onend'\n+           }\n+           // Iniciar el reconocimiento de voz\n+           recognitionRef.current.start();\n+        } catch (e) {\n+           console.error(\"Error al intentar iniciar el reconocimiento de voz:\", e);\n+           setIsListening(false);\n+           isHoldingEnter.current = false;\n+           setVoiceError(\"Error al iniciar el micrófono. ¿Permiso denegado o no soportado?\");\n+        }\n+        // Opcional: event.preventDefault(); si quieres evitar el comportamiento por defecto de Enter (ej: enviar formularios)\n       }\n-      // Las pulsaciones subsiguientes de Enter MIENTRAS SE MANTIENE PRESIONADO son ignoradas\n-      // por la condición `!isHoldingEnter.current` al principio de esta función.\n     };\n-  };\n \n-  // La función handleKeyUp se mantiene igual\n-  const handleKeyUp = (event) => {\n-    // Solo procesar si es la tecla Enter Y la estábamos manteniendo presionada\n-    if (event.key === 'Enter' && isHoldingEnter.current) {\n-        console.log('Tecla Enter soltada.');\n+    const handleKeyUp = (event) => {\n+      // Detener reconocimiento solo si es la tecla Enter y la estábamos manteniendo\n+      if (event.key === 'Enter' && isHoldingEnter.current) {\n         isHoldingEnter.current = false; // Marcar Enter como soltado\n-\n-        // Si el reconocimiento estaba en el estado 'listening', lo detenemos.\n-        // El evento 'onend' se encargará de actualizar el estado isListening.\n-        if (recognitionRef.current && recognitionRef.current.state === 'listening') {\n-             console.log('Deteniendo reconocimiento de voz...');\n+        // Llamar a stop() para detener el reconocimiento. Esto dispara el evento 'onend'.\n+        // Solo llamar stop si estaba escuchando para evitar errores.\n+        if (recognitionRef.current && isListening) {\n              recognitionRef.current.stop();\n         } else {\n-             // Si soltó Enter pero la API no estaba escuchando (quizás por un error o ya se detuvo),\n-             // solo asegurarnos de que el estado isListening es falso.\n-             console.log(`Tecla Enter soltada, pero API no estaba escuchando (estado: ${recognitionRef.current ? recognitionRef.current.state : 'N/A'}).`);\n-             setIsListening(false); // Asegurarse de que el estado local está sincronizado\n+             // Si soltó Enter pero no estaba escuchando (quizás por un error),\n+             // solo asegurar que el estado y el flag estén correctos.\n+             setIsListening(false);\n         }\n-    }\n-  };\n+      }\n+    };\n \n     // Añadir los listeners de eventos al objeto global 'window'\n     window.addEventListener('keydown', handleKeyDown);\n     window.addEventListener('keyup', handleKeyUp);\n"
                },
                {
                    "date": 1746065049144,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -171,50 +171,86 @@\n     recognitionRef.current = recognition;\n \n \n     // --- Handlers de Eventos del Teclado (en la ventana global) ---\n-    const handleKeyDown = (event) => {\n-      // Iniciar reconocimiento solo si es la tecla Enter y no la estamos manteniendo ya\n-      if (event.key === 'Enter' && !isHoldingEnter.current) {\n-        isHoldingEnter.current = true; // Marcar Enter como presionado\n-        // Limpiar estados anteriores al iniciar una nueva interacción\n-        setRecognizedText('');\n-        setGeminiResponse('');\n-        setVoiceError('');\n-        setGeminiError('');\n+    // --- Handlers de Eventos del Teclado (en la ventana global) ---\n+  const handleKeyDown = (event) => {\n+    // Solo procesar si es la tecla Enter Y no la estamos manteniendo ya presionada\n+    if (event.key === 'Enter' && !isHoldingEnter.current) {\n+      console.log('Tecla Enter presionada (primera pulsación detectada).');\n+      isHoldingEnter.current = true; // Marcamos inmediatamente que Enter está presionado\n \n-        try {\n-           // Abortar cualquier sesión de reconocimiento previa que pudiera estar activa o pendiente\n-           if(recognitionRef.current && (recognitionRef.current.recognizing || isListening)) {\n-               recognitionRef.current.abort(); // Abortar detiene inmediatamente y dispara 'onend'\n-           }\n-           // Iniciar el reconocimiento de voz\n-           recognitionRef.current.start();\n-        } catch (e) {\n-           console.error(\"Error al intentar iniciar el reconocimiento de voz:\", e);\n-           setIsListening(false);\n-           isHoldingEnter.current = false;\n-           setVoiceError(\"Error al iniciar el micrófono. ¿Permiso denegado o no soportado?\");\n-        }\n-        // Opcional: event.preventDefault(); si quieres evitar el comportamiento por defecto de Enter (ej: enviar formularios)\n+      // Verificar si la instancia de la API existe Y NO está ya escuchando o iniciando\n+      // Usamos optional chaining (?.) para seguridad si recognitionRef.current aún no está listo\n+      if (recognitionRef.current && recognitionRef.current.state !== 'listening' && recognitionRef.current.state !== 'starting') {\n+          // Aquí 'recognitionRef.current.state' podría ser 'idle', undefined, 'stopped', 'aborting'...\n+          // Siempre y cuando no esté 'listening' o 'starting', podemos intentar iniciar.\n+          console.log(`La API de reconocimiento de voz está en estado '${recognitionRef.current.state}'. Intentando iniciar...`);\n+\n+          // Limpiar estados anteriores para una nueva interacción\n+          setRecognizedText('');\n+          setGeminiResponse('');\n+          setError('');\n+          setVoiceError('');\n+          setGeminiError('');\n+          setIsLoadingGemini(false); // Asegurarse de que el indicador de carga de Gemini no se quede pegado\n+\n+          try {\n+             // Aunque verificamos el estado, llamar a abort() justo antes de start()\n+             // es una estrategia defensiva común para asegurar que cualquier proceso anterior\n+             // que pudiera estar finalizando se detenga completamente.\n+             if (recognitionRef.current.state !== 'idle') { // Solo abortar si no está ya idle\n+                 recognitionRef.current.abort();\n+                 console.log('Abortando sesión previa...');\n+             }\n+\n+             // Iniciar el reconocimiento de voz\n+             recognitionRef.current.start();\n+\n+          } catch (e) {\n+             console.error(\"Error al intentar iniciar el reconocimiento de voz:\", e);\n+             setIsListening(false);\n+             isHoldingEnter.current = false; // Resetear flag si falla el inicio\n+             setVoiceError(`Error al iniciar el micrófono: ${e.message}.`);\n+             isGeminiCallingRef.current = false; // Resetear Gemini flag si falla\n+          }\n+      } else if (recognitionRef.current) {\n+           // Si está escuchando o iniciando, saltamos el inicio para evitar errores.\n+           console.log(`Tecla Enter presionada (primera pulsación), pero API está ocupada (estado: ${recognitionRef.current.state}). Saltando inicio.`);\n+           // El flag isHoldingEnter ya está en true, lo que previene las repeticiones rápidas.\n+           // El usuario tendrá que soltar y presionar de nuevo.\n+      } else {\n+           // recognitionRef.current aún no existe (API no soportada o componente no listo).\n+            console.log(\"API de reconocimiento de voz no disponible o no inicializada.\");\n+            isHoldingEnter.current = false; // Resetear flag\n+            setVoiceError(\"API de reconocimiento de voz no soportada o no lista.\");\n       }\n+      // Las pulsaciones subsiguientes de Enter MIENTRAS SE MANTIENE PRESIONADO son ignoradas\n+      // por la condición `!isHoldingEnter.current` al principio de esta función.\n     };\n+  };\n \n-    const handleKeyUp = (event) => {\n-      // Detener reconocimiento solo si es la tecla Enter y la estábamos manteniendo\n-      if (event.key === 'Enter' && isHoldingEnter.current) {\n+  // --- Handlers de Eventos del Teclado (en la ventana global) ---\n+  const handleKeyUp = (event) => {\n+    // Solo procesar si es la tecla Enter Y la estábamos manteniendo presionada\n+    if (event.key === 'Enter' && isHoldingEnter.current) {\n+        console.log('Tecla Enter soltada.');\n         isHoldingEnter.current = false; // Marcar Enter como soltado\n-        // Llamar a stop() para detener el reconocimiento. Esto dispara el evento 'onend'.\n-        // Solo llamar stop si estaba escuchando para evitar errores.\n-        if (recognitionRef.current && isListening) {\n+\n+        // Si el reconocimiento estaba en el estado 'listening' o 'starting', lo detenemos.\n+        // El evento 'onend' se encargará de actualizar el estado isListening.\n+        if (recognitionRef.current && (recognitionRef.current.state === 'listening' || recognitionRef.current.state === 'starting')) {\n+             console.log(`API en estado ${recognitionRef.current.state}. Deteniendo reconocimiento de voz...`);\n              recognitionRef.current.stop();\n         } else {\n-             // Si soltó Enter pero no estaba escuchando (quizás por un error),\n-             // solo asegurar que el estado y el flag estén correctos.\n-             setIsListening(false);\n+             // Si soltó Enter pero la API no estaba escuchando/iniciando (quizás por un error, ya se detuvo, o estaba idle),\n+             // solo asegurarnos de que el estado isListening es falso.\n+             console.log(`Tecla Enter soltada, pero API no estaba escuchando ni iniciando (estado: ${recognitionRef.current ? recognitionRef.current.state : 'N/A'}).`);\n+             setIsListening(false); // Asegurar que el estado local está sincronizado\n+             isGeminiCallingRef.current = false; // Asegurar que el flag de Gemini también se resetea si algo salió mal\n         }\n-      }\n-    };\n+    }\n+  };\n \n     // Añadir los listeners de eventos al objeto global 'window'\n     window.addEventListener('keydown', handleKeyDown);\n     window.addEventListener('keyup', handleKeyUp);\n"
                },
                {
                    "date": 1746065078017,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -171,86 +171,50 @@\n     recognitionRef.current = recognition;\n \n \n     // --- Handlers de Eventos del Teclado (en la ventana global) ---\n-    // --- Handlers de Eventos del Teclado (en la ventana global) ---\n-  const handleKeyDown = (event) => {\n-    // Solo procesar si es la tecla Enter Y no la estamos manteniendo ya presionada\n-    if (event.key === 'Enter' && !isHoldingEnter.current) {\n-      console.log('Tecla Enter presionada (primera pulsación detectada).');\n-      isHoldingEnter.current = true; // Marcamos inmediatamente que Enter está presionado\n+    const handleKeyDown = (event) => {\n+      // Iniciar reconocimiento solo si es la tecla Enter y no la estamos manteniendo ya\n+      if (event.key === 'Enter' && !isHoldingEnter.current) {\n+        isHoldingEnter.current = true; // Marcar Enter como presionado\n+        // Limpiar estados anteriores al iniciar una nueva interacción\n+        setRecognizedText('');\n+        setGeminiResponse('');\n+        setVoiceError('');\n+        setGeminiError('');\n \n-      // Verificar si la instancia de la API existe Y NO está ya escuchando o iniciando\n-      // Usamos optional chaining (?.) para seguridad si recognitionRef.current aún no está listo\n-      if (recognitionRef.current && recognitionRef.current.state !== 'listening' && recognitionRef.current.state !== 'starting') {\n-          // Aquí 'recognitionRef.current.state' podría ser 'idle', undefined, 'stopped', 'aborting'...\n-          // Siempre y cuando no esté 'listening' o 'starting', podemos intentar iniciar.\n-          console.log(`La API de reconocimiento de voz está en estado '${recognitionRef.current.state}'. Intentando iniciar...`);\n-\n-          // Limpiar estados anteriores para una nueva interacción\n-          setRecognizedText('');\n-          setGeminiResponse('');\n-          setError('');\n-          setVoiceError('');\n-          setGeminiError('');\n-          setIsLoadingGemini(false); // Asegurarse de que el indicador de carga de Gemini no se quede pegado\n-\n-          try {\n-             // Aunque verificamos el estado, llamar a abort() justo antes de start()\n-             // es una estrategia defensiva común para asegurar que cualquier proceso anterior\n-             // que pudiera estar finalizando se detenga completamente.\n-             if (recognitionRef.current.state !== 'idle') { // Solo abortar si no está ya idle\n-                 recognitionRef.current.abort();\n-                 console.log('Abortando sesión previa...');\n-             }\n-\n-             // Iniciar el reconocimiento de voz\n-             recognitionRef.current.start();\n-\n-          } catch (e) {\n-             console.error(\"Error al intentar iniciar el reconocimiento de voz:\", e);\n-             setIsListening(false);\n-             isHoldingEnter.current = false; // Resetear flag si falla el inicio\n-             setVoiceError(`Error al iniciar el micrófono: ${e.message}.`);\n-             isGeminiCallingRef.current = false; // Resetear Gemini flag si falla\n-          }\n-      } else if (recognitionRef.current) {\n-           // Si está escuchando o iniciando, saltamos el inicio para evitar errores.\n-           console.log(`Tecla Enter presionada (primera pulsación), pero API está ocupada (estado: ${recognitionRef.current.state}). Saltando inicio.`);\n-           // El flag isHoldingEnter ya está en true, lo que previene las repeticiones rápidas.\n-           // El usuario tendrá que soltar y presionar de nuevo.\n-      } else {\n-           // recognitionRef.current aún no existe (API no soportada o componente no listo).\n-            console.log(\"API de reconocimiento de voz no disponible o no inicializada.\");\n-            isHoldingEnter.current = false; // Resetear flag\n-            setVoiceError(\"API de reconocimiento de voz no soportada o no lista.\");\n+        try {\n+           // Abortar cualquier sesión de reconocimiento previa que pudiera estar activa o pendiente\n+           if(recognitionRef.current && (recognitionRef.current.recognizing || isListening)) {\n+               recognitionRef.current.abort(); // Abortar detiene inmediatamente y dispara 'onend'\n+           }\n+           // Iniciar el reconocimiento de voz\n+           recognitionRef.current.start();\n+        } catch (e) {\n+           console.error(\"Error al intentar iniciar el reconocimiento de voz:\", e);\n+           setIsListening(false);\n+           isHoldingEnter.current = false;\n+           setVoiceError(\"Error al iniciar el micrófono. ¿Permiso denegado o no soportado?\");\n+        }\n+        // Opcional: event.preventDefault(); si quieres evitar el comportamiento por defecto de Enter (ej: enviar formularios)\n       }\n-      // Las pulsaciones subsiguientes de Enter MIENTRAS SE MANTIENE PRESIONADO son ignoradas\n-      // por la condición `!isHoldingEnter.current` al principio de esta función.\n     };\n-  };\n \n-  // --- Handlers de Eventos del Teclado (en la ventana global) ---\n-  const handleKeyUp = (event) => {\n-    // Solo procesar si es la tecla Enter Y la estábamos manteniendo presionada\n-    if (event.key === 'Enter' && isHoldingEnter.current) {\n-        console.log('Tecla Enter soltada.');\n+    const handleKeyUp = (event) => {\n+      // Detener reconocimiento solo si es la tecla Enter y la estábamos manteniendo\n+      if (event.key === 'Enter' && isHoldingEnter.current) {\n         isHoldingEnter.current = false; // Marcar Enter como soltado\n-\n-        // Si el reconocimiento estaba en el estado 'listening' o 'starting', lo detenemos.\n-        // El evento 'onend' se encargará de actualizar el estado isListening.\n-        if (recognitionRef.current && (recognitionRef.current.state === 'listening' || recognitionRef.current.state === 'starting')) {\n-             console.log(`API en estado ${recognitionRef.current.state}. Deteniendo reconocimiento de voz...`);\n+        // Llamar a stop() para detener el reconocimiento. Esto dispara el evento 'onend'.\n+        // Solo llamar stop si estaba escuchando para evitar errores.\n+        if (recognitionRef.current && isListening) {\n              recognitionRef.current.stop();\n         } else {\n-             // Si soltó Enter pero la API no estaba escuchando/iniciando (quizás por un error, ya se detuvo, o estaba idle),\n-             // solo asegurarnos de que el estado isListening es falso.\n-             console.log(`Tecla Enter soltada, pero API no estaba escuchando ni iniciando (estado: ${recognitionRef.current ? recognitionRef.current.state : 'N/A'}).`);\n-             setIsListening(false); // Asegurar que el estado local está sincronizado\n-             isGeminiCallingRef.current = false; // Asegurar que el flag de Gemini también se resetea si algo salió mal\n+             // Si soltó Enter pero no estaba escuchando (quizás por un error),\n+             // solo asegurar que el estado y el flag estén correctos.\n+             setIsListening(false);\n         }\n-    }\n-  };\n+      }\n+    };\n \n     // Añadir los listeners de eventos al objeto global 'window'\n     window.addEventListener('keydown', handleKeyDown);\n     window.addEventListener('keyup', handleKeyUp);\n"
                },
                {
                    "date": 1746114294020,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,106 +1,19 @@\n import React, { useState, useEffect, useRef } from 'react';\n-// Importa la librería cliente oficial de Google Generative AI para JS\n-import { GoogleGenerativeAI } from '@google/generative-ai';\n \n-// --- ¡¡¡ ADVERTENCIA DE SEGURIDAD !!! ---\n-// !!! NO PONGAS TU CLAVE DE API DIRECTAMENTE AQUÍ EN CÓDIGO PARA PRODUCCIÓN !!!\n-// Esto es solo para demostración. Para producción, la llamada a la API debe hacerse desde un BACKEND SEGURO.\n-const API_KEY = \"AIzaSyClAldN4Lvq3HjK1MgogyFdMzitzAqAkXM\"\n-\n-\n // --- Verifica si la Web Speech API está disponible ---\n const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n \n-\n-const VoiceChatWithGemini = () => {\n+const VoiceRecognition = ({ onTextRecognized, responseData, isLoadingResponse, responseError }) => {\n   // --- Estados ---\n   const [recognizedText, setRecognizedText] = useState(''); // Texto capturado por voz\n-  const [geminiResponse, setGeminiResponse] = useState(''); // Respuesta de Gemini\n   const [isListening, setIsListening] = useState(false); // Estado del micrófono\n-  const [isLoadingGemini, setIsLoadingGemini] = useState(false); // Estado de la llamada a Gemini\n   const [voiceError, setVoiceError] = useState(''); // Errores del reconocimiento de voz\n-  const [geminiError, setGeminiError] = useState(''); // Errores de la API de Gemini\n \n   // --- Referencias (persisten entre renders sin causar re-render) ---\n   const recognitionRef = useRef(null); // Instancia del objeto SpeechRecognition\n   const isHoldingEnter = useRef(false); // Flag para saber si Enter está presionado\n-  const genAiRef = useRef(null); // Instancia de GoogleGenerativeAI client\n-  const modelRef = useRef(null); // Instancia del modelo Gemini\n-  const isGeminiCallingRef = useRef(false); // Flag para evitar múltiples llamadas a Gemini a la vez\n \n-\n-  // --- Configuración de Gemini (similar a tu código Python) ---\n-   const MODEL_NAME = 'gemini-2.0-flash'; // El modelo rápido\n-   const generationConfig = {\n-       // max_output_tokens se omite, confiamos en el prefijo del prompt para la brevedad\n-       \"temperature\": 0.5, // Temperatura baja para respuestas directas\n-   };\n-   // Prefijo para instruir al modelo a ser breve (similar a tu código Python)\n-   const PROMPT_PREFIX = \"Responde de forma muy breve a lo siguiente: \";\n-\n-\n-  // --- Función para enviar el texto reconocido a Gemini ---\n-  const sendToGemini = async (text) => {\n-    // Evitar enviar prompts vacíos o si ya hay una llamada en curso\n-    if (!text.trim() || isLoadingGemini || isGeminiCallingRef.current) {\n-      console.log(\"Saltando llamada a Gemini: texto vacío o ya hay una llamada en progreso.\");\n-      return;\n-    }\n-\n-    setIsLoadingGemini(true);\n-    isGeminiCallingRef.current = true; // Marcar que una llamada a Gemini está activa\n-    setGeminiResponse(''); // Limpiar la respuesta anterior\n-    setGeminiError(''); // Limpiar errores anteriores\n-\n-    // --- Iniciar la llamada a la API de Gemini ---\n-    try {\n-        // Inicializar el cliente y el modelo si no existen ya (usando refs)\n-        if (!genAiRef.current) {\n-            if (!API_KEY || API_KEY === \"REEMPLAZA_ESTO_CON_TU_API_KEY_REAL\") {\n-                 throw new Error(\"API Key de Gemini no configurada correctamente.\");\n-            }\n-            genAiRef.current = new GoogleGenerativeAI(API_KEY);\n-        }\n-        if (!modelRef.current) {\n-             modelRef.current = genAiRef.current.getGenerativeModel({\n-                 model: MODEL_NAME,\n-                 generationConfig: generationConfig,\n-             });\n-        }\n-\n-        // Construir el prompt completo con el prefijo para brevedad\n-        const fullPrompt = PROMPT_PREFIX + text;\n-        console.log(\"Enviando a Gemini:\", fullPrompt);\n-\n-        // Llamar a la API usando streaming para ver la respuesta a medida que llega\n-        const result = await modelRef.current.generateContentStream(fullPrompt);\n-\n-        // Procesar el stream de respuesta\n-        let responseText = '';\n-        for await (const chunk of result.stream) {\n-            // El chunk.text contiene la parte de la respuesta\n-             const chunkText = chunk.text() || ''; // Manejar casos donde chunk.text podría ser undefined/null\n-             \n-             responseText += chunkText;\n-             setGeminiResponse(prev => prev + chunkText); // Añadir incrementalmente al estado\n-             // Opcional: Añadir un pequeño retardo para simular un stream más lento si quieres\n-             // await new Promise(resolve => setTimeout(resolve, 5));\n-        }\n-\n-         console.log(\"Respuesta de Gemini finalizada.\");\n-\n-    } catch (e) {\n-      console.error(\"Error llamando a la API de Gemini:\", e);\n-      setGeminiError(`Error de Gemini: ${e.message || 'Desconocido'}. Verifica tu API key y la consola.`);\n-      setGeminiResponse(''); // Limpiar cualquier respuesta parcial en caso de error\n-    } finally {\n-      setIsLoadingGemini(false);\n-      isGeminiCallingRef.current = false; // Resetear el flag al finalizar la llamada\n-    }\n-  };\n-\n-\n   // --- useEffect para la Configuración del Reconocimiento de Voz y Eventos ---\n   useEffect(() => {\n     // Si la Web Speech API no está disponible, mostrar error y salir del efecto\n     if (!SpeechRecognition) {\n@@ -121,28 +34,24 @@\n        console.log('Reconocimiento de voz iniciado.');\n     };\n \n     recognition.onresult = (event) => {\n-      // Este evento se dispara cuando se reconoce una porción de voz final (gracias a interimResults: false)\n+      // Este evento se dispara cuando se reconoce una porción de voz final\n       const transcript = event.results[event.results.length - 1][0].transcript;\n       console.log('Resultado de voz final:', transcript);\n       setRecognizedText(transcript); // Almacenar el texto reconocido\n \n-      // --- ¡Paso Clave! Enviar el texto reconocido a Gemini ---\n-      // Disparamos la llamada a Gemini tan pronto como tengamos un resultado final\n-       if (!isGeminiCallingRef.current) { // Solo si no hay ya una llamada a Gemini en curso\n-           sendToGemini(transcript);\n-       } else {\n-           console.log(\"Resultado de voz listo, pero saltando llamada a Gemini porque ya hay una activa.\");\n-       }\n+      // Enviar el texto al componente padre para procesarlo\n+      if (onTextRecognized) {\n+        onTextRecognized(transcript);\n+      }\n     };\n \n     recognition.onerror = (event) => {\n       // Manejar errores de reconocimiento de voz\n       console.error('Error en reconocimiento de voz:', event.error);\n       setIsListening(false); // Detener estado de escucha\n       isHoldingEnter.current = false; // Asegurar que el flag de Enter se resetee\n-      isGeminiCallingRef.current = false; // También resetear el flag de Gemini\n \n       let errorMsg = `Error de voz: ${event.error}`;\n        if (event.error === 'not-allowed') {\n             errorMsg = 'Permiso del micrófono denegado. Por favor, permite el acceso.';\n@@ -158,30 +67,25 @@\n        setRecognizedText(''); // Limpiar texto reconocido en caso de error\n     };\n \n     recognition.onend = () => {\n-      // Este evento se dispara cuando la escucha termina (después de stop() o error/no-speech)\n+      // Este evento se dispara cuando la escucha termina\n       console.log('Reconocimiento de voz finalizado.');\n       setIsListening(false); // Asegurar que el estado de escucha es falso\n       isHoldingEnter.current = false; // Asegurar que el flag de Enter se resetee\n-      // El trigger a Gemini ya ocurrió en onresult si hubo voz, o no ocurrió si hubo error/no-speech.\n-      // No necesitamos llamar a sendToGemini aquí de nuevo a menos que 'onresult' no sea confiable antes de 'onend'.\n     };\n \n     // Guardar la instancia en la referencia para usarla en los handlers de teclado\n     recognitionRef.current = recognition;\n \n-\n     // --- Handlers de Eventos del Teclado (en la ventana global) ---\n     const handleKeyDown = (event) => {\n       // Iniciar reconocimiento solo si es la tecla Enter y no la estamos manteniendo ya\n       if (event.key === 'Enter' && !isHoldingEnter.current) {\n         isHoldingEnter.current = true; // Marcar Enter como presionado\n         // Limpiar estados anteriores al iniciar una nueva interacción\n         setRecognizedText('');\n-        setGeminiResponse('');\n         setVoiceError('');\n-        setGeminiError('');\n \n         try {\n            // Abortar cualquier sesión de reconocimiento previa que pudiera estar activa o pendiente\n            if(recognitionRef.current && (recognitionRef.current.recognizing || isListening)) {\n@@ -194,9 +98,8 @@\n            setIsListening(false);\n            isHoldingEnter.current = false;\n            setVoiceError(\"Error al iniciar el micrófono. ¿Permiso denegado o no soportado?\");\n         }\n-        // Opcional: event.preventDefault(); si quieres evitar el comportamiento por defecto de Enter (ej: enviar formularios)\n       }\n     };\n \n     const handleKeyUp = (event) => {\n@@ -221,28 +124,24 @@\n \n     // --- Función de Limpieza ---\n     // Se ejecuta cuando el componente se desmonta\n     return () => {\n-      console.log('Limpiando componente VoiceChatWithGemini.');\n+      console.log('Limpiando componente VoiceRecognition.');\n       // Remover los listeners de eventos del teclado para evitar fugas de memoria\n       window.removeEventListener('keydown', handleKeyDown);\n       window.removeEventListener('keyup', handleKeyUp);\n \n       // Abortar el reconocimiento de voz si todavía está activo\n       if (recognitionRef.current && (recognitionRef.current.recognizing || isListening)) {\n         recognitionRef.current.abort(); // abort() es más seguro para limpieza rápida\n       }\n-       // No es estrictamente necesario limpiar las refs genAiRef y modelRef,\n-       // ya que contienen objetos JS que serán recolectados por el recolector de basura.\n     };\n+  }, [onTextRecognized]); // Dependencia añadida para ejecutar el efecto cuando cambie la función\n \n-  }, []); // El array vacío [] asegura que este efecto se ejecute solo una vez al montar y se limpie al desmontar.\n-\n-\n   // --- Renderizado del Componente ---\n   return (\n     <div style={{ margin: '20px', padding: '25px', border: '3px solid #4a148c', borderRadius: '15px', fontFamily: 'sans-serif', backgroundColor: '#f3e5f5', boxShadow: '0 4px 8px rgba(0,0,0,0.1)' }}>\n-      <h2 style={{ color: '#4a148c', marginBottom: '20px', textAlign: 'center' }}>🎤 Chat de Voz con Gemini 🤖</h2>\n+      <h2 style={{ color: '#4a148c', marginBottom: '20px', textAlign: 'center' }}>🎤 Reconocimiento de Voz 🤖</h2>\n \n       {/* Indicador de estado del micrófono */}\n       <p style={{ marginBottom: '15px', fontSize: '1.1em', color: '#333' }}>\n         Estado del Micrófono: {isListening ?\n@@ -257,57 +156,50 @@\n       )}\n \n       {/* Área para mostrar el texto reconocido por voz */}\n       <div style={{ marginTop: '15px', padding: '15px', border: '1px dashed #ab47bc', minHeight: '80px', backgroundColor: '#fce4ec', borderRadius: '8px', wordBreak: 'break-word' }}>\n-        <strong style={{ color: '#6a1b9a' }}>Tu Voz (Prompt para Gemini):</strong>\n+        <strong style={{ color: '#6a1b9a' }}>Tu Voz (Prompt para el Asistente):</strong>\n         <p style={{ color: '#4a148c', fontStyle: recognizedText ? 'normal' : 'italic' }}>\n             {recognizedText || 'El texto que digas aparecerá aquí después de hablar...'}\n         </p>\n       </div>\n \n-      {/* Indicador de carga de Gemini */}\n-       {isLoadingGemini && (\n+      {/* Indicador de carga de la respuesta */}\n+       {isLoadingResponse && (\n            <p style={{ marginTop: '15px', color: '#4a148c', fontWeight: 'bold', textAlign: 'center' }}>\n-               Enviando a Gemini, esperando respuesta... ⏳\n+               Enviando consulta, esperando respuesta... ⏳\n            </p>\n        )}\n \n-      {/* Área para mostrar la respuesta de Gemini */}\n+      {/* Área para mostrar la respuesta */}\n       <div style={{ marginTop: '20px', padding: '15px', border: '2px solid #4a148c', minHeight: '120px', backgroundColor: '#ede7f6', borderRadius: '8px', wordBreak: 'break-word' }}>\n-        <strong style={{ color: '#4a148c' }}>Respuesta de Gemini:</strong>\n-        <p style={{ color: '#311b92', fontStyle: geminiResponse || geminiError ? 'normal' : 'italic' }}>\n-            {geminiResponse || geminiError || 'La respuesta de Gemini aparecerá aquí...'}\n+        <strong style={{ color: '#4a148c' }}>Respuesta del Asistente:</strong>\n+        <p style={{ color: '#311b92', fontStyle: responseData || responseError ? 'normal' : 'italic' }}>\n+            {responseData || responseError || 'La respuesta aparecerá aquí...'}\n         </p>\n       </div>\n \n-       {/* Mostrar errores de Gemini */}\n-       {geminiError && (\n-           <p style={{ color: '#d32f2f', fontWeight: 'bold', marginTop: '15px', padding: '10px', backgroundColor: '#ffebee', borderRadius: '5px' }}>Error de Gemini: {geminiError}</p>\n+       {/* Mostrar errores de respuesta */}\n+       {responseError && (\n+           <p style={{ color: '#d32f2f', fontWeight: 'bold', marginTop: '15px', padding: '10px', backgroundColor: '#ffebee', borderRadius: '5px' }}>Error: {responseError}</p>\n        )}\n \n       {/* Botón para limpiar el chat */}\n-       {(recognizedText || geminiResponse || voiceError || geminiError) && (\n+       {(recognizedText || responseData || voiceError || responseError) && (\n            <button\n              onClick={() => {\n                  setRecognizedText('');\n-                 setGeminiResponse('');\n                  setVoiceError('');\n-                 setGeminiError('');\n+                 if (onTextRecognized) {\n+                     onTextRecognized('', true); // Segundo parámetro indica limpieza\n+                 }\n              }}\n              style={{ marginTop: '25px', padding: '10px 20px', cursor: 'pointer', border: 'none', borderRadius: '5px', backgroundColor: '#ab47bc', color: 'white', fontSize: '1em', fontWeight: 'bold', display: 'block', margin: '0 auto' }}\n            >\n              Limpiar Chat\n\\ No newline at end of file\n            </button>\n        )}\n-\n-       {/* ADVERTENCIA DE SEGURIDAD EN EL FRONTEND */}\n-       <div style={{ color: '#e65100', backgroundColor: '#fff3e0', borderColor: '#ffcc80', padding: '15px', border: '1px solid', borderRadius: '8px', marginTop: '25px', fontSize: '0.9em' }}>\n-           <p style={{ fontWeight: 'bold' }}>⚠️ ADVERTENCIA DE SEGURIDAD (Solo Desarrollo):</p>\n-           <p>Tu clave de API de Gemini está en el código frontend. Esto NO es seguro para producción.</p>\n-           <p>Para producción, envía el texto reconocido a un **backend** seguro que realice la llamada a la API de Gemini con tu clave.</p>\n-       </div>\n-\n     </div>\n   );\n };\n \n-export default VoiceChatWithGemini;\n+export default VoiceRecognition;\n\\ No newline at end of file\n"
                }
            ],
            "date": 1746062237439,
            "name": "Commit-0",
            "content": "import React, { useState, useEffect, useRef } from 'react';\n\n// Asegúrate de que la Web Speech API esté disponible y maneja prefijos de navegador\nconst SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n\nconst SpeechToTextPTT = () => {\n  const [recognizedText, setRecognizedText] = useState(''); // Estado para almacenar el texto reconocido\n  const [isListening, setIsListening] = useState(false); // Estado para indicar si está escuchando\n  const [error, setError] = useState(''); // Estado para posibles errores\n\n  // Usamos useRef para mantener una referencia a la instancia de SpeechRecognition\n  // y a un flag para saber si la tecla Enter está siendo mantenida presionada\n  const recognitionRef = useRef(null);\n  const isHoldingEnter = useRef(false);\n\n  // Este useEffect se encarga de configurar el API de reconocimiento de voz y los listeners de eventos\n  useEffect(() => {\n    // Si la API no está disponible, mostramos un error y salimos\n    if (!SpeechRecognition) {\n      setError(\"La Web Speech API no es soportada por este navegador.\");\n      console.error(\"La Web Speech API no es soportada por este navegador.\");\n      return;\n    }\n\n    // --- Configuración del Reconocimiento de Voz ---\n    const recognition = new SpeechRecognition();\n    recognition.continuous = false; // Queremos resultados al soltar la tecla, no reconocimiento continuo\n    recognition.interimResults = false; // Solo queremos resultados finales, no intermedios\n    recognition.lang = 'es-ES'; // Configura el idioma (cámbialo si necesitas otro)\n\n    // --- Eventos del Reconocimiento de Voz ---\n    recognition.onstart = () => {\n      // Este evento se dispara cuando el micrófono comienza a escuchar\n      setIsListening(true);\n      setError(''); // Limpiar cualquier error previo al iniciar\n      console.log('Reconocimiento de voz iniciado.');\n    };\n\n    recognition.onresult = (event) => {\n      // Este evento se dispara cuando se reconoce una porción de voz\n      const transcript = event.results[event.results.length - 1][0].transcript;\n      console.log('Resultado parcial o final:', transcript);\n      // Aquí, como interimResults es false, este será el resultado final de la pausa de habla o al detenerse\n      setRecognizedText(prevText => (prevText ? prevText + ' ' : '') + transcript); // Añadir el nuevo texto reconocido\n    };\n\n    recognition.onerror = (event) => {\n      // Este evento se dispara si ocurre un error\n      console.error('Error en reconocimiento de voz:', event.error);\n      setIsListening(false); // Asegurar que el estado de escucha se desactive en caso de error\n      // Dependiendo del error, podrías querer mostrar un mensaje diferente\n      let errorMessage = `Error de reconocimiento: ${event.error}`;\n       if (event.error === 'not-allowed') {\n            errorMessage = 'Se denegó el permiso del micrófono.';\n       } else if (event.error === 'no-speech') {\n            errorMessage = 'No se detectó voz.';\n       } else if (event.error === 'network') {\n            errorMessage = 'Error de red.';\n       }\n       setError(errorMessage);\n       isHoldingEnter.current = false; // Reset flag\n\n    };\n\n    recognition.onend = () => {\n      // Este evento se dispara cuando el reconocimiento termina (se llama a stop() o hay un error/no-speech)\n      console.log('Reconocimiento de voz finalizado.');\n      setIsListening(false); // Asegurar que el estado de escucha se desactive\n      isHoldingEnter.current = false; // Asegurar que el flag se resetee\n\n    };\n\n    // Guardar la instancia en la referencia para poder acceder a ella en otros handlers\n    recognitionRef.current = recognition;\n\n    // --- Handlers de Eventos del Teclado ---\n    const handleKeyDown = (event) => {\n      // Solo actuamos si es la tecla Enter y no la estamos manteniendo ya presionada\n      if (event.key === 'Enter' && !isHoldingEnter.current) {\n        isHoldingEnter.current = true; // Marcar que Enter está presionada\n        // No llamamos a start() aquí directamente, lo haremos de forma controlada\n        // a veces es mejor dejar que onstart actualice el estado, pero aquí lo hacemos para feedback rápido\n        setIsListening(true);\n        setError(''); // Limpiar error al intentar hablar\n\n        try {\n           // Abortar cualquier sesión previa que pudiera estar pendiente\n           if(recognitionRef.current) {\n               recognitionRef.current.abort(); // Abortar detiene inmediatamente y dispara 'onend'\n           }\n           // Iniciar una nueva sesión de reconocimiento\n           recognitionRef.current.start();\n        } catch (e) {\n            // Esto puede pasar si intentas start() mientras ya está iniciando o activa (raro con el abort() previo)\n            console.error(\"Error al intentar iniciar el reconocimiento:\", e);\n            setIsListening(false);\n            isHoldingEnter.current = false;\n            setError(\"No se pudo iniciar el micrófono.\");\n        }\n\n      }\n    };\n\n    const handleKeyUp = (event) => {\n      // Solo actuamos si es la tecla Enter y la estábamos manteniendo presionada\n      if (event.key === 'Enter' && isHoldingEnter.current) {\n        isHoldingEnter.current = false; // Marcar que Enter ha sido soltada\n        // Llamar a stop() para detener el reconocimiento. Esto disparará 'onend'.\n        if (recognitionRef.current && isListening) { // Solo detener si estaba escuchando\n             recognitionRef.current.stop();\n        } else {\n            // Si soltó Enter pero no estaba escuchando (ej: error justo al presionar),\n            // solo asegurarnos de que el flag y estado estén correctos.\n             setIsListening(false); //redundante con onend, pero seguro\n        }\n      }\n    };\n\n    // Añadir los listeners de eventos al objeto global 'window'\n    window.addEventListener('keydown', handleKeyDown);\n    window.addEventListener('keyup', handleKeyUp);\n\n    // --- Función de Limpieza (se ejecuta al desmontar el componente) ---\n    return () => {\n      console.log('Limpiando componente SpeechToTextPTT.');\n      // Remover los listeners de eventos para evitar fugas de memoria\n      window.removeEventListener('keydown', handleKeyDown);\n      window.removeEventListener('keyup', handleKeyUp);\n\n      // Abortar el reconocimiento si todavía está activo al desmontar el componente\n      if (recognitionRef.current && (recognitionRef.current.recognizing || isListening)) {\n        recognitionRef.current.abort(); // abort() es más seguro para limpieza rápida\n      }\n      recognitionRef.current = null; // Limpiar la referencia\n    };\n\n  }, []); // El array vacío [] asegura que este efecto se ejecute solo una vez al montar el componente\n\n  // --- Renderizado del Componente ---\n  return (\n    <div style={{ margin: '20px', padding: '20px', border: '1px solid #ccc', borderRadius: '10px', fontFamily: 'sans-serif' }}>\n      <h2>Control por Voz (Enter para Hablar)</h2>\n\n      <p style={{ marginBottom: '15px', fontSize: '1.1em' }}>\n        Estado: {isListening ?\n                 <span style={{ color: 'green', fontWeight: 'bold' }}>🎙️ Escuchando...</span> :\n                 <span style={{ color: 'gray' }}>🔘 Presiona y mantén la tecla Enter para hablar</span>\n               }\n      </p>\n\n      {error && (\n          <p style={{ color: 'red', fontWeight: 'bold' }}>Error: {error}</p>\n      )}\n\n      <div style={{ marginTop: '15px', padding: '15px', border: '1px dashed #bbb', minHeight: '80px', backgroundColor: '#f9f9f9', borderRadius: '5px', wordBreak: 'break-word' }}>\n        <strong>Texto Reconocido:</strong>\n        <p>{recognizedText || 'El texto de la voz aparecerá aquí...'}</p>\n      </div>\n\n      {recognizedText && ( // Mostrar el botón de limpiar solo si hay texto\n          <button\n            onClick={() => { setRecognizedText(''); setError(''); }} // Limpiar texto y errores\n            style={{ marginTop: '15px', padding: '8px 15px', cursor: 'pointer', border: '1px solid #ccc', borderRadius: '5px', backgroundColor: '#eee' }}\n          >\n            Limpiar Texto\n          </button>\n      )}\n    </div>\n  );\n};\n\nexport default SpeechToTextPTT;"
        }
    ]
}