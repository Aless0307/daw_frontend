{
    "sourceFile": "src/components/VoiceLoginRecorder.jsx",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1745115094322,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1745115094322,
            "name": "Commit-0",
            "content": "import React, { useState, useEffect, useRef } from 'react';\nimport './VoiceRecorder.css';\nimport { config } from '../config';\nimport { playPredefinedMessage, playBeep } from '../services/audioService';\n\nconst VoiceLoginRecorder = ({ onRecordingComplete, onStartRecording, onStopRecording, autoStart, login, navigate }) => {\n    const [mediaRecorder, setMediaRecorder] = useState(null);\n    const [isRecording, setIsRecording] = useState(false);\n    const [recordingSuccess, setRecordingSuccess] = useState(false);\n    const [error, setError] = useState('');\n    const [volume, setVolume] = useState(0);\n    const [debugInfo, setDebugInfo] = useState('');\n    const [silenceDetected, setSilenceDetected] = useState(false);\n    const [allLevels, setAllLevels] = useState([]);\n    const [microphoneState, setMicrophoneState] = useState('');\n    const [detectorState, setDetectorState] = useState('');\n    const [audioSummary, setAudioSummary] = useState(null);\n    const [recordingProcessed, setRecordingProcessed] = useState(false);\n    const [isSubmitting, setIsSubmitting] = useState(false);\n    const isStoppingRef = useRef(false);\n    const isRecordingRef = useRef(false);\n    const silenceTimeoutRef = useRef(null);\n    const audioContextRef = useRef(null);\n    const analyserRef = useRef(null);\n    const streamRef = useRef(null);\n    const hasProcessedAudioRef = useRef(false);\n    const hasVoiceBeenDetectedRef = useRef(false);\n    const hasPlayedBeepRef = useRef(false);\n    const volumeAverageRef = useRef(0);\n    const consecutiveFramesCounterRef = useRef(0);\n    const audioLevelsBufferRef = useRef([]);\n    const animationFrameRef = useRef(null);\n    const processorRef = useRef(null);\n    const sourceRef = useRef(null);\n    const hasLoggedAudioRef = useRef(false);\n    const frameCounterRef = useRef(0);\n    const lastLevelCheckRef = useRef(Date.now());\n    const testToneRef = useRef(null);\n    const lastAveragesRef = useRef([]);\n    const rawLevelsRef = useRef([]);\n    const intervalIdRef = useRef(null);\n    const mediaRecorderRef = useRef(null);\n    const pendingSilenceTimeoutRef = useRef(null);\n    const audioChunksRef = useRef([]); // Ref para acumular chunks de audio de forma síncrona\n    const recordingTimerRef = useRef(null); // Agrega la referencia faltante para evitar el error\n    const SILENCE_THRESHOLD = 40;\n    const VOICE_THRESHOLD = 50;\n    const FRAMES_TO_CONSIDER_SILENCE = 5;\n    const FRAMES_TO_START_RECORDING = 2;\n    const SILENCE_TIMEOUT_MS = 800;\n    const BUFFER_SIZE = 30;\n    const VOICE_DEBOUNCE_TIME = 500;\n    const DEBUG_LEVEL = 3;\n    const debugLog = (message, level = 1) => {\n        if (DEBUG_LEVEL >= level) {\n            const timestamp = new Date().toLocaleTimeString('es-ES', { hour12: false, hour: '2-digit', minute: '2-digit', second: '2-digit', fractionalSecondDigits: 3 });\n            const formattedMessage = `[${timestamp}] ${message}`;\n            console.log(formattedMessage);\n            if (level <= 3) setDebugInfo(prev => `${formattedMessage}\\n${prev}`.substring(0, 2000));\n        }\n    };\n    useEffect(() => {\n        debugLog('🔄 Componente VoiceLoginRecorder montado', 1);\n        return () => {\n            debugLog('🔄 Componente VoiceLoginRecorder desmontado, limpiando recursos...', 1);\n            safeStopRecording('Componente desmontado');\n        };\n    }, []);\n    useEffect(() => {\n        debugLog(`🎙️ Estado de grabación: ${isRecording ? 'ACTIVO' : 'INACTIVO'}`, 1);\n        isRecordingRef.current = isRecording;\n    }, [isRecording]);\n    useEffect(() => {\n        if (typeof autoStart !== 'undefined' && autoStart && !isRecording) {\n            debugLog('🚦 autoStart activo, iniciando grabación automáticamente', 1);\n            handleStartRecording();\n        }\n    }, [autoStart]);\n    const safeStopRecording = (reason = \"Manual\") => {\n        if (isStoppingRef.current) {\n            debugLog(\"⛔ Ya estamos deteniendo\", 1);\n            return;\n        }\n        isStoppingRef.current = true;\n        isRecordingRef.current = false;\n        setIsRecording(false);\n        debugLog(`🛑 DETENIENDO GRABACIÓN POR: ${reason}`, 1);\n        if (silenceTimeoutRef.current) {\n            clearTimeout(silenceTimeoutRef.current);\n            silenceTimeoutRef.current = null;\n        }\n        if (recordingTimerRef.current) {\n            clearTimeout(recordingTimerRef.current);\n            recordingTimerRef.current = null;\n        }\n        if (intervalIdRef.current) {\n            clearInterval(intervalIdRef.current);\n            intervalIdRef.current = null;\n        }\n        if (animationFrameRef.current) {\n            cancelAnimationFrame(animationFrameRef.current);\n            animationFrameRef.current = null;\n        }\n        if (testToneRef.current) {\n            try {\n                testToneRef.current.stop();\n                testToneRef.current = null;\n            } catch (error) {\n                console.error('Error al detener tono de prueba:', error);\n            }\n        }\n        if (mediaRecorder && (mediaRecorder.state === 'recording' || mediaRecorder.state === 'paused')) {\n            try {\n                debugLog(`📼 MediaRecorder activo detectado (estado: ${mediaRecorder.state}), deteniendo...`, 1);\n                mediaRecorder.stop();\n                if (onStopRecording) {\n                    onStopRecording();\n                }\n                debugLog('✅ Grabación detenida correctamente', 1);\n            } catch (error) {\n                console.error('❌ Error al detener MediaRecorder:', error);\n                debugLog(`❌ ERROR AL DETENER GRABACIÓN: ${error.message}`, 1);\n            }\n        }\n        if (streamRef.current) {\n            try {\n                const tracks = streamRef.current.getTracks();\n                debugLog(`🧹 Deteniendo ${tracks.length} tracks de audio`, 2);\n                tracks.forEach(track => {\n                    debugLog(`🧹 Deteniendo track: ${track.kind} - ${track.label} - ${track.readyState}`, 2);\n                    track.stop();\n                });\n            } catch (err) {\n                console.error(\"Error al detener tracks de stream:\", err);\n                debugLog(`❌ Error al detener tracks: ${err.message}`, 1);\n            }\n            streamRef.current = null;\n        }\n        if (processorRef.current) {\n            try {\n                processorRef.current.disconnect();\n                processorRef.current = null;\n            } catch (err) {\n                console.error(\"Error al desconectar processor:\", err);\n            }\n        }\n        if (sourceRef.current) {\n            try {\n                sourceRef.current.disconnect();\n                sourceRef.current = null;\n            } catch (err) {\n                console.error(\"Error al desconectar source:\", err);\n            }\n        }\n        if (analyserRef.current) {\n            try {\n                analyserRef.current = null;\n            } catch (err) {\n                console.error(\"Error al limpiar analyser:\", err);\n            }\n        }\n        if (audioContextRef.current) {\n            try {\n                audioContextRef.current.close().then(() => {\n                    debugLog('✅ Contexto de audio cerrado correctamente', 2);\n                }).catch(err => {\n                    console.error(\"Error al cerrar contexto de audio:\", err);\n                    debugLog(`❌ Error al cerrar contexto de audio: ${err.message}`, 1);\n                });\n            } catch (err) {\n                console.error(\"Error al intentar cerrar contexto de audio:\", err);\n                debugLog(`❌ Error al cerrar contexto de audio: ${err.message}`, 1);\n            }\n            audioContextRef.current = null;\n        }\n        if (pendingSilenceTimeoutRef.current) {\n            clearTimeout(pendingSilenceTimeoutRef.current);\n            pendingSilenceTimeoutRef.current = null;\n        }\n        hasVoiceBeenDetectedRef.current = false;\n        hasPlayedBeepRef.current = false;\n        volumeAverageRef.current = 0;\n        consecutiveFramesCounterRef.current = 0;\n        audioLevelsBufferRef.current = [];\n        hasLoggedAudioRef.current = false;\n        frameCounterRef.current = 0;\n        lastLevelCheckRef.current = Date.now();\n        lastAveragesRef.current = [];\n        rawLevelsRef.current = [];\n        setAllLevels([]);\n        setMicrophoneState('');\n        setDetectorState('');\n        debugLog(\"🎙️ Todos los recursos de audio liberados\", 1);\n        setTimeout(() => {\n            isStoppingRef.current = false;\n            debugLog(\"🔄 Listo para una nueva grabación\", 2);\n        }, 200);\n    };\n    const calculateSilenceFromBuffer = () => {\n        if (audioLevelsBufferRef.current.length < 5) {\n            debugLog('⚠️ Buffer de audio insuficiente para calcular silencio', 2);\n            return false;\n        }\n        const recentLevels = audioLevelsBufferRef.current.slice(-5);\n        const average = recentLevels.reduce((acc, val) => acc + val, 0) / recentLevels.length;\n        const isSilent = average < SILENCE_THRESHOLD;\n        debugLog(`🔍 Análisis de buffer: Promedio=${average.toFixed(2)}, Umbral=${SILENCE_THRESHOLD}, Silencio=${isSilent ? 'SÍ' : 'NO'}`, 2);\n        return isSilent;\n    };\n    const handleStartRecording = async (e) => {\n        if (e) e.preventDefault();\n        if (isRecording || isStoppingRef.current) {\n            debugLog('Ya estamos grabando o en proceso de detener, ignorando solicitud', 1);\n            return;\n        }\n        debugLog('▶️ INICIANDO GRABACIÓN...', 1);\n        debugLog(`📝 Navegador: ${navigator.userAgent}`, 1);\n        if (!window.AudioContext && !window.webkitAudioContext) {\n            debugLog('❌ ERROR: AudioContext no está soportado en este navegador', 1);\n            setError('Tu navegador no soporta AudioContext, necesario para la detección de silencio.');\n            return;\n        }\n        if (!window.MediaRecorder) {\n            debugLog('❌ ERROR: MediaRecorder no está soportado en este navegador', 1);\n            setError('Tu navegador no soporta la grabación de audio.');\n            return;\n        }\n        setError('');\n        setRecordingSuccess(false);\n        setDebugInfo('');\n        setSilenceDetected(false);\n        setAllLevels([]);\n        setMicrophoneState('Inicializando...');\n        setDetectorState('Preparando...');\n        hasProcessedAudioRef.current = false;\n        hasVoiceBeenDetectedRef.current = false;\n        hasPlayedBeepRef.current = false;\n        volumeAverageRef.current = 0;\n        consecutiveFramesCounterRef.current = 0;\n        audioLevelsBufferRef.current = [];\n        hasLoggedAudioRef.current = false;\n        frameCounterRef.current = 0;\n        lastLevelCheckRef.current = Date.now();\n        lastAveragesRef.current = [];\n        rawLevelsRef.current = [];\n        try {\n            debugLog('🎤 Solicitando acceso al micrófono...', 1);\n            setMicrophoneState('Solicitando acceso...');\n            try {\n                const devices = await navigator.mediaDevices.enumerateDevices();\n                const audioInputs = devices.filter(device => device.kind === 'audioinput');\n                debugLog(`📱 Dispositivos de audio disponibles: ${audioInputs.length}`, 1);\n                audioInputs.forEach((device, index) => {\n                    debugLog(`📱 Micrófono ${index + 1}: ${device.label || 'Sin nombre'} (${device.deviceId.substring(0, 8)}...)`, 1);\n                });\n            } catch (devErr) {\n                debugLog('⚠️ No se pudieron listar los dispositivos de audio', 2);\n            }\n            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n            streamRef.current = stream;\n            setMicrophoneState('Micrófono activo');\n            audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();\n            analyserRef.current = audioContextRef.current.createAnalyser();\n            analyserRef.current.fftSize = 2048;\n            sourceRef.current = audioContextRef.current.createMediaStreamSource(stream);\n            processorRef.current = audioContextRef.current.createScriptProcessor(2048, 1, 1);\n            sourceRef.current.connect(analyserRef.current);\n            sourceRef.current.connect(processorRef.current);\n            processorRef.current.connect(audioContextRef.current.destination);\n            processorRef.current.onaudioprocess = (event) => {\n                const input = event.inputBuffer.getChannelData(0);\n                let sum = 0.0;\n                for (let i = 0; i < input.length; ++i) sum += input[i] * input[i];\n                const rms = Math.sqrt(sum / input.length);\n                const level = Math.min(100, Math.max(0, Math.round(rms * 1000)));\n                setVolume(level);\n                audioLevelsBufferRef.current.push(level);\n                if (audioLevelsBufferRef.current.length > BUFFER_SIZE) audioLevelsBufferRef.current.shift();\n                setAllLevels([...audioLevelsBufferRef.current]);\n                if (level > VOICE_THRESHOLD) {\n                    hasVoiceBeenDetectedRef.current = true;\n                    setSilenceDetected(false);\n                    // If we were waiting to stop due to silence, cancel it if voice resumes\n                    if (pendingSilenceTimeoutRef.current) {\n                        debugLog('🔊 Voz detectada durante periodo de gracia, cancelando parada por silencio', 1);\n                        clearTimeout(pendingSilenceTimeoutRef.current);\n                        pendingSilenceTimeoutRef.current = null;\n                    }\n                }\n                if (hasVoiceBeenDetectedRef.current && calculateSilenceFromBuffer()) {\n                    setSilenceDetected(true);\n                    // Only start grace period timeout if not already started\n                    if (!pendingSilenceTimeoutRef.current) {\n                        debugLog('🤫 Silencio detectado tras voz. Iniciando periodo de gracia antes de detener grabación...', 1);\n                        pendingSilenceTimeoutRef.current = setTimeout(() => {\n                            debugLog('⏳ Silencio prolongado tras voz. Deteniendo grabación...', 1);\n                            safeStopRecording('Silencio prolongado tras voz');\n                            pendingSilenceTimeoutRef.current = null;\n                        }, SILENCE_TIMEOUT_MS);\n                    }\n                }\n            };\n            const recorder = new window.MediaRecorder(stream);\n            setMediaRecorder(recorder);\n            mediaRecorderRef.current = recorder;\n            recorder.ondataavailable = (e) => {\n                if (e.data && e.data.size > 0) {\n                    audioChunksRef.current.push(e.data);\n                }\n            };\n            recorder.onstop = () => {\n                debugLog('⏹️ Grabación detenida (onstop)', 1);\n                const blob = new Blob(audioChunksRef.current, { type: 'audio/wav' });\n                setRecordingSuccess(true);\n                setAudioSummary({ size: blob.size, type: blob.type });\n                // Información detallada sobre el archivo grabado\n                const fileSizeKB = (blob.size / 1024).toFixed(2);\n                const fileType = blob.type;\n                // Crear un nombre de archivo con timestamp\n                const now = new Date();\n                const fileName = `voice_login_${now.getFullYear()}-${String(now.getMonth()+1).padStart(2,'0')}-${String(now.getDate()).padStart(2,'0')}_${String(now.getHours()).padStart(2,'0')}${String(now.getMinutes()).padStart(2,'0')}${String(now.getSeconds()).padStart(2,'0')}.wav`;\n                debugLog(`✅ Archivo grabado: Nombre = ${fileName}, Tamaño = ${fileSizeKB} KB, Tipo = ${fileType}`, 1);\n                debugLog(`📁 Guardado en memoria temporal del navegador (Blob en RAM, no en disco)`, 1);\n                // Solo reproducir si el blob tiene datos\n                if (blob.size > 100) { // 100 bytes como umbral mínimo\n                    // Solo reproducir una vez: elimina la reproducción duplicada\n                    debugLog('🔊 Reproduciendo el audio grabado...', 1);\n                    const audioUrl = URL.createObjectURL(blob);\n                    const audio = new Audio(audioUrl);\n                    audio.play().catch(e => debugLog('❌ Error al reproducir audio: ' + e.message, 1));\n                    audio.onended = () => handleVoiceLogin(blob);\n                } else {\n                    debugLog('❌ El archivo grabado está vacío o corrupto. No se reproducirá audio ni se enviará al backend.', 1);\n                }\n                audioChunksRef.current = [];\n            };\n            recorder.start();\n            setIsRecording(true);\n            if (onStartRecording) onStartRecording();\n            debugLog('🎙️ Grabando audio...', 1);\n        } catch (err) {\n            debugLog(`❌ Error al iniciar grabación: ${err.message}`, 1);\n            setError('No se pudo acceder al micrófono.');\n            safeStopRecording('Error al iniciar grabación');\n        }\n    };\n    const handleVoiceLogin = async (audioBlob) => {\n        setError(null);\n        setIsSubmitting(true);\n        try {\n            const email = sessionStorage.getItem('correovocal') || '';\n            sessionStorage.removeItem('correovocal');\n            if (!email) {\n                setIsSubmitting(false);\n                return;\n            }\n            const formData = new FormData();\n            formData.append('email', email);\n            // El nombre del archivo puede ser fijo o usar el timestamp generado antes\n            formData.append('voice_recording', audioBlob, 'voice_login.wav');\n            debugLog('📤 Enviando audio al backend para login por voz...', 1);\n            const response = await fetch(`${config.API_URL}/auth/login-voice`, {\n                method: 'POST',\n                body: formData\n            });\n            debugLog('📥 Respuesta recibida del backend (login-voice)', 1);\n            if (!response.ok) {\n                const errData = await response.json();\n                let errorMsg = 'Error en el inicio de sesión por voz';\n                if (typeof errData.detail === 'string') errorMsg = errData.detail;\n                else if (typeof errData.msg === 'string') errorMsg = errData.msg;\n                else if (Array.isArray(errData) && errData.length && typeof errData[0].msg === 'string') errorMsg = errData[0].msg;\n                else errorMsg = JSON.stringify(errData);\n                debugLog('❌ Error en login por voz: ' + errorMsg, 1);\n                setError(errorMsg);\n                setIsSubmitting(false);\n                return;\n            }\n            const data = await response.json();\n            debugLog('✅ Login por voz exitoso. Datos recibidos: ' + JSON.stringify(data), 1);\n            sessionStorage.setItem('access_token', data.access_token);\n            if (!data.access_token) {\n                debugLog('❌ No se recibió access_token en la respuesta.', 1);\n                throw new Error('No se recibió token en la respuesta');\n            }\n            // Asume que tienes acceso a login y navigate vía props/context\n            if (typeof login === 'function') {\n                login({\n                    token: data.access_token,\n                    username: data.username || email,\n                    email: data.email || email\n                });\n            }\n            debugLog('➡️ Login por voz ejecutado correctamente. Redirigiendo a /home...', 1);\n            if (typeof navigate === 'function') navigate('/home');\n            setIsSubmitting(false);\n        } catch (err) {\n            debugLog('🚨 Error inesperado en login por voz: ' + err, 1);\n            setError('Error al conectar con el servidor');\n            setIsSubmitting(false);\n        }\n    };\n    return (\n        <div className=\"voice-recorder-container bg-white p-6 rounded-lg shadow-sm border border-gray-200\">\n            <h3 className=\"text-lg font-medium text-gray-900 mb-4\">Login por Voz</h3>\n            {error && <div className=\"text-red-600 mb-2\">{error}</div>}\n            {microphoneState && <div className=\"text-xs text-gray-500 mb-2\">Micrófono: {microphoneState}</div>}\n            {detectorState && <div className=\"text-xs text-gray-500 mb-2\">Detector: {detectorState}</div>}\n            {isRecording && (\n                <div className=\"flex items-center\">\n                    <div className=\"animate-pulse mr-2 h-3 w-3 rounded-full bg-red-600\"></div>\n                    <span className=\"text-sm text-gray-600\">\n                        {silenceDetected \n                            ? \"Silencio detectado... finalizando\" \n                            : \"Grabando... (habla claramente para iniciar)\"}\n                    </span>\n                </div>\n            )}\n            {isRecording && allLevels.length > 0 && (\n                <div className=\"mt-2 p-2 bg-gray-50 rounded border border-gray-200\">\n                    <p className=\"text-xs text-gray-500 mb-1\">Historial de niveles de audio:</p>\n                    <div className=\"flex h-8 items-end space-x-1\">\n                        {allLevels.map((level, index) => (\n                            <div \n                                key={index} \n                                className={`w-2 ${level > VOICE_THRESHOLD ? 'bg-blue-500' : level > SILENCE_THRESHOLD ? 'bg-green-500' : 'bg-gray-300'}`}\n                                style={{height: `${Math.max(5, Math.min(100, level * 3))}%`}}\n                                title={`Nivel: ${level}`}\n                            ></div>\n                        ))}\n                    </div>\n                </div>\n            )}\n            {DEBUG_LEVEL > 0 && debugInfo && (\n                <div className=\"mt-2 p-2 bg-gray-50 rounded border border-gray-200 text-xs font-mono text-gray-500 max-h-36 overflow-y-auto\">\n                    <pre className=\"whitespace-pre-wrap\">{debugInfo}</pre>\n                </div>\n            )}\n            {audioSummary && (\n                <div className=\"mt-2 text-xs text-gray-500\">\n                    Archivo generado: {audioSummary.size} bytes ({audioSummary.type})\n                </div>\n            )}\n        </div>\n    );\n};\n\nexport default VoiceLoginRecorder;\n"
        }
    ]
}